import queue
import threading
import time
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from enum import Enum
import uuid
import os
import json
from app.utils.logger import get_logger
from app.utils.task_utils import save_original_request_data
import traceback

logger = get_logger(__name__)

# --- å•ä¾‹æ¨¡å¼å®ç° ---
_task_queue_instance = None
_task_queue_lock = threading.Lock()

def get_task_queue(max_workers: int = 3) -> 'TaskQueue':
    """
    è·å–ä»»åŠ¡é˜Ÿåˆ—çš„å•ä¾‹ã€‚
    """
    global _task_queue_instance
    if _task_queue_instance is None:
        with _task_queue_lock:
            if _task_queue_instance is None:
                logger.error("ğŸš¨ [SINGLETON] Creating new TaskQueue instance.")
                _task_queue_instance = TaskQueue(max_workers=max_workers)
            else:
                logger.error("ğŸš¨ [SINGLETON] Instance already created while waiting for lock.")
    else:
        logger.error("ğŸš¨ [SINGLETON] Returning existing TaskQueue instance.")
    return _task_queue_instance

class TaskType(Enum):
    SINGLE_VIDEO = "single_video"
    COLLECTION = "collection"

class TaskStatus(Enum):
    PENDING = "PENDING"
    RUNNING = "RUNNING"
    SUCCESS = "SUCCESS"
    FAILED = "FAILED"

@dataclass
class Task:
    task_id: str
    task_type: TaskType
    data: Dict[str, Any]
    status: TaskStatus = TaskStatus.PENDING
    created_at: float = None
    started_at: float = None
    completed_at: float = None
    error_message: str = None
    result: Any = None

    def to_dict(self) -> Dict[str, Any]:
        """å°†ä»»åŠ¡å¯¹è±¡åºåˆ—åŒ–ä¸ºå­—å…¸"""
        return {
            "task_id": self.task_id,
            "task_type": self.task_type.value,
            "data": self.data,
            "status": self.status.value,
            "created_at": self.created_at,
            "started_at": self.started_at,
            "completed_at": self.completed_at,
            "error_message": self.error_message,
            "result": self.result
        }

    @classmethod
    def from_dict(cls, data: dict):
        """ä»å­—å…¸ååºåˆ—åŒ–ä¸ºä»»åŠ¡å¯¹è±¡"""
        status = TaskStatus(data.get('status', 'PENDING'))
        task_type = TaskType(data.get('task_type', 'SINGLE_VIDEO'))
        
        return cls(
            task_id=data['task_id'],
            task_type=task_type,
            data=data['data'],
            status=status,
            created_at=data.get('created_at'),
            started_at=data.get('started_at'),
            completed_at=data.get('completed_at'),
            error_message=data.get('error_message'),
            result=data.get('result')
        )

class TaskQueue:
    def __init__(self, max_workers: int = 3):
        logger.warning(f"âœ…âœ…âœ… [INSTANCE CHECK] TaskQueue __init__ called. Instance ID: {id(self)}")
        self.task_queue = queue.Queue()
        self.tasks: Dict[str, Task] = {}
        self.max_workers = max_workers
        self.workers = []
        self.running = False
        self._lock = threading.Lock()
        
        # å°†æŒä¹…åŒ–ç›®å½•è®¾ç½®åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ 'backend' æ–‡ä»¶å¤¹ä¸‹
        # os.path.dirname(__file__) -> backend/app/core
        # os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "task_persistence")) -> backend/task_persistence
        self.persistence_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "task_persistence"))
        os.makedirs(self.persistence_dir, exist_ok=True)
        logger.warning(f"âœ… [è°ƒè¯•] ä»»åŠ¡æŒä¹…åŒ–ç›®å½•å·²ç¡®è®¤ä¸º: {self.persistence_dir}")
        
        self._load_tasks_from_disk()
        
    def _save_task_to_disk(self, task: Task):
        """å°†å•ä¸ªä»»åŠ¡ä¿å­˜åˆ°ç£ç›˜"""
        file_path = os.path.join(self.persistence_dir, f"{task.task_id}.json")
        logger.error(f"ğŸ’¾ [SAVE_TASK] Attempting to save task to: {file_path}")
        try:
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(task.to_dict(), f, ensure_ascii=False, indent=4)
            logger.error(f"ğŸ’¾âœ… [SAVE_TASK] Successfully saved task: {task.task_id}")
        except Exception as e:
            logger.error(f"âŒ åºåˆ—åŒ–å¹¶ä¿å­˜ä»»åŠ¡å¤±è´¥ {file_path}: {e}")

    def _load_task_from_file(self, task_id: str) -> Optional[Task]:
        """ä»å•ä¸ªæ–‡ä»¶åŠ è½½ä»»åŠ¡"""
        file_path = os.path.join(self.persistence_dir, f"{task_id}.json")
        if not os.path.exists(file_path):
            return None
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            task = Task.from_dict(data)
            return task
        except Exception as e:
            logger.error(f"âŒ ä»æ–‡ä»¶ååºåˆ—åŒ–ä»»åŠ¡å¤±è´¥ {file_path}: {e}")
            return None

    def _load_tasks_from_disk(self):
        """åœ¨å¯åŠ¨æ—¶ä»ç£ç›˜åŠ è½½æ‰€æœ‰ä»»åŠ¡"""
        with self._lock:
            logger.warning(f"ğŸ“‚ [è°ƒè¯•] å¼€å§‹ä»ç£ç›˜åŠ è½½æŒä¹…åŒ–çš„ä»»åŠ¡...")
            if not os.path.exists(self.persistence_dir):
                logger.warning("  - æŒä¹…åŒ–ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡åŠ è½½ã€‚")
                return

            task_files = [f for f in os.listdir(self.persistence_dir) if f.endswith('.json')]
            if not task_files:
                logger.warning("  - æŒä¹…åŒ–ç›®å½•ä¸ºç©ºï¼Œè·³è¿‡åŠ è½½ã€‚")
                return

            loaded_count = 0
            requeued_count = 0
            for filename in task_files:
                task_id = filename.replace(".json", "")
                try:
                    task = self._load_task_from_file(task_id)
                    if not task:
                        continue

                    # å¦‚æœä»»åŠ¡åœ¨æœåŠ¡å…³é—­æ—¶å¤„äºæ­£åœ¨è¿è¡ŒçŠ¶æ€ï¼Œåˆ™é‡ç½®ä¸ºå¾…å¤„ç†
                    if task.status == TaskStatus.RUNNING:
                        logger.warning(f"ğŸ”„ æ£€æµ‹åˆ°ä¸­æ–­çš„ä»»åŠ¡ï¼Œé‡ç½®ä¸ºå¾…å¤„ç†: {task.task_id}")
                        task.status = TaskStatus.PENDING
                        task.started_at = None
                        self._save_task_to_disk(task)  # ä¿å­˜é‡ç½®åçš„çŠ¶æ€

                    self.tasks[task.task_id] = task
                    loaded_count += 1
                    logger.info(f"  - âœ… å·²åŠ è½½ä»»åŠ¡: {task.task_id} (çŠ¶æ€: {task.status.value})")

                    # åªæœ‰æœªå®Œæˆçš„ä»»åŠ¡æ‰éœ€è¦é‡æ–°æ”¾å…¥é˜Ÿåˆ—
                    if task.status not in [TaskStatus.SUCCESS, TaskStatus.FAILED]:
                        logger.info(f"  - ğŸ“¥ å°†å¾…å¤„ç†ä»»åŠ¡é‡æ–°æ”¾å…¥é˜Ÿåˆ—: {task.task_id}")
                        self.task_queue.put(task)
                        requeued_count += 1
                except Exception as e:
                    logger.error(f"âŒ åŠ è½½ä»»åŠ¡ {task_id} å¤±è´¥: {e}", exc_info=True)
            
            logger.info(f"âœ… ä»»åŠ¡åŠ è½½å®Œæˆã€‚å…±åŠ è½½ {loaded_count} ä¸ªä»»åŠ¡ï¼Œé‡æ–°å…¥é˜Ÿ {requeued_count} ä¸ªã€‚")

    def start(self):
        """å¯åŠ¨ä»»åŠ¡é˜Ÿåˆ—å¤„ç†å™¨"""
        if self.running:
            return
            
        self.running = True
        logger.info(f"ğŸš€ å¯åŠ¨ä»»åŠ¡é˜Ÿåˆ—ï¼Œå·¥ä½œçº¿ç¨‹æ•°: {self.max_workers}")
        
        for i in range(self.max_workers):
            worker = threading.Thread(target=self._worker, name=f"TaskWorker-{i}")
            worker.daemon = True
            worker.start()
            self.workers.append(worker)
            
    def stop(self):
        """åœæ­¢ä»»åŠ¡é˜Ÿåˆ—å¤„ç†å™¨"""
        self.running = False
        logger.info("ğŸ›‘ åœæ­¢ä»»åŠ¡é˜Ÿåˆ—")
        
    def add_task(self, task_type: TaskType, data: Dict[str, Any], task_id: Optional[str] = None) -> str:
        """æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        if not task_id:
            task_id = str(uuid.uuid4())
        
        # ä¿å­˜åŸå§‹è¯·æ±‚æ•°æ®åˆ°æŒä¹…åŒ–å­˜å‚¨
        try:
            save_original_request_data(task_id, data)
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜åŸå§‹è¯·æ±‚æ•°æ®å¤±è´¥: {task_id}, {e}")
            
        task = Task(
            task_id=task_id,
            task_type=task_type,
            data=data,
            created_at=time.time()
        )
        
        with self._lock:
            self.tasks[task_id] = task
            logger.error(f"ğŸ’¾ [ADD_TASK] About to call _save_task_to_disk for {task_id}")
            self._save_task_to_disk(task) # æŒä¹…åŒ–
            logger.error(f"ğŸ’¾ [ADD_TASK] Returned from _save_task_to_disk for {task_id}")
            
        self.task_queue.put(task)
        logger.warning(f"ğŸ“ [INSTANCE CHECK] Task added to queue. Instance ID: {id(self)}. Task ID: {task_id}. Total tasks in memory: {len(self.tasks)}")
        
        return task_id
        
    def get_task_status(self, task_id: str) -> Optional[Task]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        with self._lock:
            return self.tasks.get(task_id)
            
    def get_all_tasks(self) -> Dict[str, Task]:
        """è·å–æ‰€æœ‰ä»»åŠ¡"""
        with self._lock:
            return self.tasks.copy()
            
    def retry_task(self, task_id: str) -> bool:
        """é‡è¯•ä»»åŠ¡ï¼ˆæ”¯æŒé‡è¯•ä»»ä½•éSUCCESSçŠ¶æ€çš„ä»»åŠ¡ï¼‰"""
        with self._lock:
            task = self.tasks.get(task_id)
            if not task:
                logger.warning(f"âš ï¸ ä»»åŠ¡ä¸å­˜åœ¨ï¼Œæ— æ³•é‡è¯•: {task_id}")
                return False
            
            if task.status == TaskStatus.SUCCESS:
                logger.warning(f"âš ï¸ ä»»åŠ¡å·²æˆåŠŸå®Œæˆï¼Œæ— éœ€é‡è¯•: {task_id}")
                return False
            
            # é‡ç½®ä»»åŠ¡çŠ¶æ€
            task.status = TaskStatus.PENDING
            task.started_at = None
            task.completed_at = None
            task.error_message = None
            task.result = None
            self._save_task_to_disk(task) # æŒä¹…åŒ–
            
            # é‡æ–°æäº¤åˆ°é˜Ÿåˆ—
            self.task_queue.put(task)
            
        logger.info(f"ğŸ”„ ä»»åŠ¡å·²é‡æ–°æäº¤åˆ°é˜Ÿåˆ—: {task_id}")
        return True
        
    def batch_retry_failed_tasks(self) -> dict:
        """æ‰¹é‡é‡è¯•æ‰€æœ‰å¤±è´¥çš„ä»»åŠ¡"""
        with self._lock:
            failed_tasks = [task for task in self.tasks.values() if task.status == TaskStatus.FAILED]
            
            if not failed_tasks:
                logger.info("ğŸ“ æ²¡æœ‰æ‰¾åˆ°å¤±è´¥çš„ä»»åŠ¡")
                return {"retried_count": 0, "total_failed": 0, "message": "æ²¡æœ‰éœ€è¦é‡è¯•çš„å¤±è´¥ä»»åŠ¡"}
            
            retried_count = 0
            for task in failed_tasks:
                # é‡ç½®ä»»åŠ¡çŠ¶æ€
                task.status = TaskStatus.PENDING
                task.started_at = None
                task.completed_at = None
                task.error_message = None
                task.result = None
                self._save_task_to_disk(task) # æŒä¹…åŒ–
                
                # é‡æ–°æäº¤åˆ°é˜Ÿåˆ—
                self.task_queue.put(task)
                retried_count += 1
                
        logger.info(f"ğŸ”„ æ‰¹é‡é‡è¯•å®Œæˆï¼Œé‡è¯•äº† {retried_count} ä¸ªå¤±è´¥ä»»åŠ¡")
        return {
            "retried_count": retried_count, 
            "total_failed": len(failed_tasks),
            "message": f"æˆåŠŸé‡è¯• {retried_count} ä¸ªå¤±è´¥ä»»åŠ¡"
        }
        
    def batch_retry_non_success_tasks(self) -> dict:
        """æ‰¹é‡é‡è¯•æ‰€æœ‰éæˆåŠŸçŠ¶æ€çš„ä»»åŠ¡ï¼ˆåŒ…æ‹¬PENDINGã€RUNNINGã€FAILEDï¼‰"""
        with self._lock:
            non_success_tasks = [task for task in self.tasks.values() if task.status != TaskStatus.SUCCESS]
            
            if not non_success_tasks:
                logger.info("ğŸ“ æ²¡æœ‰æ‰¾åˆ°éæˆåŠŸçŠ¶æ€çš„ä»»åŠ¡")
                return {"retried_count": 0, "total_non_success": 0, "message": "æ²¡æœ‰éœ€è¦é‡è¯•çš„éæˆåŠŸä»»åŠ¡"}
            
            # æŒ‰çŠ¶æ€åˆ†ç±»ç»Ÿè®¡
            pending_count = len([t for t in non_success_tasks if t.status == TaskStatus.PENDING])
            running_count = len([t for t in non_success_tasks if t.status == TaskStatus.RUNNING])
            failed_count = len([t for t in non_success_tasks if t.status == TaskStatus.FAILED])
            
            retried_count = 0
            for task in non_success_tasks:
                # é‡ç½®ä»»åŠ¡çŠ¶æ€
                task.status = TaskStatus.PENDING
                task.started_at = None
                task.completed_at = None
                task.error_message = None
                task.result = None
                self._save_task_to_disk(task) # æŒä¹…åŒ–
                
                # é‡æ–°æäº¤åˆ°é˜Ÿåˆ—
                self.task_queue.put(task)
                retried_count += 1
                
        logger.info(f"ğŸ”„ æ‰¹é‡é‡è¯•éæˆåŠŸä»»åŠ¡å®Œæˆï¼Œé‡è¯•äº† {retried_count} ä¸ªä»»åŠ¡")
        logger.info(f"ğŸ“Š é‡è¯•ç»Ÿè®¡: PENDING({pending_count}), RUNNING({running_count}), FAILED({failed_count})")
        
        return {
            "retried_count": retried_count, 
            "total_non_success": len(non_success_tasks),
            "pending_count": pending_count,
            "running_count": running_count, 
            "failed_count": failed_count,
            "message": f"æˆåŠŸé‡è¯• {retried_count} ä¸ªéæˆåŠŸä»»åŠ¡ (PENDING:{pending_count}, RUNNING:{running_count}, FAILED:{failed_count})"
        }
        
    def force_retry_all(self, task_ids: List[str], override_data: Optional[dict] = None) -> dict:
        """
        å¼ºåˆ¶é‡è¯•æŒ‡å®šåˆ—è¡¨ä¸­çš„æ‰€æœ‰ä»»åŠ¡ã€‚
        ä¸å†æ‰«æç£ç›˜ï¼Œè€Œæ˜¯åŸºäºå‰ç«¯æä¾›çš„IDåˆ—è¡¨ã€‚
        """
        with self._lock:
            logger.error(f"âš¡ï¸ [å¼ºåˆ¶é‡è¯•] æ”¶åˆ° {len(task_ids)} ä¸ªä»»åŠ¡çš„é‡è¯•è¯·æ±‚ã€‚")
            logger.error(f"ğŸ“‚ [FORCE_RETRY] Checking persistence directory: {self.persistence_dir}")

            retried_count = 0
            not_found_count = 0
            
            for task_id in task_ids:
                # é¦–å…ˆæ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—ä¸­æ˜¯å¦å·²å­˜åœ¨
                if task_id in self.tasks:
                    task = self.tasks[task_id]
                    
                    # æ›´æ–°ä»»åŠ¡æ•°æ®
                    if override_data:
                        task.data.update(override_data)
                        logger.info(f"  - âš™ï¸ åº”ç”¨æ–°é…ç½®åˆ°ä»»åŠ¡ {task_id}")

                    # é‡ç½®ä»»åŠ¡çŠ¶æ€
                    task.status = TaskStatus.PENDING
                    task.started_at = None
                    task.completed_at = None
                    task.error_message = None
                    task.result = None
                    
                    self.task_queue.put(task)
                    self._save_task_to_disk(task)
                    
                    retried_count += 1
                    logger.info(f"  - âœ… æˆåŠŸé‡ç½®å¹¶é‡è¯•ä»»åŠ¡: {task_id} (å†…å­˜ä¸­)")
                    continue
                
                # æ£€æŸ¥task_persistenceç›®å½•
                task_file = os.path.join(self.persistence_dir, f"{task_id}.json")
                if os.path.exists(task_file):
                    task = self._load_task_from_file(task_id)
                    if task:
                        # æ›´æ–°ä»»åŠ¡æ•°æ®
                        if override_data:
                            task.data.update(override_data)
                            logger.info(f"  - âš™ï¸ åº”ç”¨æ–°é…ç½®åˆ°ä»»åŠ¡ {task_id}")

                        # é‡ç½®ä»»åŠ¡çŠ¶æ€
                        task.status = TaskStatus.PENDING
                        task.started_at = None
                        task.completed_at = None
                        task.error_message = None
                        task.result = None
                        
                        self.tasks[task.task_id] = task
                        self.task_queue.put(task)
                        self._save_task_to_disk(task)
                        
                        retried_count += 1
                        logger.info(f"  - âœ… æˆåŠŸé‡ç½®å¹¶é‡è¯•ä»»åŠ¡: {task_id}")
                        continue
                
                # æ£€æŸ¥note_resultsç›®å½•ä¸­çš„ä»»åŠ¡æ–‡ä»¶
                note_results_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "note_results"))
                logger.warning(f"  - [DEBUG] æ£€æŸ¥note_resultsç»å¯¹è·¯å¾„: {note_results_dir}")
                request_file = os.path.join(note_results_dir, f"{task_id}.request.json")
                
                logger.warning(f"  - [DEBUG] æ£€æŸ¥note_resultsè¯·æ±‚æ–‡ä»¶: {request_file}")
                logger.warning(f"  - [DEBUG] æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(request_file)}")
                
                if os.path.exists(request_file):
                    try:
                        # ä»note_resultsè¯»å–ä»»åŠ¡æ•°æ®
                        with open(request_file, 'r', encoding='utf-8') as f:
                            request_data = json.load(f)
                        
                        logger.warning(f"  - [DEBUG] è¯·æ±‚æ•°æ®çš„é”®: {list(request_data.keys())}")
                        
                        # ä»è¯·æ±‚æ•°æ®ä¸­æå–åŸå§‹è¯·æ±‚
                        original_request = request_data.get("original_request", {})
                        
                        logger.warning(f"  - [DEBUG] åŸå§‹è¯·æ±‚çš„é”®: {list(original_request.keys())}")
                        
                        # æ£€æŸ¥æ˜¯å¦å«æœ‰å¿…è¦ä¿¡æ¯
                        if "video_url" in original_request and "platform" in original_request:
                            # åˆ›å»ºä»»åŠ¡
                            task_data = {
                                'video_url': original_request.get('video_url'),
                                'platform': original_request.get('platform'),
                                'quality': original_request.get('quality', 'medium'),
                                'model_name': original_request.get('model_name', 'gpt-4o-mini'),
                                'provider_id': original_request.get('provider_id', 'openai'),
                                'title': original_request.get('title', 'æœªçŸ¥æ ‡é¢˜'),
                                'screenshot': original_request.get('screenshot', False),
                                'link': original_request.get('link', False),
                                'format': original_request.get('format', []),
                                'style': original_request.get('style', 'ç®€æ´'),
                                'extras': original_request.get('extras'),
                                'video_understanding': original_request.get('video_understanding', False),
                                'video_interval': original_request.get('video_interval', 0),
                                'grid_size': original_request.get('grid_size', [])
                            }
                            
                            # åº”ç”¨è¦†ç›–æ•°æ®
                            if override_data:
                                logger.warning(f"  - [DEBUG] åº”ç”¨è¦†ç›–æ•°æ®: {override_data}")
                                task_data.update(override_data)
                            
                            logger.warning(f"  - [DEBUG] æœ€ç»ˆä»»åŠ¡æ•°æ®: {task_data}")
                            
                            # åˆ›å»ºä»»åŠ¡å¯¹è±¡
                            task = Task(
                                task_id=task_id,
                                task_type=TaskType.SINGLE_VIDEO,
                                data=task_data,
                                created_at=time.time()
                            )
                            
                            # ä¿å­˜ä»»åŠ¡
                            self.tasks[task_id] = task
                            self.task_queue.put(task)
                            self._save_task_to_disk(task)
                            
                            retried_count += 1
                            logger.info(f"  - âœ… ä»note_resultsçš„requestæ–‡ä»¶æˆåŠŸé‡å»ºå¹¶é‡è¯•ä»»åŠ¡: {task_id}")
                            continue
                        else:
                            logger.warning(f"  - [DEBUG] åŸå§‹è¯·æ±‚ç¼ºå°‘å¿…è¦ä¿¡æ¯ video_url æˆ– platform")
                    except Exception as e:
                        logger.error(f"  - âŒ ä»note_resultsåŠ è½½requestæ–‡ä»¶å¤±è´¥: {task_id}, é”™è¯¯: {e}")
                        logger.error(f"  - [DEBUG] å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
                else:
                    logger.warning(f"  - [DEBUG] requestæ–‡ä»¶ä¸å­˜åœ¨: {request_file}")
                
                # å°è¯•ä½¿ç”¨æ™®é€š.jsonæ–‡ä»¶
                note_file = os.path.join(note_results_dir, f"{task_id}.json")
                if os.path.exists(note_file):
                    try:
                        # ä»note_resultsè¯»å–ä»»åŠ¡æ•°æ®
                        with open(note_file, 'r', encoding='utf-8') as f:
                            note_data = json.load(f)
                        
                        # æ£€æŸ¥æ˜¯å¦å«æœ‰å¿…è¦ä¿¡æ¯
                        if "video_url" in note_data and "platform" in note_data:
                            # åˆ›å»ºä»»åŠ¡
                            task_data = {
                                'video_url': note_data.get('video_url'),
                                'platform': note_data.get('platform'),
                                'quality': note_data.get('quality', 'medium'),
                                'model_name': note_data.get('model_name', 'gpt-4o-mini'),
                                'provider_id': note_data.get('provider_id', 'openai'),
                                'title': note_data.get('title', 'æœªçŸ¥æ ‡é¢˜')
                            }
                            
                            # åº”ç”¨è¦†ç›–æ•°æ®
                            if override_data:
                                task_data.update(override_data)
                            
                            # åˆ›å»ºä»»åŠ¡å¯¹è±¡
                            task = Task(
                                task_id=task_id,
                                task_type=TaskType.SINGLE_VIDEO,
                                data=task_data,
                                created_at=time.time()
                            )
                            
                            # ä¿å­˜ä»»åŠ¡
                            self.tasks[task_id] = task
                            self.task_queue.put(task)
                            self._save_task_to_disk(task)
                            
                            retried_count += 1
                            logger.info(f"  - âœ… ä»note_resultsæˆåŠŸé‡å»ºå¹¶é‡è¯•ä»»åŠ¡: {task_id}")
                            continue
                    except Exception as e:
                        logger.error(f"  - âŒ ä»note_resultsåŠ è½½ä»»åŠ¡æ–‡ä»¶å¤±è´¥: {task_id}, é”™è¯¯: {e}")
                
                # å¦‚æœä¸Šè¿°å°è¯•éƒ½å¤±è´¥ï¼Œæ‰è®¡ç®—ä¸ºæœªæ‰¾åˆ°
                logger.warning(f"  - â“ æœªæ‰¾åˆ°ä»»åŠ¡æ–‡ä»¶ï¼Œè·³è¿‡: {task_id}")
                not_found_count += 1

            summary = {
                "retried_count": retried_count,
                "not_found_count": not_found_count,
                "total_requested": len(task_ids),
                "message": f"å¼ºåˆ¶é‡è¯•å®Œæˆ: {retried_count}ä¸ªä»»åŠ¡æˆåŠŸé‡è¯•, {not_found_count}ä¸ªä»»åŠ¡æœªæ‰¾åˆ°ã€‚"
            }
            logger.warning(f"  - ğŸ“ [å¼ºåˆ¶é‡è¯•æ€»ç»“] {summary['message']}")
            return summary
        
    def _worker(self):
        """å·¥ä½œçº¿ç¨‹ä¸»å¾ªç¯"""
        worker_name = threading.current_thread().name
        logger.info(f"ğŸ”„ {worker_name} å¯åŠ¨")
        
        while self.running:
            try:
                # è·å–ä»»åŠ¡ï¼Œè®¾ç½®è¶…æ—¶é¿å…é˜»å¡
                task = self.task_queue.get(timeout=1)
                self._process_task(task, worker_name)
                self.task_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"âŒ {worker_name} å¤„ç†ä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                
        logger.info(f"ğŸ›‘ {worker_name} åœæ­¢")
        
    def _process_task(self, task: Task, worker_name: str):
        """å¤„ç†å•ä¸ªä»»åŠ¡ï¼Œå¢åŠ é¡¶å±‚å¼‚å¸¸æ•è·"""
        logger.info(f"ğŸ¬ {worker_name} å¼€å§‹å¤„ç†ä»»åŠ¡: {task.task_id}")
        
        try:
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
            with self._lock:
                task.status = TaskStatus.RUNNING
                task.started_at = time.time()
                task.error_message = None
                task.result = None
                self._save_task_to_disk(task) # æŒä¹…åŒ–
            
            # æ‰§è¡Œä»»åŠ¡
            if task.task_type == TaskType.SINGLE_VIDEO:
                result = self._process_single_video(task)
            elif task.task_type == TaskType.COLLECTION:
                result = self._process_collection(task)
            else:
                raise ValueError(f"æœªçŸ¥çš„ä»»åŠ¡ç±»å‹: {task.task_type}")

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºæˆåŠŸ
            with self._lock:
                task.status = TaskStatus.SUCCESS
                task.result = result
                self._save_task_to_disk(task) # æŒä¹…åŒ–
            
            logger.info(f"âœ… {worker_name} ä»»åŠ¡å®Œæˆ: {task.task_id}")
            
        except Exception as e:
            # æ•è·æ‰€æœ‰å¯èƒ½çš„å¼‚å¸¸ï¼Œç¡®ä¿å·¥ä½œçº¿ç¨‹ä¸ä¼šå´©æºƒ
            error_message = f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ {worker_name} ä»»åŠ¡å¤„ç†å¤±è´¥: {task.task_id}")
            logger.error(f"   é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            with self._lock:
                task.status = TaskStatus.FAILED
                task.error_message = error_message
                self._save_task_to_disk(task) # æŒä¹…åŒ–
        
        finally:
            # ç¡®ä¿ä»»åŠ¡å®Œæˆæ—¶é—´è¢«è®°å½•
            with self._lock:
                task.completed_at = time.time()
                self._save_task_to_disk(task) # æŒä¹…åŒ–
        
    def _process_single_video(self, task: Task) -> Any:
        """å¤„ç†å•ä¸ªè§†é¢‘ä»»åŠ¡"""
        from app.utils.task_process import process_single_video_task
        
        data = task.data
        # è°ƒç”¨task_processä¸­çš„å¤„ç†é€»è¾‘
        return process_single_video_task(task.task_id, data)
        
    def _process_collection(self, task: Task) -> Any:
        """å¤„ç†åˆé›†ä»»åŠ¡"""
        from app.utils.task_process import process_collection_task
        
        data = task.data
        # è°ƒç”¨task_processä¸­çš„å¤„ç†é€»è¾‘
        return process_collection_task(task.task_id, data, self.add_task)

# å…¨å±€ä»»åŠ¡é˜Ÿåˆ—å®ä¾‹ï¼Œã€é‡è¦ã€‘æ‰€æœ‰æ¨¡å—éƒ½åº”é€šè¿‡ get_task_queue() è·å–å®ä¾‹
task_queue = get_task_queue() 