# app/routers/note.py
import json
import os
import traceback
import uuid
import time
import glob
import asyncio
from typing import Optional, Union, List, Tuple
from urllib.parse import urlparse

from fastapi import APIRouter, HTTPException, BackgroundTasks, UploadFile, File
from pydantic import BaseModel, validator, field_validator
from dataclasses import asdict

from app.db.video_task_dao import get_task_by_video
from app.enmus.note_enums import DownloadQuality
from app.services.note import NoteGenerator, logger, NoteService
from app.utils.response import ResponseWrapper as R
from app.utils.url_parser import extract_video_id, is_collection_url, extract_collection_videos_async, identify_platform
from app.utils.task_utils import save_original_request_data, load_original_request_data
from app.validators.video_url_validator import is_supported_video_url
from fastapi import APIRouter, Request, HTTPException
from fastapi.responses import StreamingResponse
import httpx
from app.enmus.task_status_enums import TaskStatus
from app.models.note_api import StandardResponse, SingleVideoResponse, CollectionResponse, TaskInfo
from app.core.task_queue import TaskType, TaskStatus as QueueTaskStatus, task_queue
from app.core.exception_handlers import wrap_request_handler, record_request_error
from app.utils.baidu_utils import delete_baidu_pan_file

router = APIRouter()


class RecordRequest(BaseModel):
    video_id: str
    platform: str


class VideoRequest(BaseModel):
    video_url: str
    platform: str
    quality: DownloadQuality
    screenshot: Optional[bool] = False
    link: Optional[bool] = False
    model_name: str
    provider_id: str
    task_id: Optional[str] = None
    format: Optional[list] = []
    style: str = None
    extras: Optional[str]=None
    video_understanding: Optional[bool] = False
    video_interval: Optional[int] = 0
    grid_size: Optional[list] = []
    is_collection: Optional[bool] = False
    max_collection_videos: Optional[int] = 400
    auto_save_notion: Optional[bool] = True
    auto_detect_collection: Optional[bool] = True  # æ–°å¢ï¼šè‡ªåŠ¨è¯†åˆ«åˆé›†å¼€å…³

    @field_validator("video_url")
    def validate_supported_url(cls, v):
        url = str(v)
        parsed = urlparse(url)
        if parsed.scheme in ("http", "https"):
            # æ˜¯ç½‘ç»œé“¾æ¥ï¼Œç»§ç»­ç”¨åŸæœ‰å¹³å°æ ¡éªŒ
            if not is_supported_video_url(url):
                raise ValueError("æš‚ä¸æ”¯æŒè¯¥è§†é¢‘å¹³å°æˆ–é“¾æ¥æ ¼å¼æ— æ•ˆ")

        return v


NOTE_OUTPUT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "..", "note_results"))
UPLOAD_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "..", "uploads"))


def save_note_to_file(task_id: str, note):
    os.makedirs(NOTE_OUTPUT_DIR, exist_ok=True)
    
    # å®‰å…¨å¤„ç†ä¸åŒç±»å‹çš„noteå¯¹è±¡
    try:
        if hasattr(note, '__dataclass_fields__'):
            # å¦‚æœæ˜¯dataclasså®ä¾‹ï¼Œä½¿ç”¨asdict
            note_data = asdict(note)
        elif isinstance(note, dict):
            # å¦‚æœå·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
            note_data = note
        else:
            # å…¶ä»–æƒ…å†µï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            note_data = {"data": str(note), "type": type(note).__name__}
        
        with open(os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json"), "w", encoding="utf-8") as f:
            json.dump(note_data, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        # å¦‚æœåºåˆ—åŒ–å¤±è´¥ï¼Œä¿å­˜é”™è¯¯ä¿¡æ¯
        error_data = {
            "error": f"åºåˆ—åŒ–å¤±è´¥: {str(e)}",
            "note_type": type(note).__name__,
            "task_id": task_id
        }
        with open(os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json"), "w", encoding="utf-8") as f:
            json.dump(error_data, f, ensure_ascii=False, indent=2)


def run_note_task(task_id: str, video_url: str, platform: str, quality: DownloadQuality,
                  link: bool = False, screenshot: bool = False, model_name: str = None, provider_id: str = None,
                  _format: list = None, style: str = None, extras: str = None, video_understanding: bool = False,
                  video_interval=0, grid_size=[]
                  ):
    try:
        if not model_name or not provider_id:
            raise HTTPException(status_code=400, detail="è¯·é€‰æ‹©æ¨¡å‹å’Œæä¾›è€…")

        note = NoteGenerator().generate(
            video_url=video_url,
            platform=platform,
            quality=quality,
            task_id=task_id,
            model_name=model_name,
            provider_id=provider_id,
            link=link,
            _format=_format,
            style=style,
            extras=extras,
            screenshot=screenshot
            , video_understanding=video_understanding,
            video_interval=video_interval,
            grid_size=grid_size
        )
        logger.info(f"Note generated: {task_id}")
        save_note_to_file(task_id, note)
    except Exception as e:
        save_note_to_file(task_id, {"error": str(e)})


@router.post('/delete_task')
def delete_task(data: RecordRequest):
    try:

        NoteGenerator().delete_note(video_id=data.video_id, platform=data.platform)
        return R.success(msg='åˆ é™¤æˆåŠŸ')
    except Exception as e:
        return R.error(msg=e)


@router.post("/upload")
async def upload(file: UploadFile = File(...)):
    os.makedirs(UPLOAD_DIR, exist_ok=True)
    file_location = os.path.join(UPLOAD_DIR, file.filename)

    with open(file_location, "wb+") as f:
        f.write(await file.read())

    # å‡è®¾ä½ é™æ€ç›®å½•æŒ‚è½½äº† /uploads
    return R.success({"url": f"/uploads/{file.filename}"})


@router.post("/generate_note")
async def generate_note(
    request: VideoRequest
) -> StandardResponse[Union[SingleVideoResponse, CollectionResponse]]:
    logger.info(f"ğŸ¬ æ”¶åˆ°ç”Ÿæˆç¬”è®°è¯·æ±‚: {request.video_url}")
    logger.info(f"ğŸ“Š è¯·æ±‚å‚æ•°: max_collection_videos={request.max_collection_videos}")
    
    try:
        # è¯†åˆ«è§†é¢‘å¹³å°
        platform = identify_platform(request.video_url)
        logger.info(f"ğŸ¯ è¯†åˆ«åˆ°å¹³å°: {platform}")
        
        if not platform:
            logger.error("âŒ ä¸æ”¯æŒçš„å¹³å°æˆ–æ— æ•ˆçš„URL")
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„å¹³å°æˆ–æ— æ•ˆçš„URL")

        # æ£€æµ‹æ˜¯å¦ä¸ºåˆé›†URLï¼ˆæ ¹æ®auto_detect_collectionå¼€å…³å†³å®šï¼‰
        is_collection = False
        if request.auto_detect_collection:
            is_collection = is_collection_url(request.video_url, platform)
            logger.info(f"ğŸ” åˆé›†æ£€æµ‹ç»“æœ: {is_collection} (è‡ªåŠ¨è¯†åˆ«å¼€å…³: å¼€)")
        else:
            logger.info(f"ğŸ” åˆé›†æ£€æµ‹è¢«è·³è¿‡ (è‡ªåŠ¨è¯†åˆ«å¼€å…³: å…³)")
        
        if is_collection:
            logger.info("ğŸ¬ è¿›å…¥åˆé›†å¤„ç†åˆ†æ”¯")
            return await handle_collection_generation(request, platform)
        else:
            logger.info("ğŸ“º è¿›å…¥å•è§†é¢‘å¤„ç†åˆ†æ”¯")
            return await handle_single_video_generation(request, platform)
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆç¬”è®°å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆç¬”è®°å¤±è´¥: {str(e)}")


async def handle_collection_generation(
    request: VideoRequest, 
    platform: str
) -> StandardResponse[CollectionResponse]:
    """å¤„ç†åˆé›†ç”Ÿæˆè¯·æ±‚"""
    logger.info(f"ğŸ¬ å¼€å§‹å¤„ç†åˆé›†: {request.video_url}")
    logger.info(f"ğŸ“Š åˆé›†å‚æ•°: platform={platform}, max_videos={request.max_collection_videos}")
    
    try:
        # å¯¹äºå…¶ä»–åˆé›†URLï¼Œå°è¯•å¿«é€Ÿæå–è§†é¢‘åˆ—è¡¨
        logger.info("ğŸ” [å¼‚æ­¥] å¿«é€Ÿæå–åˆé›†è§†é¢‘åˆ—è¡¨...")
        videos = None
        
        try:
            # ä½¿ç”¨æ–°çš„å¼‚æ­¥æå–å‡½æ•°ï¼Œå¹¶è®¾ç½®è¶…æ—¶
            videos = await asyncio.wait_for(
                extract_collection_videos_async(
                    request.video_url, 
                    platform, 
                    request.max_collection_videos
                ),
                timeout=25.0  # è®¾ç½®25ç§’è¶…æ—¶
            )
            
            if videos:
                logger.info(f"ğŸ“¹ [å¼‚æ­¥] å¿«é€Ÿæå–æˆåŠŸï¼Œå…± {len(videos)} ä¸ªè§†é¢‘")
                
                # ä¸ºæ¯ä¸ªè§†é¢‘åˆ›å»ºä»»åŠ¡
                task_list = []
                for video_url, title in videos:
                    task_data = {
                        'video_url': video_url,
                        'platform': platform,
                        'quality': request.quality,
                        'model_name': request.model_name,
                        'provider_id': request.provider_id,
                        'screenshot': request.screenshot,
                        'link': request.link,
                        'format': request.format,
                        'style': request.style,
                        'extras': request.extras,
                        'video_understanding': request.video_understanding,
                        'video_interval': request.video_interval,
                        'grid_size': request.grid_size,
                        'title': title
                    }
                    
                    task_id = task_queue.add_task(TaskType.SINGLE_VIDEO, task_data)
                    task_list.append(TaskInfo(
                        task_id=task_id,
                        video_url=video_url,
                        title=title
                    ))
                
                logger.info(f"âœ… å·²ä¸º {len(task_list)} ä¸ªè§†é¢‘åˆ›å»ºä»»åŠ¡")
                
                response_data = CollectionResponse(
                    is_collection=True,
                    total_videos=len(videos),
                    created_tasks=len(task_list),
                    task_list=task_list,
                    message=f"å·²æˆåŠŸä¸ºåˆé›†ä¸­çš„ {len(task_list)} ä¸ªè§†é¢‘åˆ›å»ºç¬”è®°ç”Ÿæˆä»»åŠ¡"
                )
                
                return StandardResponse(
                    success=True,
                    data=response_data,
                    message=f"åˆé›†å¤„ç†å®Œæˆï¼Œå…±åˆ›å»º {len(task_list)} ä¸ªä»»åŠ¡"
                )
                
        except asyncio.TimeoutError:
            logger.warning("âš ï¸ å¿«é€Ÿæå–è¶…æ—¶ (25ç§’)ï¼Œå°†å›é€€åˆ°åå°å¼‚æ­¥å¤„ç†ã€‚")
            # è¶…æ—¶å videos ä¼šæ˜¯ None, æµç¨‹å°†è‡ªç„¶è¿›å…¥ä¸‹é¢çš„å›é€€é€»è¾‘
        except Exception as e:
            logger.warning(f"âš ï¸ [å¼‚æ­¥] å¿«é€Ÿæå–å¤±è´¥: {e}", exc_info=True)
            # åŒæ ·å›é€€åˆ°åå°å¼‚æ­¥å¤„ç†
        
        # å¦‚æœå¿«é€Ÿæå–å¤±è´¥ã€è¶…æ—¶æˆ–æ²¡æœ‰è¿”å›è§†é¢‘ï¼Œåˆ™å›é€€åˆ°å¼‚æ­¥å¤„ç†
        logger.info("ğŸ”„ å›é€€åˆ°åå°å¼‚æ­¥å¤„ç†æ¨¡å¼ (åˆ›å»ºå•ä¸ªåˆé›†ä»»åŠ¡)")
        
        task_data = {
            'video_url': request.video_url,
            'platform': platform,
            'quality': request.quality,
            'model_name': request.model_name,
            'provider_id': request.provider_id,
            'screenshot': request.screenshot,
            'link': request.link,
            'format': request.format,
            'style': request.style,
            'extras': request.extras,
            'video_understanding': request.video_understanding,
            'video_interval': request.video_interval,
            'grid_size': request.grid_size,
            'max_collection_videos': request.max_collection_videos
        }
        
        collection_task_id = task_queue.add_task(TaskType.COLLECTION, task_data)
        logger.info(f"âœ… åˆé›†ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—: {collection_task_id}")
        
        response_data = CollectionResponse(
            is_collection=True,
            total_videos=0,
            created_tasks=0,
            task_list=[],
            message="åˆé›†è§†é¢‘åˆ—è¡¨è§£æè€—æ—¶è¾ƒé•¿ï¼Œå·²è½¬ä¸ºåå°ä»»åŠ¡å¤„ç†ï¼Œè¯·ç¨ååœ¨ä»»åŠ¡åˆ—è¡¨ä¸­æŸ¥çœ‹è¿›åº¦ã€‚"
        )
        
        return StandardResponse(
            success=True,
            data=response_data,
            message="åˆé›†å¤„ç†å·²è½¬ä¸ºåå°ä»»åŠ¡"
        )
        
    except Exception as e:
        logger.error(f"âŒ å¤„ç†åˆé›†å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¤„ç†åˆé›†å¤±è´¥: {str(e)}")


async def handle_single_video_generation(
    request: VideoRequest, 
    platform: str
) -> StandardResponse[SingleVideoResponse]:
    """å¤„ç†å•è§†é¢‘ç”Ÿæˆè¯·æ±‚"""
    logger.info(f"ğŸ“º å¼€å§‹å¤„ç†å•è§†é¢‘: {request.video_url}")
    logger.info(f"ğŸ“Š å•è§†é¢‘å‚æ•°: platform={platform}")
    
    try:
        # å‡†å¤‡ä»»åŠ¡æ•°æ®
        task_data = {
            'video_url': request.video_url,
            'platform': platform,
            'quality': request.quality,
            'model_name': request.model_name,
            'provider_id': request.provider_id,
            'screenshot': request.screenshot,
            'link': request.link,
            'format': request.format,
            'style': request.style,
            'extras': request.extras,
            'video_understanding': request.video_understanding,
            'video_interval': request.video_interval,
            'grid_size': request.grid_size
        }
        
        # æ·»åŠ å•è§†é¢‘ä»»åŠ¡åˆ°é˜Ÿåˆ—
        task_id = task_queue.add_task(TaskType.SINGLE_VIDEO, task_data)
        logger.info(f"âœ… å•è§†é¢‘ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—: {task_id}")
        
        # è¿”å›å•è§†é¢‘å¤„ç†ç»“æœ
        response_data = SingleVideoResponse(
            is_collection=False,
            task_id=task_id
        )
        
        return StandardResponse(
            success=True,
            data=response_data,
            message="ç¬”è®°ç”Ÿæˆä»»åŠ¡å·²åˆ›å»º"
        )
        
    except Exception as e:
        logger.error(f"âŒ å¤„ç†å•è§†é¢‘å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†å•è§†é¢‘å¤±è´¥: {str(e)}")


@router.get("/task_status/{task_id}")
def get_task_status(task_id: str):
    # é¦–å…ˆæ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—ä¸­çš„çŠ¶æ€
    queue_task = task_queue.get_task_status(task_id)
    if queue_task:
        # åˆ é™¤é¢‘ç¹çš„çŠ¶æ€æŸ¥è¯¢æ—¥å¿—ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
        # logger.info(f"ğŸ” ä»ä»»åŠ¡é˜Ÿåˆ—è·å–çŠ¶æ€: {task_id} -> {queue_task.status.value}")
        
        # æ˜ å°„ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€åˆ°åŸæœ‰çŠ¶æ€
        status_mapping = {
            QueueTaskStatus.PENDING: TaskStatus.PENDING.value,
            QueueTaskStatus.RUNNING: TaskStatus.RUNNING.value,
            QueueTaskStatus.SUCCESS: TaskStatus.SUCCESS.value,
            QueueTaskStatus.FAILED: TaskStatus.FAILED.value
        }
        
        mapped_status = status_mapping.get(queue_task.status, TaskStatus.PENDING.value)
        
        if queue_task.status == QueueTaskStatus.FAILED:
            return R.error(queue_task.error_message or "ä»»åŠ¡å¤±è´¥", code=500)
        elif queue_task.status == QueueTaskStatus.SUCCESS:
            # ä»»åŠ¡æˆåŠŸï¼Œå°è¯•è¯»å–ç»“æœæ–‡ä»¶
            result_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json")
            if os.path.exists(result_path):
                with open(result_path, "r", encoding="utf-8") as f:
                    result_content = json.load(f)
                return R.success({
                    "status": mapped_status,
                    "result": result_content,
                    "message": "ä»»åŠ¡å®Œæˆ",
                    "task_id": task_id
                })
            else:
                return R.success({
                    "status": TaskStatus.PENDING.value,
                    "message": "ä»»åŠ¡å®Œæˆï¼Œä½†ç»“æœæ–‡ä»¶æœªæ‰¾åˆ°",
                    "task_id": task_id
                })
        else:
            # PENDING æˆ– RUNNING çŠ¶æ€
            message = "ä»»åŠ¡æ’é˜Ÿä¸­" if queue_task.status == QueueTaskStatus.PENDING else "ä»»åŠ¡å¤„ç†ä¸­"
            return R.success({
                "status": mapped_status,
                "message": message,
                "task_id": task_id
            })
    
    # ä»»åŠ¡é˜Ÿåˆ—ä¸­æ‰¾ä¸åˆ°ï¼Œæ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿ
    status_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.status.json")
    result_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json")

    # ä¼˜å…ˆè¯»çŠ¶æ€æ–‡ä»¶
    if os.path.exists(status_path):
        with open(status_path, "r", encoding="utf-8") as f:
            status_content = json.load(f)

        status = status_content.get("status")
        message = status_content.get("message", "")

        if status == TaskStatus.SUCCESS.value:
            # æˆåŠŸçŠ¶æ€çš„è¯ï¼Œç»§ç»­è¯»å–æœ€ç»ˆç¬”è®°å†…å®¹
            if os.path.exists(result_path):
                with open(result_path, "r", encoding="utf-8") as rf:
                    result_content = json.load(rf)
                return R.success({
                    "status": status,
                    "result": result_content,
                    "message": message,
                    "task_id": task_id
                })
            else:
                # ç†è®ºä¸Šä¸ä¼šå‡ºç°ï¼Œä¿é™©å¤„ç†
                return R.success({
                    "status": TaskStatus.PENDING.value,
                    "message": "ä»»åŠ¡å®Œæˆï¼Œä½†ç»“æœæ–‡ä»¶æœªæ‰¾åˆ°",
                    "task_id": task_id
                })

        if status == TaskStatus.FAILED.value:
            return R.error(message or "ä»»åŠ¡å¤±è´¥", code=500)

        # å¤„ç†ä¸­çŠ¶æ€
        return R.success({
            "status": status,
            "message": message,
            "task_id": task_id
        })

    # æ²¡æœ‰çŠ¶æ€æ–‡ä»¶ï¼Œä½†æœ‰ç»“æœ
    if os.path.exists(result_path):
        with open(result_path, "r", encoding="utf-8") as f:
            result_content = json.load(f)
        return R.success({
            "status": TaskStatus.SUCCESS.value,
            "result": result_content,
            "task_id": task_id
        })

    # ä»€ä¹ˆéƒ½æ²¡æœ‰ï¼Œé»˜è®¤PENDING
    return R.success({
        "status": TaskStatus.PENDING.value,
        "message": "ä»»åŠ¡æ’é˜Ÿä¸­",
        "task_id": task_id
    })


@router.get("/image_proxy")
async def image_proxy(request: Request, url: str):
    headers = {
        "Referer": "https://www.bilibili.com/",
        "User-Agent": request.headers.get("User-Agent", ""),
    }

    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            resp = await client.get(url, headers=headers)

            if resp.status_code != 200:
                raise HTTPException(status_code=resp.status_code, detail="å›¾ç‰‡è·å–å¤±è´¥")

            content_type = resp.headers.get("Content-Type", "image/jpeg")
            return StreamingResponse(
                resp.aiter_bytes(),
                media_type=content_type,
                headers={
                    "Cache-Control": "public, max-age=86400",  # âœ… ç¼“å­˜ä¸€å¤©
                    "Content-Type": content_type,
                }
            )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ä»»åŠ¡å¤„ç†é€»è¾‘å·²ç§»è‡³ app/core/task_queue.py ä¸­çš„ TaskQueue ç±»

@router.get("/queue_status")
def get_queue_status():
    """è·å–ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€"""
    try:
        all_tasks = task_queue.get_all_tasks()
        
        queue_info = {
            "total_tasks": len(all_tasks),
            "pending_tasks": len([t for t in all_tasks.values() if t.status == QueueTaskStatus.PENDING]),
            "running_tasks": len([t for t in all_tasks.values() if t.status == QueueTaskStatus.RUNNING]),
            "completed_tasks": len([t for t in all_tasks.values() if t.status == QueueTaskStatus.SUCCESS]),
            "failed_tasks": len([t for t in all_tasks.values() if t.status == QueueTaskStatus.FAILED]),
            "tasks": []
        }
        
        # è¿”å›ä»»åŠ¡è¯¦æƒ…
        for task in all_tasks.values():
            task_info = {
                "task_id": task.task_id,
                "task_type": task.task_type.value,
                "status": task.status.value,
                "created_at": task.created_at,
                "started_at": task.started_at,
                "completed_at": task.completed_at,
                "video_url": task.data.get('video_url', ''),
                "title": task.data.get('title', 'æœªçŸ¥æ ‡é¢˜'),
                "error_message": task.error_message
            }
            queue_info["tasks"].append(task_info)
        
        return R.success(queue_info)
        
    except Exception as e:
        logger.error(f"âŒ è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {e}")
        return R.error(f"è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {str(e)}")

@router.get("/tasks/recent")
def get_recent_tasks(limit: int = 50):
    """è·å–æœ€è¿‘çš„ä»»åŠ¡åˆ—è¡¨ï¼ˆç”¨äºå‰ç«¯ä»»åŠ¡åˆ—è¡¨æ˜¾ç¤ºï¼‰"""
    try:
        all_tasks = task_queue.get_all_tasks()
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        sorted_tasks = sorted(all_tasks.values(), key=lambda x: x.created_at or 0, reverse=True)
        
        task_list = []
        for task in sorted_tasks[:limit]:
            # æ˜ å°„é˜Ÿåˆ—çŠ¶æ€åˆ°å‰ç«¯çŠ¶æ€
            frontend_status = "PENDING"
            if task.status == QueueTaskStatus.RUNNING:
                frontend_status = "RUNNING"
            elif task.status == QueueTaskStatus.SUCCESS:
                frontend_status = "SUCCESS"
            elif task.status == QueueTaskStatus.FAILED:
                frontend_status = "FAILED"
            
            task_info = {
                "task_id": task.task_id,
                "video_url": task.data.get('video_url', ''),
                "title": task.data.get('title', 'æœªçŸ¥æ ‡é¢˜'),
                "platform": task.data.get('platform', ''),
                "status": frontend_status,
                "created_at": task.created_at,
                "error_message": task.error_message
            }
            task_list.append(task_info)
        
        return R.success({
            "tasks": task_list,
            "total": len(sorted_tasks)
        })
        
    except Exception as e:
        logger.error(f"âŒ è·å–æœ€è¿‘ä»»åŠ¡å¤±è´¥: {e}")
        return R.error(f"è·å–æœ€è¿‘ä»»åŠ¡å¤±è´¥: {str(e)}")

@router.post("/retry_task/{task_id}")
def retry_task(task_id: str):
    """é‡è¯•å¤±è´¥çš„ä»»åŠ¡"""
    try:
        # é¦–å…ˆæ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—ä¸­æ˜¯å¦å­˜åœ¨è¯¥ä»»åŠ¡
        queue_task = task_queue.get_task_status(task_id)
        if queue_task:
            # åœ¨ä»»åŠ¡é˜Ÿåˆ—ä¸­é‡è¯•
            success = task_queue.retry_task(task_id)
            if success:
                logger.info(f"âœ… ä»»åŠ¡é‡è¯•æˆåŠŸ: {task_id}")
                return R.success({
                    "message": "ä»»åŠ¡å·²é‡æ–°æäº¤ï¼Œè¯·ç­‰å¾…å¤„ç†",
                    "task_id": task_id
                })
            else:
                return R.error("ä»»åŠ¡é‡è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»»åŠ¡çŠ¶æ€")
        
        # ä»»åŠ¡é˜Ÿåˆ—ä¸­æ²¡æœ‰ï¼Œæ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿä¸­çš„ä»»åŠ¡
        status_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.status.json")
        if os.path.exists(status_path):
            with open(status_path, "r", encoding="utf-8") as f:
                status_content = json.load(f)
            
            status = status_content.get("status")
            if status == TaskStatus.FAILED.value:
                # ä»æ–‡ä»¶ç³»ç»Ÿä¸­è¯»å–åŸå§‹ä»»åŠ¡æ•°æ®å¹¶é‡æ–°æäº¤
                # è¿™éœ€è¦æœ‰å­˜å‚¨åŸå§‹è¯·æ±‚å‚æ•°çš„æœºåˆ¶
                logger.warning(f"âš ï¸ ä»»åŠ¡ {task_id} åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­ï¼Œä½†æ— æ³•ç›´æ¥é‡è¯•ã€‚å»ºè®®é‡æ–°æäº¤æ–°ä»»åŠ¡ã€‚")
                return R.error("è¯¥ä»»åŠ¡æ— æ³•ç›´æ¥é‡è¯•ï¼Œè¯·é‡æ–°æäº¤æ–°ä»»åŠ¡")
            else:
                return R.error(f"ä»»åŠ¡çŠ¶æ€ä¸æ˜¯å¤±è´¥çŠ¶æ€ï¼Œæ— æ³•é‡è¯• (å½“å‰çŠ¶æ€: {status})")
        
        return R.error("ä»»åŠ¡ä¸å­˜åœ¨")
        
    except Exception as e:
        logger.error(f"âŒ é‡è¯•ä»»åŠ¡å¤±è´¥: {e}")
        return R.error(f"é‡è¯•ä»»åŠ¡å¤±è´¥: {str(e)}")

@router.post("/batch_retry_failed")
def batch_retry_failed_tasks():
    """æ‰¹é‡é‡è¯•æ‰€æœ‰å¤±è´¥çš„ä»»åŠ¡"""
    try:
        result = task_queue.batch_retry_failed_tasks()
        logger.info(f"âœ… æ‰¹é‡é‡è¯•å¤±è´¥ä»»åŠ¡å®Œæˆ: {result}")
        
        if result["retried_count"] > 0:
            return R.success({
                "retried_count": result["retried_count"],
                "total_failed": result["total_failed"],
                "message": result["message"]
            })
        else:
            return R.success({
                "retried_count": 0,
                "total_failed": 0,
                "message": "æ²¡æœ‰éœ€è¦é‡è¯•çš„å¤±è´¥ä»»åŠ¡"
            })
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡é‡è¯•å¤±è´¥ä»»åŠ¡å‡ºé”™: {e}")
        return R.error(f"æ‰¹é‡é‡è¯•å¤±è´¥: {str(e)}")

@router.post("/batch_retry_non_success")
def batch_retry_non_success_tasks():
    """æ‰¹é‡é‡è¯•æ‰€æœ‰éæˆåŠŸçŠ¶æ€çš„ä»»åŠ¡ï¼ˆåŒ…æ‹¬PENDINGã€RUNNINGã€FAILEDï¼‰"""
    try:
        # é¦–å…ˆå°è¯•é‡è¯•é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        queue_result = task_queue.batch_retry_non_success_tasks()
        logger.info(f"âœ… é˜Ÿåˆ—æ‰¹é‡é‡è¯•å®Œæˆ: {queue_result}")
        
        # å¦‚æœé˜Ÿåˆ—ä¸­æ²¡æœ‰éœ€è¦é‡è¯•çš„ä»»åŠ¡ï¼Œå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿé‡å»º
        if queue_result["retried_count"] == 0:
            logger.info("ğŸ” é˜Ÿåˆ—ä¸ºç©ºï¼Œå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿé‡å»ºéœ€è¦é‡è¯•çš„ä»»åŠ¡")
            
            # æ‰«ææ‰€æœ‰çŠ¶æ€æ–‡ä»¶ï¼ŒæŸ¥æ‰¾å¤±è´¥çš„ä»»åŠ¡
            rebuilt_count = 0
            status_files = glob.glob(os.path.join(NOTE_OUTPUT_DIR, "*.status.json"))
            
            for status_file in status_files:
                try:
                    task_id = os.path.basename(status_file).replace(".status.json", "")
                    
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²åœ¨é˜Ÿåˆ—ä¸­
                    if task_queue.get_task_status(task_id):
                        continue
                    
                    with open(status_file, "r", encoding="utf-8") as f:
                        status_content = json.load(f)
                    
                    status = status_content.get("status")
                    if status and status != TaskStatus.SUCCESS.value:
                        # å°è¯•é‡å»ºä»»åŠ¡
                        success = rebuild_task_from_files(task_id)
                        if success:
                            rebuilt_count += 1
                            logger.info(f"âœ… æˆåŠŸé‡å»ºä»»åŠ¡: {task_id}")
                        else:
                            logger.warning(f"âš ï¸ é‡å»ºä»»åŠ¡å¤±è´¥: {task_id}")
                            
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†çŠ¶æ€æ–‡ä»¶å¤±è´¥ {status_file}: {e}")
            
            if rebuilt_count > 0:
                logger.info(f"ğŸ”„ ä»æ–‡ä»¶ç³»ç»Ÿé‡å»ºäº† {rebuilt_count} ä¸ªä»»åŠ¡")
                return R.success({
                    "retried_count": rebuilt_count,
                    "total_non_success": rebuilt_count,
                    "rebuilt_from_files": True,
                    "message": f"ä»æ–‡ä»¶ç³»ç»Ÿé‡å»ºå¹¶é‡è¯•äº† {rebuilt_count} ä¸ªä»»åŠ¡"
                })
        
        # è¿”å›åŸå§‹é˜Ÿåˆ—é‡è¯•ç»“æœ
        if queue_result["retried_count"] > 0:
            return R.success({
                "retried_count": queue_result["retried_count"],
                "total_non_success": queue_result["total_non_success"],
                "pending_count": queue_result["pending_count"],
                "running_count": queue_result["running_count"],
                "failed_count": queue_result["failed_count"],
                "message": queue_result["message"]
            })
        else:
            return R.success({
                "retried_count": 0,
                "total_non_success": 0,
                "message": "æ²¡æœ‰éœ€è¦é‡è¯•çš„éæˆåŠŸä»»åŠ¡"
            })
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡é‡è¯•éæˆåŠŸä»»åŠ¡å‡ºé”™: {e}")
        return R.error(f"æ‰¹é‡é‡è¯•éæˆåŠŸä»»åŠ¡å¤±è´¥: {str(e)}")

def rebuild_task_from_files(task_id: str) -> bool:
    """ä»æ–‡ä»¶ç³»ç»Ÿé‡å»ºä»»åŠ¡"""
    try:
        from app.core.task_queue import TaskType
        from app.enmus.note_enums import DownloadQuality
        
        # æ£€æŸ¥éŸ³é¢‘metadataæ–‡ä»¶ï¼ˆåˆ†ç¦»æ–‡ä»¶æ¨¡å¼ï¼‰
        audio_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}_audio.json")
        result_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json")
        
        # é¦–å…ˆå°è¯•ä»éŸ³é¢‘metadataæ–‡ä»¶è·å–ä¿¡æ¯
        if os.path.exists(audio_path):
            try:
                with open(audio_path, "r", encoding="utf-8") as f:
                    audio_data = json.load(f)
                
                video_url = audio_data.get("file_path", "")
                platform = audio_data.get("platform", "")
                title = audio_data.get("title", "æœªçŸ¥æ ‡é¢˜")
                
                if video_url and platform:
                    try:
                        task_data = {
                            'video_url': video_url,
                            'platform': platform,
                            'quality': DownloadQuality.fast,
                            'model_name': 'gpt-4o-mini',
                            'provider_id': 'openai',
                            'screenshot': False,
                            'link': False,
                            'format': [],
                            'style': 'ç®€æ´',
                            'extras': None,
                            'video_understanding': False,
                            'video_interval': 0,
                            'grid_size': [],
                            'title': title
                        }
                        
                        task_queue.add_task(
                            task_type=TaskType.SINGLE_VIDEO, 
                            data=task_data,
                            task_id=task_id
                        )
                        return True
                    except Exception as task_error:
                        logger.error(f"âŒ ä»éŸ³é¢‘metadataåˆ›å»ºä»»åŠ¡å¤±è´¥: {task_id}, {task_error}")
                        # åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•æ¸…ç©ºé‡ç½®
                        return clear_and_reset_task(task_id)
                    
            except Exception as e:
                logger.error(f"âŒ ä»éŸ³é¢‘metadataé‡å»ºä»»åŠ¡å¤±è´¥: {task_id}, {e}")
                # è¯»å–éŸ³é¢‘metadataæ–‡ä»¶å¤±è´¥ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
                logger.info(f"ğŸ”„ éŸ³é¢‘metadataæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                return clear_and_reset_task(task_id)
        
        # å¦‚æœéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä»ä¸»ç»“æœæ–‡ä»¶è¯»å–
        if os.path.exists(result_path):
            try:
                with open(result_path, "r", encoding="utf-8") as f:
                    result_data = json.load(f)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºé”™è¯¯æ–‡ä»¶
                if "error" in result_data:
                    logger.warning(f"âš ï¸ å‘ç°é”™è¯¯æ–‡ä»¶ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                    return clear_and_reset_task(task_id, result_data)
                
                if "audioMeta" in result_data:
                    audio_meta = result_data.get("audioMeta", {})
                    video_url = audio_meta.get("file_path", "")
                    platform = audio_meta.get("platform", "")
                    title = audio_meta.get("title", "æœªçŸ¥æ ‡é¢˜")
                    
                    if video_url and platform:
                        try:
                            task_data = {
                                'video_url': video_url,
                                'platform': platform,
                                'quality': DownloadQuality.fast,
                                'model_name': 'gpt-4o-mini',
                                'provider_id': 'openai',
                                'screenshot': False,
                                'link': False,
                                'format': [],
                                'style': 'ç®€æ´',
                                'extras': None,
                                'video_understanding': False,
                                'video_interval': 0,
                                'grid_size': [],
                                'title': title
                            }
                            
                            task_queue.add_task(
                                task_type=TaskType.SINGLE_VIDEO, 
                                data=task_data,
                                task_id=task_id
                            )
                            return True
                        except Exception as task_error:
                            logger.error(f"âŒ ä»ç»“æœæ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥: {task_id}, {task_error}")
                            # åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•æ¸…ç©ºé‡ç½®
                            return clear_and_reset_task(task_id, result_data)
                else:
                    # ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
                    logger.warning(f"âš ï¸ ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®: {task_id}")
                    logger.info(f"ğŸ”„ ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                    return clear_and_reset_task(task_id, result_data)
                        
            except Exception as e:
                logger.error(f"âŒ ä»ç»“æœæ–‡ä»¶é‡å»ºä»»åŠ¡å¤±è´¥: {task_id}, {e}")
                # è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
                logger.info(f"ğŸ”„ ç»“æœæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                return clear_and_reset_task(task_id)
        else:
            # æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶: {task_id}")
            logger.info(f"ğŸ”„ æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
            return clear_and_reset_task(task_id)
        
        # å¦‚æœéƒ½æ— æ³•é‡å»ºï¼Œå°è¯•æ¸…ç©ºé‡ç½®
        logger.warning(f"âš ï¸ æ— æ³•é‡å»ºä»»åŠ¡ï¼Œå°è¯•æ¸…ç©ºé‡ç½®: {task_id}")
        return clear_and_reset_task(task_id)
        
    except Exception as e:
        logger.error(f"âŒ é‡å»ºä»»åŠ¡å‡ºé”™: {task_id}, {e}")
        return False

def clear_and_reset_task(task_id: str, error_data: dict = None) -> bool:
    """æ¸…ç©ºä»»åŠ¡ç›¸å…³æ–‡ä»¶å¹¶å°è¯•é‡ç½®ä»»åŠ¡"""
    try:
        from app.core.task_queue import TaskType
        from app.enmus.note_enums import DownloadQuality
        
        logger.info(f"ğŸ§¹ å¼€å§‹æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
        
        # å°è¯•ä»å¤šä¸ªæ¥æºæå–åŸå§‹ä¿¡æ¯
        original_url = None
        original_platform = None
        original_title = "é‡ç½®ä»»åŠ¡"
        
        # 1. ä¼˜å…ˆä»æŒä¹…åŒ–çš„åŸå§‹è¯·æ±‚æ•°æ®ä¸­æå–
        request_file_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.request.json")
        if os.path.exists(request_file_path):
            try:
                with open(request_file_path, "r", encoding="utf-8") as f:
                    request_data = json.load(f)
                
                original_request = request_data.get("original_request", {})
                if original_request:
                    original_url = original_request.get("video_url")
                    original_platform = original_request.get("platform")
                    original_title = original_request.get("title", "é‡ç½®ä»»åŠ¡")
                    
                    if original_url:
                        logger.info(f"âœ… ä»æŒä¹…åŒ–è¯·æ±‚æ•°æ®ä¸­æ‰¾åˆ°åŸå§‹URL: {original_url}")
                        
            except Exception as e:
                logger.warning(f"âš ï¸ è¯»å–æŒä¹…åŒ–è¯·æ±‚æ•°æ®å¤±è´¥: {e}")
        
        # 2. å¦‚æœæŒä¹…åŒ–æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»é”™è¯¯æ•°æ®ä¸­æå–
        if not original_url and error_data and isinstance(error_data, dict):
            # å°è¯•ä»é”™è¯¯ä¿¡æ¯ä¸­æå–åŸå§‹URL
            if "url" in error_data:
                original_url = error_data["url"]
            elif "video_url" in error_data:
                original_url = error_data["video_url"]
            elif "request_data" in error_data:
                request_data = error_data["request_data"]
                if isinstance(request_data, dict):
                    original_url = request_data.get("video_url")
                    original_platform = request_data.get("platform")
                    original_title = request_data.get("title", "é‡ç½®ä»»åŠ¡")
            # å°è¯•ä»audioMetaä¸­æå–
            elif "audioMeta" in error_data:
                audio_meta = error_data["audioMeta"]
                if isinstance(audio_meta, dict):
                    file_path = audio_meta.get("file_path", "")
                    video_id = audio_meta.get("video_id", "")
                    original_platform = audio_meta.get("platform", "")
                    original_title = audio_meta.get("title", "é‡ç½®ä»»åŠ¡")
                    
                    # å¦‚æœæ˜¯BVå·ï¼Œè½¬æ¢ä¸ºBç«™URL
                    if video_id and video_id.startswith("BV"):
                        original_url = f"https://www.bilibili.com/video/{video_id}"
                        original_platform = "bilibili"
                    elif file_path and "http" in file_path:
                        original_url = file_path
        
        # 3. å¦‚æœé”™è¯¯æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»ä»»åŠ¡çŠ¶æ€æ–‡ä»¶ä¸­æå–
        if not original_url:
            status_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.status.json")
            if os.path.exists(status_path):
                try:
                    with open(status_path, "r", encoding="utf-8") as f:
                        status_data = json.load(f)
                    
                    # ä»çŠ¶æ€æ–‡ä»¶ä¸­æå–åŸå§‹ä¿¡æ¯
                    if "original_request" in status_data:
                        orig_req = status_data["original_request"]
                        original_url = orig_req.get("video_url")
                        original_platform = orig_req.get("platform")
                        original_title = orig_req.get("title", "é‡ç½®ä»»åŠ¡")
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
        
        # 4. å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»éŸ³é¢‘metadataæ–‡ä»¶ä¸­æå–
        if not original_url:
            audio_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}_audio.json")
            if os.path.exists(audio_path):
                try:
                    with open(audio_path, "r", encoding="utf-8") as f:
                        audio_data = json.load(f)
                    
                    file_path = audio_data.get("file_path", "")
                    video_id = audio_data.get("video_id", "")
                    original_platform = audio_data.get("platform", "")
                    original_title = audio_data.get("title", "é‡ç½®ä»»åŠ¡")
                    raw_info = audio_data.get("raw_info", {})
                    
                    # ä¼˜å…ˆæ£€æŸ¥ raw_info ä¸­æ˜¯å¦æœ‰åŸå§‹URLä¿¡æ¯
                    if raw_info and isinstance(raw_info, dict):
                        if "webpage_url" in raw_info:
                            original_url = raw_info["webpage_url"]
                            logger.info(f"ğŸ” ä»raw_infoä¸­æ‰¾åˆ°åŸå§‹URL: {original_url}")
                        elif "original_url" in raw_info:
                            original_url = raw_info["original_url"]
                            logger.info(f"ğŸ” ä»raw_infoä¸­æ‰¾åˆ°åŸå§‹URL: {original_url}")
                    
                    # å¦‚æœ raw_info ä¸­æ²¡æœ‰ï¼Œå°è¯•ç”¨ video_id é‡æ„
                    if not original_url and video_id:
                        if video_id.startswith("BV"):
                            # æ£€æŸ¥ video_id ä¸­æ˜¯å¦åŒ…å«åˆ†Pä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼šBV1pwj2zxEL9_p64ï¼‰
                            if "_p" in video_id:
                                base_bv, p_part = video_id.split("_p", 1)
                                try:
                                    p_num = int(p_part)
                                    original_url = f"https://www.bilibili.com/video/{base_bv}?p={p_num}"
                                    logger.info(f"ğŸ”„ é‡æ„åˆ†Pè§†é¢‘URL: {video_id} -> {original_url}")
                                except ValueError:
                                    # åˆ†Pç¼–å·æ— æ•ˆï¼Œä½¿ç”¨åŸºç¡€BVå·
                                    original_url = f"https://www.bilibili.com/video/{base_bv}"
                                    logger.info(f"ğŸ”„ é‡æ„è§†é¢‘URL (å¿½ç•¥æ— æ•ˆåˆ†P): {video_id} -> {original_url}")
                            else:
                                # æ™®é€šBVå·
                                original_url = f"https://www.bilibili.com/video/{video_id}"
                                logger.info(f"ğŸ”„ é‡æ„è§†é¢‘URL: {video_id} -> {original_url}")
                            original_platform = "bilibili"
                        else:
                            logger.warning(f"âš ï¸ æ— æ³•è¯†åˆ«çš„video_idæ ¼å¼: {video_id}")
                    
                    # æœ€åæ£€æŸ¥file_pathæ˜¯å¦åŒ…å«HTTP URLï¼ˆç”¨äºå…¶ä»–å¹³å°ï¼‰
                    if not original_url and file_path and "http" in file_path:
                        original_url = file_path
                        logger.info(f"ğŸ”„ ä½¿ç”¨file_pathä½œä¸ºURL: {file_path}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–éŸ³é¢‘metadataæ–‡ä»¶å¤±è´¥: {e}")
        
        # æ¸…ç©ºç›¸å…³æ–‡ä»¶ï¼ˆä¿ç•™åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶ï¼‰
        files_to_clean = [
            f"{task_id}.json",          # ç»“æœæ–‡ä»¶
            f"{task_id}.status.json",   # çŠ¶æ€æ–‡ä»¶
            # f"{task_id}.request.json",  # ğŸ”’ ä¿ç•™åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶ï¼Œä¸åˆ é™¤
            f"{task_id}_audio.json",    # éŸ³é¢‘metadataæ–‡ä»¶
            f"{task_id}_audio.wav",     # éŸ³é¢‘æ–‡ä»¶
            f"{task_id}_audio.mp3",     # éŸ³é¢‘æ–‡ä»¶
            f"{task_id}.wav",           # éŸ³é¢‘æ–‡ä»¶
            f"{task_id}.mp3",           # éŸ³é¢‘æ–‡ä»¶
        ]
        
        cleaned_files = []
        for filename in files_to_clean:
            file_path = os.path.join(NOTE_OUTPUT_DIR, filename)
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    cleaned_files.append(filename)
                    logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤æ–‡ä»¶: {filename}")
                except Exception as e:
                    logger.warning(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥ {filename}: {e}")
        
        logger.info(f"ğŸ§¹ æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {len(cleaned_files)} ä¸ªæ–‡ä»¶")
        
        # å¦‚æœæ‰¾åˆ°äº†åŸå§‹URLï¼Œé‡æ–°åˆ›å»ºä»»åŠ¡
        if original_url:
            # å°è¯•è¯†åˆ«å¹³å°
            if not original_platform:
                if "bilibili.com" in original_url or "b23.tv" in original_url:
                    original_platform = "bilibili"
                elif "youtube.com" in original_url or "youtu.be" in original_url:
                    original_platform = "youtube"
                else:
                    original_platform = "unknown"
            
            logger.info(f"ğŸ”„ ä½¿ç”¨åŸå§‹URLé‡æ–°åˆ›å»ºä»»åŠ¡: {original_url}")
            
            try:
                task_data = {
                    'video_url': original_url,
                    'platform': original_platform,
                    'quality': DownloadQuality.fast,
                    'model_name': 'gpt-4o-mini',
                    'provider_id': 'openai',
                    'screenshot': False,
                    'link': False,
                    'format': [],
                    'style': 'ç®€æ´',
                    'extras': None,
                    'video_understanding': False,
                    'video_interval': 0,
                    'grid_size': [],
                    'title': original_title
                }
                
                # ä½¿ç”¨åŸtask_idé‡æ–°åˆ›å»ºä»»åŠ¡
                new_task_id = task_queue.add_task(
                    task_type=TaskType.SINGLE_VIDEO, 
                    data=task_data,
                    task_id=task_id
                )
                
                logger.info(f"âœ… ä»»åŠ¡é˜Ÿåˆ—æ·»åŠ æˆåŠŸ: {task_id}")
                
                # æ›´æ–°åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶ï¼ˆä¿å­˜æ–°çš„ä»»åŠ¡æ•°æ®ï¼‰
                try:
                    updated_request_data = {
                        "task_id": task_id,
                        "created_at": time.time(),
                        "created_at_iso": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
                        "reset_count": 1,  # æ ‡è®°è¿™æ˜¯é‡ç½®ä»»åŠ¡
                        "original_request": {
                            "video_url": original_url,
                            "platform": original_platform,
                            "title": original_title,
                            "quality": task_data.get('quality', DownloadQuality.fast),
                            "model_name": task_data.get('model_name', 'gpt-4o-mini'),
                            "provider_id": task_data.get('provider_id', 'openai'),
                            "screenshot": task_data.get('screenshot', False),
                            "link": task_data.get('link', False),
                            "format": task_data.get('format', []),
                            "style": task_data.get('style', 'ç®€æ´'),
                            "extras": task_data.get('extras', None),
                            "video_understanding": task_data.get('video_understanding', False),
                            "video_interval": task_data.get('video_interval', 0),
                            "grid_size": task_data.get('grid_size', [])
                        }
                    }
                    
                    request_file_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.request.json")
                    with open(request_file_path, "w", encoding="utf-8") as f:
                        json.dump(updated_request_data, f, ensure_ascii=False, indent=2)
                    
                    logger.info(f"ğŸ“ å·²æ›´æ–°åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶: {task_id}")
                    
                except Exception as save_error:
                    logger.warning(f"âš ï¸ æ›´æ–°åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶å¤±è´¥: {save_error}")
                
                logger.info(f"âœ… ä»»åŠ¡æ¸…ç©ºé‡ç½®æˆåŠŸ: {task_id} -> æ–°URL: {original_url}")
                return True
                
            except Exception as task_create_error:
                logger.error(f"âŒ åˆ›å»ºä»»åŠ¡ç¥å¥‡çš„å¤±è´¥: {task_id}, {task_create_error}, {traceback.format_exc()}")
                logger.warning(f"âš ï¸ ä»»åŠ¡åˆ›å»ºå¤±è´¥ä½†æ–‡ä»¶å·²æ¸…ç©ºï¼Œç»§ç»­å¤„ç†: {task_id}")
                # ä»»åŠ¡åˆ›å»ºå¤±è´¥ï¼Œä½†æ–‡ä»¶æ¸…ç©ºæˆåŠŸï¼Œä¹Ÿè®¤ä¸ºæ˜¯éƒ¨åˆ†æˆåŠŸ
                return len(cleaned_files) > 0
        else:
            logger.warning(f"âš ï¸ æ— æ³•æ‰¾åˆ°åŸå§‹URLï¼Œåªèƒ½æ¸…ç©ºæ–‡ä»¶: {task_id}ï¼Œ {error_data}")
            # å³ä½¿æ— æ³•é‡æ–°åˆ›å»ºï¼Œæ¸…ç©ºæ–‡ä»¶ä¹Ÿç®—æˆåŠŸ
            return len(cleaned_files) > 0
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç©ºé‡ç½®ä»»åŠ¡å¤±è´¥: {task_id}, {e}")
        return False

class ValidateTasksRequest(BaseModel):
    """éªŒè¯ä»»åŠ¡è¯·æ±‚æ¨¡å‹"""
    task_ids: List[str]

@router.post("/validate_tasks")
def validate_tasks(request: ValidateTasksRequest):
    """éªŒè¯å‰ç«¯ä»»åŠ¡IDåˆ—è¡¨ï¼Œè¿”å›çœŸæ­£éœ€è¦é‡è¯•çš„ä»»åŠ¡çŠ¶æ€"""
    try:
        task_ids = request.task_ids
        validation_results = []
        
        for task_id in task_ids:
            # æ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—ä¸­çš„çŠ¶æ€
            queue_task = task_queue.get_task_status(task_id)
            if queue_task:
                # ä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­ï¼Œè¿”å›é˜Ÿåˆ—çŠ¶æ€
                validation_results.append({
                    "task_id": task_id,
                    "exists_in_queue": True,
                    "status": queue_task.status.value,
                    "needs_retry": queue_task.status != QueueTaskStatus.SUCCESS,
                    "error_message": queue_task.error_message
                })
            else:
                # ä»»åŠ¡ä¸åœ¨é˜Ÿåˆ—ä¸­ï¼Œæ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿ
                status_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.status.json")
                result_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json")
                
                if os.path.exists(status_path):
                    try:
                        with open(status_path, "r", encoding="utf-8") as f:
                            status_content = json.load(f)
                        status = status_content.get("status")
                        validation_results.append({
                            "task_id": task_id,
                            "exists_in_queue": False,
                            "status": status,
                            "needs_retry": status != TaskStatus.SUCCESS.value,
                            "error_message": status_content.get("message")
                        })
                    except Exception as e:
                        validation_results.append({
                            "task_id": task_id,
                            "exists_in_queue": False,
                            "status": "UNKNOWN",
                            "needs_retry": True,
                            "error_message": f"è¯»å–çŠ¶æ€æ–‡ä»¶å¤±è´¥: {str(e)}"
                        })
                elif os.path.exists(result_path):
                    # åªæœ‰ç»“æœæ–‡ä»¶ï¼Œè¯´æ˜ä»»åŠ¡å·²å®Œæˆ
                    validation_results.append({
                        "task_id": task_id,
                        "exists_in_queue": False,
                        "status": TaskStatus.SUCCESS.value,
                        "needs_retry": False,
                        "error_message": None
                    })
                else:
                    # ä»€ä¹ˆéƒ½æ²¡æœ‰ï¼Œä»»åŠ¡ä¸å­˜åœ¨
                    validation_results.append({
                        "task_id": task_id,
                        "exists_in_queue": False,
                        "status": "NOT_FOUND",
                        "needs_retry": False,
                        "error_message": "ä»»åŠ¡ä¸å­˜åœ¨"
                    })
        
        # ç»Ÿè®¡ç»“æœ
        needs_retry_count = len([r for r in validation_results if r["needs_retry"]])
        total_tasks = len(validation_results)
        
        logger.info(f"âœ… ä»»åŠ¡éªŒè¯å®Œæˆ: æ€»æ•°={total_tasks}, éœ€é‡è¯•={needs_retry_count}")
        
        return R.success({
            "validation_results": validation_results,
            "total_tasks": total_tasks,
            "needs_retry_count": needs_retry_count,
            "message": f"éªŒè¯å®Œæˆï¼š{total_tasks}ä¸ªä»»åŠ¡ä¸­æœ‰{needs_retry_count}ä¸ªéœ€è¦é‡è¯•"
        })
        
    except Exception as e:
        logger.error(f"âŒ éªŒè¯ä»»åŠ¡çŠ¶æ€å‡ºé”™: {e}")
        return R.error(f"éªŒè¯ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")

class ForceRetryRequest(BaseModel):
    """å¼ºåˆ¶é‡è¯•è¯·æ±‚æ¨¡å‹"""
    model_name: Optional[str] = None
    provider_id: Optional[str] = None
    style: Optional[str] = None
    format: Optional[list] = None
    video_understanding: Optional[bool] = None
    video_interval: Optional[int] = None

class ForceRetryAllRequest(BaseModel):
    """å¼ºåˆ¶å…¨éƒ¨é‡è¯•è¯·æ±‚æ¨¡å‹"""
    task_ids: List[str]
    config: Optional[dict] = {}

@router.post("/force_retry_all")
def force_retry_all(request: ForceRetryAllRequest):
    """
    å¼ºåˆ¶é‡è¯•æ‰€æœ‰ä»»åŠ¡ï¼Œå¯é€‰æ‹©ä½¿ç”¨æ–°çš„é…ç½®è¦†ç›–ã€‚
    """
    try:
        logger.info(f"âš¡ï¸ APIå±‚: æ¥æ”¶åˆ°å¼ºåˆ¶é‡è¯•æ‰€æœ‰ä»»åŠ¡è¯·æ±‚ for {len(request.task_ids)} tasks")
        
        config = request.config
        logger.info(f"   - æä¾›çš„è¦†ç›–é…ç½®: {config}")

        note_service = NoteService()
        result = note_service.force_retry_all(task_ids=request.task_ids, override_data=config)
        
        return R.success(data=result)
        
    except Exception as e:
        logger.error(f"âŒ å¼ºåˆ¶é‡è¯•æ‰€æœ‰ä»»åŠ¡å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/force_retry_task/{task_id}")
def force_retry_task(task_id: str, request: Optional[ForceRetryRequest] = None):
    """å¼ºåˆ¶é‡è¯•å•ä¸ªä»»åŠ¡ï¼ˆåŒ…æ‹¬æˆåŠŸçŠ¶æ€çš„ä»»åŠ¡ï¼‰"""
    try:
        from app.core.task_queue import TaskStatus as QueueTaskStatus, TaskType
        
        # é¦–å…ˆæ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—ä¸­æ˜¯å¦å­˜åœ¨è¯¥ä»»åŠ¡
        queue_task = task_queue.get_task_status(task_id)
        if queue_task:
            # å¼ºåˆ¶é‡è¯•ï¼Œä¸æ£€æŸ¥çŠ¶æ€
            with task_queue._lock:
                task = task_queue.tasks.get(task_id)
                if task:
                    # å¦‚æœæœ‰æ–°çš„é…ç½®ï¼Œæ›´æ–°ä»»åŠ¡æ•°æ®
                    if request and hasattr(request, 'model_name') and request.model_name:
                        task.data['model_name'] = request.model_name
                    if request and hasattr(request, 'provider_id') and request.provider_id:
                        task.data['provider_id'] = request.provider_id
                    if request and hasattr(request, 'style') and request.style:
                        task.data['style'] = request.style
                    if request and hasattr(request, 'format') and request.format:
                        task.data['format'] = request.format
                    if request and hasattr(request, 'video_understanding') and request.video_understanding is not None:
                        task.data['video_understanding'] = request.video_understanding
                    if request and hasattr(request, 'video_interval') and request.video_interval is not None:
                        task.data['video_interval'] = request.video_interval
                    
                    # é‡ç½®ä»»åŠ¡çŠ¶æ€
                    task.status = QueueTaskStatus.PENDING
                    task.started_at = None
                    task.completed_at = None
                    task.error_message = None
                    task.result = None
                    
                    # é‡æ–°æäº¤åˆ°é˜Ÿåˆ—
                    task_queue.task_queue.put(task)
                    
                    logger.info(f"âœ… å¼ºåˆ¶é‡è¯•ä»»åŠ¡æˆåŠŸ: {task_id}")
                    return R.success({
                        "message": "ä»»åŠ¡å·²å¼ºåˆ¶é‡æ–°æäº¤ï¼Œè¯·ç­‰å¾…å¤„ç†",
                        "task_id": task_id
                    })
                else:
                    return R.error("ä»»åŠ¡ä¸å­˜åœ¨")
        
        # ä»»åŠ¡ä¸åœ¨é˜Ÿåˆ—ä¸­ï¼Œä¼˜å…ˆå°è¯•ä»æŒä¹…åŒ–çš„åŸå§‹è¯·æ±‚æ•°æ®é‡å»º
        logger.info(f"ğŸ” ä»»åŠ¡ä¸åœ¨é˜Ÿåˆ—ä¸­ï¼Œå°è¯•ä»æŒä¹…åŒ–çš„åŸå§‹è¯·æ±‚æ•°æ®é‡å»º: {task_id}")
        
        try:
            # åŠ è½½æŒä¹…åŒ–çš„åŸå§‹è¯·æ±‚æ•°æ®
            original_request_data = load_original_request_data(task_id)
            
            if original_request_data:
                video_url = original_request_data.get('video_url')
                platform = original_request_data.get('platform')
                title = original_request_data.get('title', 'æœªçŸ¥æ ‡é¢˜')
                
                if video_url and platform:
                    try:
                        from app.enmus.note_enums import DownloadQuality
                        
                        # æ„å»ºä»»åŠ¡æ•°æ®ï¼Œä½¿ç”¨æŒä¹…åŒ–æ•°æ®ï¼Œå¯èƒ½ä¼šè¢«è¯·æ±‚ä¸­çš„æ–°é…ç½®è¦†ç›–
                        task_data = {
                            'video_url': video_url,
                            'platform': platform,
                            'quality': original_request_data.get('quality', DownloadQuality.fast),
                            'model_name': request.model_name if request and request.model_name else original_request_data.get('model_name', 'gpt-4o-mini'),
                            'provider_id': request.provider_id if request and request.provider_id else original_request_data.get('provider_id', 'openai'),
                            'screenshot': original_request_data.get('screenshot', False),
                            'link': original_request_data.get('link', False),
                            'format': request.format if request and request.format else original_request_data.get('format', []),
                            'style': request.style if request and request.style else original_request_data.get('style', 'ç®€æ´'),
                            'extras': original_request_data.get('extras', None),
                            'video_understanding': request.video_understanding if request and request.video_understanding is not None else original_request_data.get('video_understanding', False),
                            'video_interval': request.video_interval if request and request.video_interval is not None else original_request_data.get('video_interval', 0),
                            'grid_size': original_request_data.get('grid_size', []),
                            'title': title
                        }
                        
                        # ä½¿ç”¨åŸtask_idé‡æ–°åˆ›å»ºä»»åŠ¡
                        new_task_id = task_queue.add_task(
                            task_type=TaskType.SINGLE_VIDEO, 
                            data=task_data,
                            task_id=task_id  # ä½¿ç”¨åŸæœ‰çš„task_id
                        )
                        
                        logger.info(f"âœ… ä»æŒä¹…åŒ–åŸå§‹è¯·æ±‚æ•°æ®é‡å»ºä»»åŠ¡æˆåŠŸ: {task_id}, æ ‡é¢˜: {title}")
                        return R.success({
                            "message": f"ä»»åŠ¡å·²ä»æŒä¹…åŒ–æ•°æ®é‡å»ºå¹¶é‡æ–°æäº¤ï¼Œæ ‡é¢˜: {title}",
                            "task_id": task_id,
                            "video_url": video_url,
                            "title": title
                        })
                    except Exception as task_error:
                        logger.error(f"âŒ ä»æŒä¹…åŒ–æ•°æ®åˆ›å»ºä»»åŠ¡å¤±è´¥: {task_id}, {task_error}")
                        logger.warning(f"âš ï¸ æŒä¹…åŒ–æ•°æ®åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹æ³•: {task_id}")
                else:
                    logger.warning(f"âš ï¸ æŒä¹…åŒ–æ•°æ®ä¸­ç¼ºå°‘å¿…è¦çš„video_urlæˆ–platform: {task_id}")
            else:
                logger.info(f"ğŸ“‹ æœªæ‰¾åˆ°æŒä¹…åŒ–çš„åŸå§‹è¯·æ±‚æ•°æ®: {task_id}")
                
        except Exception as e:
            logger.error(f"âŒ ä»æŒä¹…åŒ–æ•°æ®é‡å»ºä»»åŠ¡å¤±è´¥: {task_id}, {e}")
        
        # ä»»åŠ¡ä¸åœ¨é˜Ÿåˆ—ä¸­ï¼Œä¸”æ²¡æœ‰æŒä¹…åŒ–æ•°æ®ï¼Œå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿé‡å»ºä»»åŠ¡
        logger.info(f"ğŸ” å°è¯•ä»æ–‡ä»¶ç³»ç»Ÿé‡å»ºä»»åŠ¡: {task_id}")
        
        # æ£€æŸ¥ç»“æœæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆåŒ…å«åŸå§‹ä»»åŠ¡æ•°æ®ï¼‰
        result_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json")
        audio_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}_audio.json")
        
        # é¦–å…ˆå°è¯•ä»éŸ³é¢‘metadataæ–‡ä»¶è·å–ä¿¡æ¯ï¼ˆåˆ†ç¦»æ–‡ä»¶æ¨¡å¼ï¼‰
        if os.path.exists(audio_path):
            try:
                with open(audio_path, "r", encoding="utf-8") as f:
                    audio_data = json.load(f)
                
                # ä»éŸ³é¢‘æ–‡ä»¶æå–åŸå§‹ä»»åŠ¡æ•°æ®
                video_url = audio_data.get("file_path", "")
                platform = audio_data.get("platform", "")
                title = audio_data.get("title", "æœªçŸ¥æ ‡é¢˜")
                
                if video_url and platform:
                    try:
                        # é‡å»ºä»»åŠ¡æ•°æ®ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
                        from app.enmus.note_enums import DownloadQuality
                        
                        task_data = {
                            'video_url': video_url,
                            'platform': platform,
                            'quality': DownloadQuality.fast,
                            'model_name': request.model_name if request and request.model_name else 'gpt-4o-mini',
                            'provider_id': request.provider_id if request and request.provider_id else 'openai',
                            'screenshot': False,
                            'link': False,
                            'format': request.format if request and request.format else [],
                            'style': request.style if request and request.style else 'ç®€æ´',
                            'extras': None,
                            'video_understanding': request.video_understanding if request and request.video_understanding is not None else False,
                            'video_interval': request.video_interval if request and request.video_interval is not None else 0,
                            'grid_size': [],
                            'title': title
                        }
                        
                        # ä½¿ç”¨åŸtask_idé‡æ–°åˆ›å»ºä»»åŠ¡
                        new_task_id = task_queue.add_task(
                            task_type=TaskType.SINGLE_VIDEO, 
                            data=task_data,
                            task_id=task_id  # ä½¿ç”¨åŸæœ‰çš„task_id
                        )
                        
                        logger.info(f"âœ… ä»éŸ³é¢‘metadataæ–‡ä»¶é‡å»ºä»»åŠ¡æˆåŠŸ: {task_id}")
                        return R.success({
                            "message": f"ä»»åŠ¡å·²ä»éŸ³é¢‘æ–‡ä»¶é‡å»ºå¹¶é‡æ–°æäº¤ï¼Œæ ‡é¢˜: {title}",
                            "task_id": task_id
                        })
                    except Exception as task_error:
                        logger.error(f"âŒ ä»éŸ³é¢‘æ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥: {task_id}, {task_error}")
                        logger.warning(f"âš ï¸ éŸ³é¢‘æ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹æ³•: {task_id}")
                    
            except Exception as e:
                logger.error(f"âŒ è¯»å–éŸ³é¢‘metadataæ–‡ä»¶å¤±è´¥: {task_id}, {e}")
                # ç¬¬ä¸€ç§å¤±è´¥ï¼šè¯»å–éŸ³é¢‘metadataæ–‡ä»¶å¤±è´¥ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
                logger.info(f"ğŸ”„ è¯»å–éŸ³é¢‘metadataæ–‡ä»¶å¤±è´¥ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                success = clear_and_reset_task(task_id)
                if success:
                    return R.success({
                        "message": "éŸ³é¢‘æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œå·²æ¸…ç©ºé‡ç½®å¹¶é‡æ–°æäº¤ä»»åŠ¡",
                        "task_id": task_id
                    })
                else:
                    return R.error("éŸ³é¢‘æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œæ¸…ç©ºé‡ç½®ä»»åŠ¡ä¹Ÿå¤±è´¥")
        
        # å¦‚æœéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨æˆ–å¤±è´¥ï¼Œå°è¯•ä»ä¸»ç»“æœæ–‡ä»¶è¯»å–
        if os.path.exists(result_path):
            try:
                with open(result_path, "r", encoding="utf-8") as f:
                    result_data = json.load(f)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºé”™è¯¯æ–‡ä»¶
                if "error" in result_data:
                    logger.warning(f"âš ï¸ å‘ç°é”™è¯¯æ–‡ä»¶ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                    success = clear_and_reset_task(task_id, result_data)
                    if success:
                        return R.success({
                            "message": "å‘ç°é”™è¯¯æ–‡ä»¶ï¼Œå·²æ¸…ç©ºé‡ç½®å¹¶é‡æ–°æäº¤ä»»åŠ¡",
                            "task_id": task_id
                        })
                    else:
                        return R.error("å‘ç°é”™è¯¯æ–‡ä»¶ï¼Œæ¸…ç©ºé‡ç½®ä»»åŠ¡å¤±è´¥")
                
                # ä»ç»“æœæ–‡ä»¶ä¸­æå–åŸå§‹ä»»åŠ¡æ•°æ®
                if "audioMeta" in result_data and "transcript" in result_data:
                    # è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç»“æœæ–‡ä»¶ï¼ŒåŒ…å«åŸå§‹æ•°æ®
                    audio_meta = result_data.get("audioMeta", {})
                    video_url = audio_meta.get("file_path", "")
                    platform = audio_meta.get("platform", "")
                    title = audio_meta.get("title", "æœªçŸ¥æ ‡é¢˜")
                    
                    if video_url and platform:
                        try:
                            # é‡å»ºä»»åŠ¡æ•°æ®ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
                            from app.enmus.note_enums import DownloadQuality
                            
                            task_data = {
                                'video_url': video_url,
                                'platform': platform,
                                'quality': DownloadQuality.fast,
                                'model_name': request.model_name if request and request.model_name else 'gpt-4o-mini',
                                'provider_id': request.provider_id if request and request.provider_id else 'openai',
                                'screenshot': False,
                                'link': False,
                                'format': request.format if request and request.format else [],
                                'style': request.style if request and request.style else 'ç®€æ´',
                                'extras': None,
                                'video_understanding': request.video_understanding if request and request.video_understanding is not None else False,
                                'video_interval': request.video_interval if request and request.video_interval is not None else 0,
                                'grid_size': [],
                                'title': title
                            }
                            
                            # ä½¿ç”¨åŸtask_idé‡æ–°åˆ›å»ºä»»åŠ¡
                            new_task_id = task_queue.add_task(
                                task_type=TaskType.SINGLE_VIDEO, 
                                data=task_data,
                                task_id=task_id  # ä½¿ç”¨åŸæœ‰çš„task_id
                            )
                            
                            logger.info(f"âœ… ä»ç»“æœæ–‡ä»¶é‡å»ºä»»åŠ¡æˆåŠŸ: {task_id}")
                            return R.success({
                                "message": f"ä»»åŠ¡å·²ä»ç»“æœæ–‡ä»¶é‡å»ºå¹¶é‡æ–°æäº¤ï¼Œæ ‡é¢˜: {title}",
                                "task_id": task_id
                            })
                        except Exception as task_error:
                            logger.error(f"âŒ ä»ç»“æœæ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥: {task_id}, {task_error}")
                            logger.warning(f"âš ï¸ ç»“æœæ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œå°è¯•æ¸…ç©ºé‡ç½®: {task_id}")
                            # åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œå°è¯•æ¸…ç©ºé‡ç½®
                            success = clear_and_reset_task(task_id, result_data)
                            if success:
                                return R.success({
                                    "message": "ç»“æœæ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œå·²æ¸…ç©ºé‡ç½®å¹¶é‡æ–°æäº¤ä»»åŠ¡",
                                    "task_id": task_id
                                })
                            else:
                                return R.error("ç»“æœæ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œæ¸…ç©ºé‡ç½®ä»»åŠ¡ä¹Ÿå¤±è´¥")
                    else:
                        logger.warning(f"âš ï¸ ç»“æœæ–‡ä»¶ä¸­ç¼ºå°‘å¿…è¦çš„è§†é¢‘ä¿¡æ¯: {task_id}")
                        # ç»“æœæ–‡ä»¶ä¸­ç¼ºå°‘å¿…è¦ä¿¡æ¯ï¼Œä¹Ÿè°ƒç”¨æ¸…ç©ºé‡ç½®
                        logger.info(f"ğŸ”„ ç»“æœæ–‡ä»¶ç¼ºå°‘è§†é¢‘ä¿¡æ¯ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                        success = clear_and_reset_task(task_id, result_data)
                        if success:
                            return R.success({
                                "message": "ç»“æœæ–‡ä»¶ç¼ºå°‘å¿…è¦ä¿¡æ¯ï¼Œå·²æ¸…ç©ºé‡ç½®å¹¶é‡æ–°æäº¤ä»»åŠ¡",
                                "task_id": task_id
                            })
                        else:
                            return R.error("ç»“æœæ–‡ä»¶ç¼ºå°‘å¿…è¦ä¿¡æ¯ï¼Œæ¸…ç©ºé‡ç½®ä»»åŠ¡å¤±è´¥")
                else:
                    logger.warning(f"âš ï¸ ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®: {task_id}")
                    # ç¬¬äºŒç§å¤±è´¥ï¼šç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
                    logger.info(f"ğŸ”„ ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                    success = clear_and_reset_task(task_id, result_data)
                    if success:
                        return R.success({
                            "message": "ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œå·²æ¸…ç©ºé‡ç½®å¹¶é‡æ–°æäº¤ä»»åŠ¡",
                            "task_id": task_id
                        })
                    else:
                        return R.error("ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œæ¸…ç©ºé‡ç½®ä»»åŠ¡å¤±è´¥")
                    
            except Exception as e:
                logger.error(f"âŒ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {task_id}, {e}")
                # è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥ï¼Œä¹Ÿè°ƒç”¨æ¸…ç©ºé‡ç½®
                logger.info(f"ğŸ”„ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                success = clear_and_reset_task(task_id)
                if success:
                    return R.success({
                        "message": "ç»“æœæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œå·²æ¸…ç©ºé‡ç½®å¹¶é‡æ–°æäº¤ä»»åŠ¡",
                        "task_id": task_id
                    })
                else:
                    return R.error(f"ç»“æœæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œæ¸…ç©ºé‡ç½®ä»»åŠ¡ä¹Ÿå¤±è´¥: {str(e)}")
        else:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶: {task_id}")
            # ç¬¬ä¸‰ç§å¤±è´¥ï¼šæœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
            logger.info(f"ğŸ”„ æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
            success = clear_and_reset_task(task_id)
            if success:
                return R.success({
                    "message": "æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶ï¼Œå·²å°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡",
                    "task_id": task_id
                })
            else:
                return R.error("æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶ï¼Œæ— æ³•é‡å»ºä»»åŠ¡")
        
    except Exception as e:
        logger.error(f"âŒ å¼ºåˆ¶é‡è¯•ä»»åŠ¡å¤±è´¥: {e}")
        return R.error(f"å¼ºåˆ¶é‡è¯•ä»»åŠ¡å¤±è´¥: {str(e)}")

@router.post("/force_restart_task/{task_id}")
def force_restart_task(task_id: str):
    """å¼ºåˆ¶æ¸…ç†å¹¶é‡æ–°å¼€å§‹ä»»åŠ¡ - å®Œå…¨ä»å¤´å¼€å§‹ï¼Œæ¸…ç†æ‰€æœ‰ç›¸å…³æ–‡ä»¶"""
    try:
        from app.core.task_queue import TaskStatus as QueueTaskStatus, TaskType
        import glob
        
        logger.info(f"ğŸ”¥ å¼€å§‹å¼ºåˆ¶é‡æ–°å¼€å§‹ä»»åŠ¡: {task_id}")
        
        # 1. é¦–å…ˆå°è¯•ä»æŒä¹…åŒ–çš„åŸå§‹è¯·æ±‚æ•°æ®è·å–ä»»åŠ¡æ•°æ®
        request_file_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.request.json")
        task_data = None
        
        if os.path.exists(request_file_path):
            try:
                with open(request_file_path, "r", encoding="utf-8") as f:
                    request_data = json.load(f)
                
                original_request = request_data.get("original_request", {})
                if original_request and original_request.get("video_url"):
                    try:
                        video_url = original_request.get("video_url")
                        platform = original_request.get("platform", "bilibili")
                        title = original_request.get("title", "æœªçŸ¥æ ‡é¢˜")
                        
                        from app.enmus.note_enums import DownloadQuality
                        
                        task_data = {
                            'video_url': video_url,
                            'platform': platform,
                            'quality': original_request.get('quality', DownloadQuality.fast),
                            'model_name': original_request.get('model_name', 'gpt-4o-mini'),
                            'provider_id': original_request.get('provider_id', 'openai'),
                            'screenshot': original_request.get('screenshot', False),
                            'link': original_request.get('link', False),
                            'format': original_request.get('format', []),
                            'style': original_request.get('style', 'ç®€æ´'),
                            'extras': original_request.get('extras', None),
                            'video_understanding': original_request.get('video_understanding', False),
                            'video_interval': original_request.get('video_interval', 0),
                            'grid_size': original_request.get('grid_size', []),
                            'title': title
                        }
                        
                        logger.info(f"âœ… ä»æŒä¹…åŒ–è¯·æ±‚æ•°æ®è·å–ä»»åŠ¡æ•°æ®æˆåŠŸ: {title} ({video_url})")
                    except Exception as data_error:
                        logger.error(f"âŒ ä»æŒä¹…åŒ–æ•°æ®æ„å»ºä»»åŠ¡æ•°æ®å¤±è´¥: {task_id}, {data_error}")
                        # å¦‚æœæ„å»ºä»»åŠ¡æ•°æ®å¤±è´¥ï¼Œtask_dataä¿æŒä¸ºNone
                    
            except Exception as e:
                logger.error(f"âŒ è¯»å–æŒä¹…åŒ–è¯·æ±‚æ•°æ®å¤±è´¥: {task_id}, {e}")
        
        # 2. å¦‚æœæŒä¹…åŒ–æ•°æ®ä¸å­˜åœ¨ï¼Œå°è¯•ä»éŸ³é¢‘æ–‡ä»¶è·å–åŸå§‹ä»»åŠ¡æ•°æ®
        if not task_data:
            audio_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}_audio.json")
            
            if os.path.exists(audio_path):
                try:
                    with open(audio_path, "r", encoding="utf-8") as f:
                        audio_data = json.load(f)
                
                    # ä»éŸ³é¢‘æ–‡ä»¶æå–åŸå§‹ä»»åŠ¡æ•°æ®
                    video_url = audio_data.get("file_path", "")
                    # å¦‚æœæ˜¯BVå·ï¼Œè½¬æ¢ä¸ºBç«™URL
                    if "BV" in video_url:
                        video_id = os.path.basename(video_url).replace(".mp3", "")
                        video_url = f"https://www.bilibili.com/video/{video_id}"
                    elif not video_url.startswith("http"):
                        # å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œå°è¯•ä»video_idæ„å»ºURL
                        video_id = audio_data.get("video_id", "")
                        if video_id and video_id.startswith("BV"):
                            video_url = f"https://www.bilibili.com/video/{video_id}"
                        else:
                            video_url = audio_data.get("file_path", "")
                    
                    platform = audio_data.get("platform", "bilibili")
                    title = audio_data.get("title", "æœªçŸ¥æ ‡é¢˜")
                    
                    if video_url and platform:
                        try:
                            # é‡å»ºä»»åŠ¡æ•°æ®ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼Œå¯ä»¥åç»­è°ƒæ•´ï¼‰
                            from app.enmus.note_enums import DownloadQuality
                            
                            task_data = {
                                'video_url': video_url,
                                'platform': platform,
                                'quality': DownloadQuality.fast,
                                'model_name': 'gpt-4o-mini',  # é»˜è®¤æ¨¡å‹
                                'provider_id': 'openai',      # é»˜è®¤æä¾›è€…
                                'screenshot': False,
                                'link': False,
                                'format': [],
                                'style': 'ç®€æ´',
                                'extras': None,
                                'video_understanding': False,
                                'video_interval': 0,
                                'grid_size': [],
                                'title': title
                            }
                            
                            logger.info(f"âœ… ä»éŸ³é¢‘æ–‡ä»¶è·å–ä»»åŠ¡æ•°æ®æˆåŠŸ: {title} ({video_url})")
                        except Exception as data_error:
                            logger.error(f"âŒ æ„å»ºä»»åŠ¡æ•°æ®å¤±è´¥: {task_id}, {data_error}")
                            # å¦‚æœæ„å»ºä»»åŠ¡æ•°æ®å¤±è´¥ï¼Œtask_dataä¿æŒä¸ºNone
                except Exception as e:
                    logger.error(f"âŒ è¯»å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {task_id}, {e}")
        
        # å¦‚æœæ²¡æœ‰è·å–åˆ°ä»»åŠ¡æ•°æ®ï¼Œè¿”å›é”™è¯¯
        if not task_data:
            logger.error(f"âŒ æ— æ³•è·å–ä»»åŠ¡æ•°æ®ï¼Œæ— æ³•é‡æ–°å¼€å§‹: {task_id}")
            return R.error("æ— æ³•è·å–åŸå§‹ä»»åŠ¡æ•°æ®ï¼Œè¯·ç¡®ä¿ä»»åŠ¡æ–‡ä»¶å­˜åœ¨")
        
        # 2. æ¸…ç†æ‰€æœ‰ç›¸å…³æ–‡ä»¶
        logger.info(f"ğŸ§¹ å¼€å§‹æ¸…ç†ä»»åŠ¡ç›¸å…³æ–‡ä»¶: {task_id}")
        
        # æ¸…ç†æ¨¡å¼åˆ—è¡¨
        cleanup_patterns = [
            f"{task_id}.json",
            f"{task_id}.status.json", 
            f"{task_id}.request.json",  # åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶
            f"{task_id}_*.json",
            f"{task_id}_*.md",
            f"{task_id}_*.txt"
        ]
        
        cleaned_files = []
        for pattern in cleanup_patterns:
            file_pattern = os.path.join(NOTE_OUTPUT_DIR, pattern)
            matching_files = glob.glob(file_pattern)
            for file_path in matching_files:
                try:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                        cleaned_files.append(os.path.basename(file_path))
                        logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤æ–‡ä»¶: {os.path.basename(file_path)}")
                except Exception as e:
                    logger.warning(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥: {os.path.basename(file_path)}, {e}")
        
        # 3. ä»ä»»åŠ¡é˜Ÿåˆ—ä¸­ç§»é™¤æ—§ä»»åŠ¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        with task_queue._lock:
            if task_id in task_queue.tasks:
                del task_queue.tasks[task_id]
                logger.info(f"ğŸ—‘ï¸ å·²ä»ä»»åŠ¡é˜Ÿåˆ—ç§»é™¤æ—§ä»»åŠ¡: {task_id}")
        
        # 4. åˆ›å»ºå…¨æ–°çš„ä»»åŠ¡
        try:
            new_task_id = task_queue.add_task(
                task_type=TaskType.SINGLE_VIDEO, 
                data=task_data,
                task_id=task_id  # ä½¿ç”¨åŸæœ‰çš„task_id
            )
            
            logger.info(f"âœ… å¼ºåˆ¶é‡æ–°å¼€å§‹ä»»åŠ¡æˆåŠŸ: {task_id}")
            logger.info(f"ğŸ“‹ ä»»åŠ¡è¯¦æƒ…: {task_data.get('title', 'æœªçŸ¥æ ‡é¢˜')}")
            logger.info(f"ğŸ§¹ æ¸…ç†äº† {len(cleaned_files)} ä¸ªæ–‡ä»¶: {', '.join(cleaned_files)}")
            
            return R.success({
                "message": f"ä»»åŠ¡å·²å¼ºåˆ¶é‡æ–°å¼€å§‹ï¼Œæ ‡é¢˜: {task_data.get('title', 'æœªçŸ¥æ ‡é¢˜')}",
                "task_id": task_id,
                "video_url": task_data.get('video_url', ''),
                "title": task_data.get('title', 'æœªçŸ¥æ ‡é¢˜'),
                "cleaned_files": cleaned_files,
                "restart_time": time.time()
            })
        except Exception as task_error:
            logger.error(f"âŒ å¼ºåˆ¶é‡æ–°å¼€å§‹ä»»åŠ¡æ—¶åˆ›å»ºä»»åŠ¡å¤±è´¥: {task_id}, {task_error}")
            return R.error(f"å¼ºåˆ¶é‡æ–°å¼€å§‹ä»»åŠ¡å¤±è´¥: æ–‡ä»¶å·²æ¸…ç†ä½†ä»»åŠ¡åˆ›å»ºå¤±è´¥ - {str(task_error)}")
        
    except Exception as e:
        logger.error(f"âŒ å¼ºåˆ¶é‡æ–°å¼€å§‹ä»»åŠ¡å¤±è´¥: {task_id}, {e}")
        return R.error(f"å¼ºåˆ¶é‡æ–°å¼€å§‹ä»»åŠ¡å¤±è´¥: {str(e)}")

@router.post("/clear_reset_task/{task_id}")
def clear_reset_task(task_id: str):
    """æ¸…ç©ºå¹¶é‡ç½®å•ä¸ªä»»åŠ¡ï¼ˆåˆ é™¤æ‰€æœ‰ç›¸å…³æ–‡ä»¶å¹¶é‡æ–°åˆ›å»ºï¼‰"""
    try:
        logger.info(f"ğŸ§¹ æ‰‹åŠ¨æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
        
        # é¦–å…ˆä»é˜Ÿåˆ—ä¸­ç§»é™¤ä»»åŠ¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        with task_queue._lock:
            if task_id in task_queue.tasks:
                del task_queue.tasks[task_id]
                logger.info(f"ğŸ—‘ï¸ å·²ä»é˜Ÿåˆ—ä¸­ç§»é™¤ä»»åŠ¡: {task_id}")
        
        # æ‰§è¡Œæ¸…ç©ºé‡ç½®
        success = clear_and_reset_task(task_id)
        
        if success:
            logger.info(f"âœ… ä»»åŠ¡æ¸…ç©ºé‡ç½®æˆåŠŸ: {task_id}")
            return R.success({
                "message": "ä»»åŠ¡å·²æ¸…ç©ºé‡ç½®ï¼Œé‡æ–°è¿›å…¥é˜Ÿåˆ—",
                "task_id": task_id
            })
        else:
            logger.warning(f"âš ï¸ ä»»åŠ¡æ¸…ç©ºé‡ç½®éƒ¨åˆ†å¤±è´¥: {task_id}")
            return R.success({
                "message": "ä»»åŠ¡æ–‡ä»¶å·²æ¸…ç©ºï¼Œä½†æ— æ³•é‡æ–°åˆ›å»ºï¼ˆç¼ºå°‘åŸå§‹URLï¼‰",
                "task_id": task_id
            })
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç©ºé‡ç½®ä»»åŠ¡å‡ºé”™: {task_id}, {e}")
        return R.error(f"æ¸…ç©ºé‡ç½®ä»»åŠ¡å¤±è´¥: {str(e)}")

class BatchClearResetRequest(BaseModel):
    """æ‰¹é‡æ¸…ç©ºé‡ç½®è¯·æ±‚æ¨¡å‹"""
    task_ids: List[str]
    force_clear: Optional[bool] = False  # æ˜¯å¦å¼ºåˆ¶æ¸…ç©ºï¼ˆå³ä½¿æ— æ³•é‡æ–°åˆ›å»ºï¼‰

@router.post("/batch_clear_reset_tasks")
def batch_clear_reset_tasks(request: BatchClearResetRequest):
    """æ‰¹é‡æ¸…ç©ºé‡ç½®ä»»åŠ¡"""
    try:
        task_ids = request.task_ids
        force_clear = request.force_clear
        
        logger.info(f"ğŸ§¹ æ‰¹é‡æ¸…ç©ºé‡ç½®ä»»åŠ¡: {len(task_ids)} ä¸ªä»»åŠ¡")
        
        results = []
        success_count = 0
        
        for task_id in task_ids:
            try:
                # ä»é˜Ÿåˆ—ä¸­ç§»é™¤ä»»åŠ¡
                with task_queue._lock:
                    if task_id in task_queue.tasks:
                        del task_queue.tasks[task_id]
                
                # æ‰§è¡Œæ¸…ç©ºé‡ç½®
                success = clear_and_reset_task(task_id)
                
                if success:
                    results.append({
                        "task_id": task_id,
                        "status": "success",
                        "message": "æ¸…ç©ºé‡ç½®æˆåŠŸ"
                    })
                    success_count += 1
                else:
                    if force_clear:
                        # å¼ºåˆ¶æ¸…ç©ºæ¨¡å¼ï¼šå³ä½¿æ— æ³•é‡æ–°åˆ›å»ºä¹Ÿæ¸…ç©ºæ–‡ä»¶
                        results.append({
                            "task_id": task_id,
                            "status": "partial",
                            "message": "æ–‡ä»¶å·²æ¸…ç©ºï¼Œä½†æ— æ³•é‡æ–°åˆ›å»º"
                        })
                        success_count += 1
                    else:
                        results.append({
                            "task_id": task_id,
                            "status": "failed",
                            "message": "æ¸…ç©ºé‡ç½®å¤±è´¥"
                        })
                
            except Exception as e:
                results.append({
                    "task_id": task_id,
                    "status": "error",
                    "message": f"å¤„ç†å‡ºé”™: {str(e)}"
                })
        
        logger.info(f"âœ… æ‰¹é‡æ¸…ç©ºé‡ç½®å®Œæˆ: æˆåŠŸ={success_count}, æ€»æ•°={len(task_ids)}")
        
        return R.success({
            "results": results,
            "success_count": success_count,
            "total_count": len(task_ids),
            "message": f"æ‰¹é‡æ¸…ç©ºé‡ç½®å®Œæˆï¼ŒæˆåŠŸå¤„ç† {success_count}/{len(task_ids)} ä¸ªä»»åŠ¡"
        })
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡æ¸…ç©ºé‡ç½®ä»»åŠ¡å‡ºé”™: {e}")
        return R.error(f"æ‰¹é‡æ¸…ç©ºé‡ç½®ä»»åŠ¡å¤±è´¥: {str(e)}")

@router.get("/baidu_pan/file_list")
def get_baidu_pan_file_list(path: str = "/", share_code: str = None, extract_code: str = None):
    """è·å–ç™¾åº¦ç½‘ç›˜æ–‡ä»¶åˆ—è¡¨ - ä½¿ç”¨BaiduPCS-Py"""
    try:
        from app.downloaders.baidupcs_downloader import BaiduPCSDownloader
        
        logger.info(f"ğŸ—‚ï¸ è·å–ç™¾åº¦ç½‘ç›˜æ–‡ä»¶åˆ—è¡¨: path={path}, share_code={share_code}")
        
        downloader = BaiduPCSDownloader()
        
        # æ£€æŸ¥è®¤è¯çŠ¶æ€
        if not downloader.is_authenticated():
            return R.error("ç™¾åº¦ç½‘ç›˜æœªè®¤è¯ï¼Œè¯·å…ˆæ·»åŠ ç”¨æˆ·", code=401)
        
        # è·å–æ–‡ä»¶åˆ—è¡¨
        try:
            file_list = downloader.get_file_list(path=path, share_code=share_code, extract_code=extract_code)
        except Exception as download_error:
            logger.error(f"âŒ è·å–ç™¾åº¦ç½‘ç›˜æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {download_error}")
            return R.error(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(download_error)}", code=500)
        
        if not file_list:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶")
            return R.success({
                "files": [],
                "total": 0,
                "media_count": 0,
                "message": "å½“å‰ç›®å½•ä¸ºç©º"
            })
        
        # è®¡ç®—åª’ä½“æ–‡ä»¶æ•°é‡
        media_count = sum(1 for f in file_list if f.get("is_media", False))
        
        logger.info(f"âœ… è·å–æ–‡ä»¶åˆ—è¡¨æˆåŠŸ: æ€»è®¡ {len(file_list)} ä¸ªé¡¹ç›®ï¼Œå…¶ä¸­ {media_count} ä¸ªåª’ä½“æ–‡ä»¶")
        
        return R.success({
            "files": file_list,
            "total": len(file_list),
            "media_count": media_count,
            "current_path": path
        })
        
    except Exception as e:
        logger.error(f"âŒ è·å–ç™¾åº¦ç½‘ç›˜æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
        return R.error(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")


def format_file_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes == 0:
        return "0 B"
    
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024.0
    
    return f"{size_bytes:.1f} PB"


@router.post("/baidu_pan/select_files")
def select_baidu_pan_files(request: dict):
    """é€‰æ‹©ç™¾åº¦ç½‘ç›˜æ–‡ä»¶å¹¶åˆ›å»ºä¸‹è½½ä»»åŠ¡"""
    try:
        selected_files = request.get("selected_files", [])
        task_config = request.get("task_config", {})
        
        if not selected_files:
            return R.error("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ–‡ä»¶")
        
        logger.info(f"ğŸ“ é€‰æ‹©ç™¾åº¦ç½‘ç›˜æ–‡ä»¶: {len(selected_files)} ä¸ªæ–‡ä»¶")
        
        created_tasks = []
        
        # ä¸ºæ¯ä¸ªé€‰æ‹©çš„æ–‡ä»¶åˆ›å»ºä»»åŠ¡
        for file_info in selected_files:
            try:
                fs_id = file_info.get("fs_id")
                filename = file_info.get("filename")
                file_path = file_info.get("path", "/")
                
                if not fs_id or not filename:
                    logger.warning(f"âš ï¸ æ–‡ä»¶ä¿¡æ¯ä¸å®Œæ•´ï¼Œè·³è¿‡: {file_info}")
                    continue
                
                # æ„é€ ç™¾åº¦ç½‘ç›˜æ–‡ä»¶URL
                file_url = f"baidu_pan://file/{fs_id}?filename={filename}&path={file_path}"
                
                # å‡†å¤‡ä»»åŠ¡æ•°æ®
                task_data = {
                    'video_url': file_url,
                    'platform': 'baidu_pan',
                    'quality': task_config.get('quality', 'fast'),
                    'model_name': task_config.get('model_name', 'gpt-4o-mini'),
                    'provider_id': task_config.get('provider_id', 'openai'),
                    'screenshot': task_config.get('screenshot', False),
                    'link': task_config.get('link', False),
                    'format': task_config.get('format', []),
                    'style': task_config.get('style', 'ç®€æ´'),
                    'extras': task_config.get('extras', None),
                    'video_understanding': task_config.get('video_understanding', False),
                    'video_interval': task_config.get('video_interval', 0),
                    'grid_size': task_config.get('grid_size', []),
                    'title': os.path.splitext(filename)[0]  # å»æ‰æ‰©å±•åä½œä¸ºæ ‡é¢˜
                }
                
                # æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—
                task_id = task_queue.add_task(TaskType.SINGLE_VIDEO, task_data)
                
                # ä¿å­˜åŸå§‹è¯·æ±‚æ•°æ®
                original_request_data = {
                    "video_url": file_url,
                    "platform": "baidu_pan",
                    "title": task_data['title'],
                    **task_config
                }
                save_original_request_data(task_id, original_request_data)
                
                created_tasks.append({
                    "task_id": task_id,
                    "filename": filename,
                    "title": task_data['title']
                })
                
                logger.info(f"âœ… å·²åˆ›å»ºä»»åŠ¡: {task_id} - {filename}")
                
            except Exception as task_error:
                logger.error(f"âŒ åˆ›å»ºä»»åŠ¡å¤±è´¥: {filename}, {task_error}")
                continue
        
        if not created_tasks:
            return R.error("æ²¡æœ‰æˆåŠŸåˆ›å»ºä»»ä½•ä»»åŠ¡")
        
        logger.info(f"âœ… ç™¾åº¦ç½‘ç›˜æ–‡ä»¶é€‰æ‹©å®Œæˆï¼Œå…±åˆ›å»º {len(created_tasks)} ä¸ªä»»åŠ¡")
        
        return R.success({
            "created_tasks": created_tasks,
            "total_tasks": len(created_tasks),
            "message": f"å·²æˆåŠŸä¸º {len(created_tasks)} ä¸ªæ–‡ä»¶åˆ›å»ºç¬”è®°ç”Ÿæˆä»»åŠ¡"
        })
        
    except Exception as e:
        logger.error(f"âŒ é€‰æ‹©ç™¾åº¦ç½‘ç›˜æ–‡ä»¶å¤±è´¥: {e}")
        return R.error(f"é€‰æ‹©æ–‡ä»¶å¤±è´¥: {str(e)}")


@router.get("/baidu_pan/auth_status")
def get_baidu_pan_auth_status():
    """æ£€æŸ¥ç™¾åº¦ç½‘ç›˜è®¤è¯çŠ¶æ€ - ä½¿ç”¨BaiduPCS-Py"""
    try:
        from app.downloaders.baidupcs_downloader import BaiduPCSDownloader
        
        downloader = BaiduPCSDownloader()
        is_authenticated = downloader.is_authenticated()
        
        if is_authenticated:
            user_info = downloader.get_current_user_info()
            return R.success({
                "authenticated": True,
                "message": "ç™¾åº¦ç½‘ç›˜å·²è®¤è¯",
                "user_info": user_info,
                "validation_success": True
            })
        else:
            return R.success({
                "authenticated": False,
                "message": "æœªè®¤è¯ï¼Œè¯·ä½¿ç”¨BaiduPCS-Pyæ·»åŠ ç”¨æˆ·",
                "validation_success": False,
                "setup_guide": {
                    "steps": [
                        "1. åœ¨æµè§ˆå™¨ä¸­è®¿é—® https://pan.baidu.com",
                        "2. ç™»å½•æ‚¨çš„ç™¾åº¦è´¦å·", 
                        "3. æŒ‰F12æ‰“å¼€å¼€å‘è€…å·¥å…·",
                        "4. è½¬åˆ° Application/åº”ç”¨ -> Storage/å­˜å‚¨ -> Cookies",
                        "5. é€‰æ‹© https://pan.baidu.com",
                        "6. å¤åˆ¶æ‰€æœ‰cookieå€¼ï¼ˆç‰¹åˆ«æ˜¯BDUSSï¼‰",
                        "7. è°ƒç”¨ /api/baidupcs/add_user æ¥å£æ·»åŠ ç”¨æˆ·"
                    ],
                    "required_cookies": ["BDUSS"],
                    "tips": [
                        "ç¡®ä¿å¤åˆ¶å®Œæ•´çš„cookieå­—ç¬¦ä¸²",
                        "cookieä¸­å¿…é¡»åŒ…å«BDUSSå­—æ®µ",
                        "ä½¿ç”¨æ–°çš„BaiduPCS-Pyæ¥å£è¿›è¡Œè®¤è¯ç®¡ç†"
                    ]
                }
            })
            
    except Exception as e:
        logger.error(f"âŒ æ£€æŸ¥ç™¾åº¦ç½‘ç›˜è®¤è¯çŠ¶æ€å¤±è´¥: {e}")
        return R.error(f"æ£€æŸ¥è®¤è¯çŠ¶æ€å¤±è´¥: {str(e)}")

# @router.post("/baidu_pan/validate_cookie")
# æ³¨æ„ï¼šæ­¤è·¯ç”±å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨æ–°çš„BaiduPCS-Pyæ¥å£
# æ–°æ¥å£: GET /api/baidupcs/auth_status
def validate_baidu_pan_cookie(request: dict):
    """éªŒè¯ç™¾åº¦ç½‘ç›˜cookieæœ‰æ•ˆæ€§ - å·²åºŸå¼ƒ"""
    try:
        cookie_string = request.get("cookie", "").strip()
        
        if not cookie_string:
            return R.error("è¯·æä¾›cookieå­—ç¬¦ä¸²")
        
        # è§£æcookie
        critical_cookies = ['BDUSS', 'STOKEN', 'PSTM']
        parsed_cookies = {}
        
        for cookie_pair in cookie_string.split(';'):
            if '=' in cookie_pair:
                name, value = cookie_pair.split('=', 1)
                name = name.strip()
                value = value.strip()
                if name and value:
                    parsed_cookies[name] = value
        
        # æ£€æŸ¥å…³é”®cookie
        missing_critical = [c for c in critical_cookies if c not in parsed_cookies]
        existing_critical = [c for c in critical_cookies if c in parsed_cookies]
        
        if missing_critical:
            return R.error(
                f"cookieç¼ºå°‘å…³é”®å­—æ®µ: {', '.join(missing_critical)}",
                code=400,
                data={
                    "missing_cookies": missing_critical,
                    "existing_cookies": existing_critical,
                    "is_valid": False
                }
            )
        
        # å°è¯•ä½¿ç”¨cookieè¿›è¡ŒAPIè°ƒç”¨éªŒè¯
        try:
            from app.downloaders.baidupcs_downloader import BaiduPanDownloader
            
            # ä¸´æ—¶åˆ›å»ºä¸‹è½½å™¨å®ä¾‹è¿›è¡Œæµ‹è¯•
            downloader = BaiduPanDownloader()
            
            # ä¸´æ—¶è®¾ç½®cookieè¿›è¡ŒéªŒè¯
            temp_session = downloader.session
            temp_session.cookies.clear()
            
            for name, value in parsed_cookies.items():
                temp_session.cookies.set(name, value, domain='.baidu.com')
            
            # å°è¯•éªŒè¯cookie
            if downloader._validate_cookie_status():
                return R.success({
                    "is_valid": True,
                    "message": "cookieéªŒè¯æˆåŠŸ",
                    "existing_cookies": existing_critical,
                    "total_cookies": len(parsed_cookies)
                })
            else:
                return R.error(
                    "cookieéªŒè¯å¤±è´¥ï¼Œå¯èƒ½å·²è¿‡æœŸæˆ–æ— æ•ˆ",
                    code=401,
                    data={
                        "is_valid": False,
                        "existing_cookies": existing_critical
                    }
                )
                
        except Exception as validation_error:
            logger.warning(f"âš ï¸ CookieéªŒè¯å¼‚å¸¸: {validation_error}")
            return R.error(
                f"cookieéªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(validation_error)}",
                code=500,
                data={
                    "is_valid": False,
                    "validation_error": str(validation_error)
                }
            )
        
    except Exception as e:
        logger.error(f"âŒ éªŒè¯ç™¾åº¦ç½‘ç›˜cookieå¤±è´¥: {e}")
        return R.error(f"éªŒè¯cookieå¤±è´¥: {str(e)}")

# @router.get("/baidu_pan/cookie_guide")  
# æ³¨æ„ï¼šæ­¤è·¯ç”±å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨æ–°çš„BaiduPCS-Pyæ¥å£
# æ–°æ¥å£: GET /api/baidupcs/usage_guide
def get_baidu_pan_cookie_guide():
    """è·å–ç™¾åº¦ç½‘ç›˜cookieè·å–æŒ‡å—"""
    try:
        guide = {
            "title": "ç™¾åº¦ç½‘ç›˜Cookieè·å–æŒ‡å—",
            "description": "è¯¦ç»†çš„ç™¾åº¦ç½‘ç›˜cookieè·å–æ­¥éª¤ï¼Œç¡®ä¿èƒ½æ­£å¸¸è®¿é—®ä¸ªäººç½‘ç›˜æ–‡ä»¶",
            "steps": [
                {
                    "step": 1,
                    "title": "æ‰“å¼€ç™¾åº¦ç½‘ç›˜",
                    "description": "åœ¨æµè§ˆå™¨ä¸­è®¿é—® https://pan.baidu.com",
                    "tips": ["å»ºè®®ä½¿ç”¨Chromeã€Firefoxæˆ–Edgeæµè§ˆå™¨"]
                },
                {
                    "step": 2,
                    "title": "ç™»å½•è´¦å·",
                    "description": "ä½¿ç”¨æ‚¨çš„ç™¾åº¦è´¦å·ç™»å½•",
                    "tips": ["ç¡®ä¿ç™»å½•æˆåŠŸï¼Œèƒ½çœ‹åˆ°ç½‘ç›˜é¦–é¡µ"]
                },
                {
                    "step": 3,
                    "title": "æ‰“å¼€å¼€å‘è€…å·¥å…·",
                    "description": "æŒ‰F12é”®æˆ–å³é”®ç‚¹å‡»\"æ£€æŸ¥\"æ‰“å¼€å¼€å‘è€…å·¥å…·",
                    "tips": ["åœ¨Windows/Linuxä¸ŠæŒ‰F12ï¼Œåœ¨Macä¸ŠæŒ‰Cmd+Option+I"]
                },
                {
                    "step": 4,
                    "title": "æ‰¾åˆ°Cookie",
                    "description": "ç‚¹å‡»\"Application\"ï¼ˆåº”ç”¨ï¼‰æˆ–\"Storage\"ï¼ˆå­˜å‚¨ï¼‰é€‰é¡¹å¡",
                    "tips": ["å¦‚æœæ‰¾ä¸åˆ°ï¼Œå¯èƒ½å«åš\"åº”ç”¨ç¨‹åº\"æˆ–\"å­˜å‚¨\""]
                },
                {
                    "step": 5,
                    "title": "é€‰æ‹©ç½‘ç«™Cookie",
                    "description": "åœ¨å·¦ä¾§èœå•ä¸­å±•å¼€\"Cookies\"ï¼Œç‚¹å‡»\"https://pan.baidu.com\"",
                    "tips": ["ç¡®ä¿é€‰æ‹©çš„æ˜¯pan.baidu.comåŸŸåä¸‹çš„cookie"]
                },
                {
                    "step": 6,
                    "title": "å¤åˆ¶å…³é”®Cookie",
                    "description": "æ‰¾åˆ°å¹¶å¤åˆ¶BDUSSã€STOKENã€PSTMç­‰å…³é”®cookie",
                    "tips": [
                        "BDUSSï¼šç”¨æˆ·èº«ä»½å‡­è¯ï¼Œæœ€é‡è¦",
                        "STOKENï¼šä¼šè¯ä»¤ç‰Œï¼Œå¿…éœ€",
                        "PSTMï¼šæ—¶é—´æˆ³ï¼Œå¿…éœ€",
                        "å»ºè®®å¤åˆ¶æ‰€æœ‰å¯è§çš„cookieä»¥ç¡®ä¿å®Œæ•´æ€§"
                    ]
                },
                {
                    "step": 7,
                    "title": "æ ¼å¼åŒ–Cookie",
                    "description": "å°†cookieæ ¼å¼åŒ–ä¸º: åç§°1=å€¼1; åç§°2=å€¼2; ...",
                    "tips": [
                        "æ¯ä¸ªcookieä¹‹é—´ç”¨åˆ†å·å’Œç©ºæ ¼åˆ†éš”",
                        "ç¤ºä¾‹ï¼šBDUSS=abc123; STOKEN=def456; PSTM=1234567890"
                    ]
                },
                {
                    "step": 8,
                    "title": "é…ç½®åˆ°ç³»ç»Ÿ",
                    "description": "åœ¨ç³»ç»Ÿè®¾ç½®ä¸­ç²˜è´´å®Œæ•´çš„cookieå­—ç¬¦ä¸²",
                    "tips": ["ç²˜è´´åç³»ç»Ÿä¼šè‡ªåŠ¨éªŒè¯cookieæœ‰æ•ˆæ€§"]
                }
            ],
            "required_cookies": [
                {
                    "name": "BDUSS",
                    "description": "ç™¾åº¦ç”¨æˆ·èº«ä»½å‡­è¯ï¼Œæœ€é‡è¦çš„è®¤è¯cookie",
                    "required": True
                },
                {
                    "name": "STOKEN",
                    "description": "ç™¾åº¦ç½‘ç›˜ä¼šè¯ä»¤ç‰Œ",
                    "required": True
                },
                {
                    "name": "PSTM",
                    "description": "æ—¶é—´æˆ³ç›¸å…³å‚æ•°",
                    "required": True
                },
                {
                    "name": "BAIDUID",
                    "description": "ç™¾åº¦ç”¨æˆ·ID",
                    "required": False
                }
            ],
            "common_issues": [
                {
                    "issue": "å¤åˆ¶çš„cookieéªŒè¯å¤±è´¥",
                    "solutions": [
                        "ç¡®ä¿å·²æˆåŠŸç™»å½•ç™¾åº¦ç½‘ç›˜",
                        "æ£€æŸ¥cookieæ˜¯å¦åŒ…å«BDUSSã€STOKENã€PSTM",
                        "åˆ·æ–°é¡µé¢åé‡æ–°å¤åˆ¶cookie",
                        "æ¸…é™¤æµè§ˆå™¨ç¼“å­˜åé‡æ–°ç™»å½•"
                    ]
                },
                {
                    "issue": "æ‰¾ä¸åˆ°å¼€å‘è€…å·¥å…·",
                    "solutions": [
                        "å°è¯•æŒ‰F12é”®",
                        "å³é”®ç‚¹å‡»é¡µé¢é€‰æ‹©\"æ£€æŸ¥\"æˆ–\"å®¡æŸ¥å…ƒç´ \"",
                        "åœ¨æµè§ˆå™¨èœå•ä¸­æŸ¥æ‰¾\"å¼€å‘è€…å·¥å…·\"é€‰é¡¹"
                    ]
                },
                {
                    "issue": "Cookieç»å¸¸è¿‡æœŸ",
                    "solutions": [
                        "ä¿æŒæµè§ˆå™¨ä¸­ç™¾åº¦ç½‘ç›˜çš„ç™»å½•çŠ¶æ€",
                        "é¿å…åœ¨å…¶ä»–åœ°æ–¹é‡å¤ç™»å½•åŒä¸€è´¦å·",
                        "å®šæœŸæ›´æ–°cookieï¼ˆå»ºè®®æ¯å‘¨æ›´æ–°ä¸€æ¬¡ï¼‰"
                    ]
                }
            ],
            "security_notes": [
                "CookieåŒ…å«æ‚¨çš„ç™»å½•å‡­è¯ï¼Œè¯·å¦¥å–„ä¿ç®¡",
                "ä¸è¦å°†cookieåˆ†äº«ç»™ä»–äºº",
                "å¦‚å‘ç°cookieæ³„éœ²ï¼Œè¯·åŠæ—¶ä¿®æ”¹å¯†ç ",
                "å»ºè®®å®šæœŸæ›´æ–°cookieä»¥ç¡®ä¿å®‰å…¨"
            ]
        }
        
        return R.success(guide)
        
    except Exception as e:
        logger.error(f"âŒ è·å–cookieæŒ‡å—å¤±è´¥: {e}")
        return R.error(f"è·å–cookieæŒ‡å—å¤±è´¥: {str(e)}")

# @router.post("/baidu_pan/save_cookie")
# æ³¨æ„ï¼šæ­¤è·¯ç”±å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨æ–°çš„BaiduPCS-Pyæ¥å£  
# æ–°æ¥å£: POST /api/baidupcs/add_user
def save_baidu_pan_cookie(request: dict):
    """ä¿å­˜ç™¾åº¦ç½‘ç›˜cookie - å·²åºŸå¼ƒ"""
    try:
        cookie_string = request.get("cookie", "").strip()
        
        if not cookie_string:
            return R.error("è¯·æä¾›cookieå­—ç¬¦ä¸²")
        
        logger.info(f"ğŸ’¾ å‡†å¤‡ä¿å­˜ç™¾åº¦ç½‘ç›˜cookie")
        
        # å…ˆéªŒè¯cookieæœ‰æ•ˆæ€§
        try:
            # è§£æå¹¶éªŒè¯cookie
            critical_cookies = ['BDUSS', 'STOKEN', 'PSTM']
            parsed_cookies = {}
            
            for cookie_pair in cookie_string.split(';'):
                if '=' in cookie_pair:
                    name, value = cookie_pair.split('=', 1)
                    name = name.strip()
                    value = value.strip()
                    if name and value:
                        parsed_cookies[name] = value
            
            # æ£€æŸ¥å…³é”®cookie
            missing_critical = [c for c in critical_cookies if c not in parsed_cookies]
            if missing_critical:
                return R.error(
                    f"cookieç¼ºå°‘å…³é”®å­—æ®µ: {', '.join(missing_critical)}",
                    code=400,
                    data={
                        "missing_cookies": missing_critical,
                        "saved": False
                    }
                )
            
            # å°è¯•éªŒè¯cookieæœ‰æ•ˆæ€§
            from app.downloaders.baidupcs_downloader import BaiduPanDownloader
            
            # ä¸´æ—¶æµ‹è¯•cookie
            test_downloader = BaiduPanDownloader()
            test_session = test_downloader.session
            test_session.cookies.clear()
            
            for name, value in parsed_cookies.items():
                test_session.cookies.set(name, value, domain='.baidu.com')
            
            # éªŒè¯cookie
            if not test_downloader._validate_cookie_status():
                logger.warning("âš ï¸ CookieéªŒè¯å¤±è´¥ï¼Œä½†å°†ç»§ç»­ä¿å­˜")
            
        except Exception as validation_error:
            logger.warning(f"âš ï¸ CookieéªŒè¯å¼‚å¸¸: {validation_error}")
            # éªŒè¯å¤±è´¥ä½†ä»ç„¶å…è®¸ä¿å­˜
        
        # ä¿å­˜cookie
        try:
            from app.services.cookie_manager import CookieConfigManager
            cookie_manager = CookieConfigManager()
            
            cookie_manager.set("baidu_pan", cookie_string)
            
            # éªŒè¯ä¿å­˜æ˜¯å¦æˆåŠŸ
            saved_cookie = cookie_manager.get("baidu_pan")
            if saved_cookie and saved_cookie == cookie_string:
                logger.info("âœ… ç™¾åº¦ç½‘ç›˜cookieä¿å­˜æˆåŠŸ")
                
                return R.success({
                    "message": "ç™¾åº¦ç½‘ç›˜cookieä¿å­˜æˆåŠŸ",
                    "cookie_length": len(cookie_string),
                    "existing_cookies": list(parsed_cookies.keys()),
                    "saved": True
                })
            else:
                logger.error("âŒ Cookieä¿å­˜éªŒè¯å¤±è´¥")
                return R.error("Cookieä¿å­˜å¤±è´¥ï¼Œè¯·é‡è¯•")
                
        except Exception as save_error:
            logger.error(f"âŒ ä¿å­˜cookieå¤±è´¥: {save_error}")
            return R.error(f"ä¿å­˜cookieå¤±è´¥: {str(save_error)}")
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜ç™¾åº¦ç½‘ç›˜cookieå¤±è´¥: {e}")
        return R.error(f"ä¿å­˜cookieå¤±è´¥: {str(e)}")

# @router.delete("/baidu_pan/clear_cookie")
# æ³¨æ„ï¼šæ­¤è·¯ç”±å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨æ–°çš„BaiduPCS-Pyæ¥å£
# æ–°æ¥å£: POST /api/baidupcs/remove_user  
def clear_baidu_pan_cookie():
    """æ¸…é™¤ç™¾åº¦ç½‘ç›˜cookie - å·²åºŸå¼ƒ"""
    try:
        from app.services.cookie_manager import CookieConfigManager
        
        cookie_manager = CookieConfigManager()
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨cookie
        existing_cookie = cookie_manager.get("baidu_pan")
        if not existing_cookie:
            return R.success({
                "message": "ç™¾åº¦ç½‘ç›˜cookieä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…é™¤",
                "cleared": False
            })
        
        # åˆ é™¤cookie
        cookie_manager.delete("baidu_pan")
        
        # éªŒè¯åˆ é™¤æ˜¯å¦æˆåŠŸ
        remaining_cookie = cookie_manager.get("baidu_pan")
        if remaining_cookie:
            logger.error("âŒ Cookieåˆ é™¤éªŒè¯å¤±è´¥")
            return R.error("Cookieåˆ é™¤å¤±è´¥")
        
        logger.info("âœ… ç™¾åº¦ç½‘ç›˜cookieæ¸…é™¤æˆåŠŸ")
        
        return R.success({
            "message": "ç™¾åº¦ç½‘ç›˜cookieå·²æ¸…é™¤",
            "cleared": True
        })
        
    except Exception as e:
        logger.error(f"âŒ æ¸…é™¤ç™¾åº¦ç½‘ç›˜cookieå¤±è´¥: {e}")
        return R.error(f"æ¸…é™¤cookieå¤±è´¥: {str(e)}")

@router.post("/clear_baidu_pan_cookie")
def clear_baidu_pan_cookie():
    try:
        from app.services.baidupcs_service import clear_cookie
        clear_cookie()
        logger.info("âœ… ç™¾åº¦ç½‘ç›˜cookieå·²æ¸…é™¤")
        return R.success("Cookieå·²æ¸…é™¤")
    except Exception as e:
        logger.error(f"âŒ æ¸…é™¤ç™¾åº¦ç½‘ç›˜cookieå¤±è´¥: {e}")
        return R.error(f"æ¸…é™¤cookieå¤±è´¥: {str(e)}")

@router.post("/debug/force_retry_task/{task_id}")
def debug_force_retry_task(task_id: str):
    """è°ƒè¯•ç”¨ï¼šå¼ºåˆ¶é‡è¯•å•ä¸ªä»»åŠ¡ï¼ˆæ£€æŸ¥å­˜å‚¨è·¯å¾„ï¼‰"""
    try:
        logger.warning(f"ğŸ” [DEBUG] è°ƒè¯•å¼ºåˆ¶é‡è¯•å•ä¸ªä»»åŠ¡: {task_id}")
        
        # æ£€æŸ¥task_persistenceç›®å½•
        from app.core.task_queue import task_queue
        task_persistence_dir = task_queue.persistence_dir
        logger.warning(f"  - ä»»åŠ¡æŒä¹…åŒ–ç›®å½•: {task_persistence_dir}")
        task_file = os.path.join(task_persistence_dir, f"{task_id}.json")
        logger.warning(f"  - ä»»åŠ¡æ–‡ä»¶å­˜åœ¨?: {os.path.exists(task_file)}")
        
        # æ£€æŸ¥note_resultsç›®å½•
        note_results_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "note_results"))
        logger.warning(f"  - ç¬”è®°ç»“æœç›®å½•: {note_results_dir}")
        logger.warning(f"  - ç¬”è®°ç»“æœç›®å½•å­˜åœ¨?: {os.path.exists(note_results_dir)}")
        
        request_file = os.path.join(note_results_dir, f"{task_id}.request.json")
        logger.warning(f"  - è¯·æ±‚æ–‡ä»¶å­˜åœ¨?: {os.path.exists(request_file)}")
        
        if os.path.exists(request_file):
            try:
                with open(request_file, 'r', encoding='utf-8') as f:
                    request_data = json.load(f)
                logger.warning(f"  - è¯·æ±‚æ•°æ®é”®: {list(request_data.keys())}")
                
                original_request = request_data.get("original_request", {})
                logger.warning(f"  - åŸå§‹è¯·æ±‚é”®: {list(original_request.keys())}")
                
                if "video_url" in original_request and "platform" in original_request:
                    logger.warning(f"  - æ‰¾åˆ°å¿…è¦çš„video_urlå’Œplatform")
                    return R.success({
                        "message": "æ‰¾åˆ°äº†æœ‰æ•ˆçš„è¯·æ±‚æ–‡ä»¶",
                        "task_id": task_id,
                        "request_file": request_file,
                        "keys": list(original_request.keys()),
                        "video_url": original_request.get("video_url"),
                        "platform": original_request.get("platform")
                    })
                else:
                    logger.warning(f"  - åŸå§‹è¯·æ±‚ç¼ºå°‘å¿…è¦ä¿¡æ¯")
                    return R.error("è¯·æ±‚æ–‡ä»¶ä¸­ç¼ºå°‘å¿…è¦çš„video_urlæˆ–platform")
            except Exception as e:
                logger.error(f"  - åŠ è½½è¯·æ±‚æ–‡ä»¶å¤±è´¥: {e}")
                return R.error(f"åŠ è½½è¯·æ±‚æ–‡ä»¶å¤±è´¥: {str(e)}")
        else:
            logger.warning(f"  - è¯·æ±‚æ–‡ä»¶ä¸å­˜åœ¨")
            return R.error("è¯·æ±‚æ–‡ä»¶ä¸å­˜åœ¨")
    except Exception as e:
        logger.error(f"âŒ è°ƒè¯•é‡è¯•ä»»åŠ¡å¤±è´¥: {e}")
        return R.error(f"è°ƒè¯•å¤±è´¥: {str(e)}")
