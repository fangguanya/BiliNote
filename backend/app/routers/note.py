# app/routers/note.py
import json
import os
import traceback
import uuid
import time
import glob
from typing import Optional, Union, List, Tuple
from urllib.parse import urlparse

from fastapi import APIRouter, HTTPException, BackgroundTasks, UploadFile, File
from pydantic import BaseModel, validator, field_validator
from dataclasses import asdict

from app.db.video_task_dao import get_task_by_video
from app.enmus.note_enums import DownloadQuality
from app.services.note import NoteGenerator, logger
from app.utils.response import ResponseWrapper as R
from app.utils.url_parser import extract_video_id, is_collection_url, extract_collection_videos, identify_platform
from app.validators.video_url_validator import is_supported_video_url
from fastapi import APIRouter, Request, HTTPException
from fastapi.responses import StreamingResponse
import httpx
from app.enmus.task_status_enums import TaskStatus
from app.models.note_api import StandardResponse, SingleVideoResponse, CollectionResponse, TaskInfo
from app.services.note import NoteGenerator
from app.utils.logger import get_logger
from app.core.task_queue import task_queue, TaskType, TaskStatus as QueueTaskStatus

# from app.services.downloader import download_raw_audio
# from app.services.whisperer import transcribe_audio

router = APIRouter()


class RecordRequest(BaseModel):
    video_id: str
    platform: str


class VideoRequest(BaseModel):
    video_url: str
    platform: str
    quality: DownloadQuality
    screenshot: Optional[bool] = False
    link: Optional[bool] = False
    model_name: str
    provider_id: str
    task_id: Optional[str] = None
    format: Optional[list] = []
    style: str = None
    extras: Optional[str]=None
    video_understanding: Optional[bool] = False
    video_interval: Optional[int] = 0
    grid_size: Optional[list] = []
    is_collection: Optional[bool] = False
    max_collection_videos: Optional[int] = 400
    auto_save_notion: Optional[bool] = True
    auto_detect_collection: Optional[bool] = True  # æ–°å¢ï¼šè‡ªåŠ¨è¯†åˆ«åˆé›†å¼€å…³

    @field_validator("video_url")
    def validate_supported_url(cls, v):
        url = str(v)
        parsed = urlparse(url)
        if parsed.scheme in ("http", "https"):
            # æ˜¯ç½‘ç»œé“¾æ¥ï¼Œç»§ç»­ç”¨åŸæœ‰å¹³å°æ ¡éªŒ
            if not is_supported_video_url(url):
                raise ValueError("æš‚ä¸æ”¯æŒè¯¥è§†é¢‘å¹³å°æˆ–é“¾æ¥æ ¼å¼æ— æ•ˆ")

        return v


NOTE_OUTPUT_DIR = "note_results"
UPLOAD_DIR = "uploads"


def save_original_request_data(task_id: str, request_data: dict):
    """ä¿å­˜åŸå§‹è¯·æ±‚æ•°æ®åˆ°æŒä¹…åŒ–å­˜å‚¨"""
    os.makedirs(NOTE_OUTPUT_DIR, exist_ok=True)
    
    try:
        # æ·»åŠ æ—¶é—´æˆ³å’Œä»»åŠ¡ID
        request_data_with_meta = {
            "task_id": task_id,
            "created_at": time.time(),
            "created_at_iso": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
            "original_request": request_data
        }
        
        # ä¿å­˜åˆ° {task_id}.request.json æ–‡ä»¶
        request_file_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.request.json")
        with open(request_file_path, "w", encoding="utf-8") as f:
            json.dump(request_data_with_meta, f, ensure_ascii=False, indent=2)
            
        logger.info(f"âœ… åŸå§‹è¯·æ±‚æ•°æ®å·²ä¿å­˜: {task_id}")
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜åŸå§‹è¯·æ±‚æ•°æ®å¤±è´¥: {task_id}, {e}")


def load_original_request_data(task_id: str) -> dict:
    """ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½åŸå§‹è¯·æ±‚æ•°æ®"""
    try:
        request_file_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.request.json")
        
        if os.path.exists(request_file_path):
            with open(request_file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            # è¿”å›åŸå§‹è¯·æ±‚æ•°æ®
            original_request = data.get("original_request", {})
            logger.info(f"âœ… æˆåŠŸåŠ è½½åŸå§‹è¯·æ±‚æ•°æ®: {task_id}")
            return original_request
        else:
            logger.warning(f"âš ï¸ åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {task_id}")
            return {}
            
    except Exception as e:
        logger.error(f"âŒ åŠ è½½åŸå§‹è¯·æ±‚æ•°æ®å¤±è´¥: {task_id}, {e}")
        return {}


def save_note_to_file(task_id: str, note):
    os.makedirs(NOTE_OUTPUT_DIR, exist_ok=True)
    
    # å®‰å…¨å¤„ç†ä¸åŒç±»å‹çš„noteå¯¹è±¡
    try:
        if hasattr(note, '__dataclass_fields__'):
            # å¦‚æœæ˜¯dataclasså®ä¾‹ï¼Œä½¿ç”¨asdict
            note_data = asdict(note)
        elif isinstance(note, dict):
            # å¦‚æœå·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
            note_data = note
        else:
            # å…¶ä»–æƒ…å†µï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            note_data = {"data": str(note), "type": type(note).__name__}
        
        with open(os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json"), "w", encoding="utf-8") as f:
            json.dump(note_data, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        # å¦‚æœåºåˆ—åŒ–å¤±è´¥ï¼Œä¿å­˜é”™è¯¯ä¿¡æ¯
        error_data = {
            "error": f"åºåˆ—åŒ–å¤±è´¥: {str(e)}",
            "note_type": type(note).__name__,
            "task_id": task_id
        }
        with open(os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json"), "w", encoding="utf-8") as f:
            json.dump(error_data, f, ensure_ascii=False, indent=2)


def run_note_task(task_id: str, video_url: str, platform: str, quality: DownloadQuality,
                  link: bool = False, screenshot: bool = False, model_name: str = None, provider_id: str = None,
                  _format: list = None, style: str = None, extras: str = None, video_understanding: bool = False,
                  video_interval=0, grid_size=[]
                  ):
    try:
        if not model_name or not provider_id:
            raise HTTPException(status_code=400, detail="è¯·é€‰æ‹©æ¨¡å‹å’Œæä¾›è€…")

        note = NoteGenerator().generate(
            video_url=video_url,
            platform=platform,
            quality=quality,
            task_id=task_id,
            model_name=model_name,
            provider_id=provider_id,
            link=link,
            _format=_format,
            style=style,
            extras=extras,
            screenshot=screenshot
            , video_understanding=video_understanding,
            video_interval=video_interval,
            grid_size=grid_size
        )
        logger.info(f"Note generated: {task_id}")
        save_note_to_file(task_id, note)
    except Exception as e:
        save_note_to_file(task_id, {"error": str(e)})


@router.post('/delete_task')
def delete_task(data: RecordRequest):
    try:

        NoteGenerator().delete_note(video_id=data.video_id, platform=data.platform)
        return R.success(msg='åˆ é™¤æˆåŠŸ')
    except Exception as e:
        return R.error(msg=e)


@router.post("/upload")
async def upload(file: UploadFile = File(...)):
    os.makedirs(UPLOAD_DIR, exist_ok=True)
    file_location = os.path.join(UPLOAD_DIR, file.filename)

    with open(file_location, "wb+") as f:
        f.write(await file.read())

    # å‡è®¾ä½ é™æ€ç›®å½•æŒ‚è½½äº† /uploads
    return R.success({"url": f"/uploads/{file.filename}"})


@router.post("/generate_note")
async def generate_note(
    request: VideoRequest
) -> StandardResponse[Union[SingleVideoResponse, CollectionResponse]]:
    logger.info(f"ğŸ¬ æ”¶åˆ°ç”Ÿæˆç¬”è®°è¯·æ±‚: {request.video_url}")
    logger.info(f"ğŸ“Š è¯·æ±‚å‚æ•°: max_collection_videos={request.max_collection_videos}")
    
    try:
        # è¯†åˆ«è§†é¢‘å¹³å°
        platform = identify_platform(request.video_url)
        logger.info(f"ğŸ¯ è¯†åˆ«åˆ°å¹³å°: {platform}")
        
        if not platform:
            logger.error("âŒ ä¸æ”¯æŒçš„å¹³å°æˆ–æ— æ•ˆçš„URL")
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„å¹³å°æˆ–æ— æ•ˆçš„URL")

        # æ£€æµ‹æ˜¯å¦ä¸ºåˆé›†URLï¼ˆæ ¹æ®auto_detect_collectionå¼€å…³å†³å®šï¼‰
        is_collection = False
        if request.auto_detect_collection:
            is_collection = is_collection_url(request.video_url, platform)
            logger.info(f"ğŸ” åˆé›†æ£€æµ‹ç»“æœ: {is_collection} (è‡ªåŠ¨è¯†åˆ«å¼€å…³: å¼€)")
        else:
            logger.info(f"ğŸ” åˆé›†æ£€æµ‹è¢«è·³è¿‡ (è‡ªåŠ¨è¯†åˆ«å¼€å…³: å…³)")
        
        if is_collection:
            logger.info("ğŸ¬ è¿›å…¥åˆé›†å¤„ç†åˆ†æ”¯")
            return await handle_collection_generation(request, platform)
        else:
            logger.info("ğŸ“º è¿›å…¥å•è§†é¢‘å¤„ç†åˆ†æ”¯")
            return await handle_single_video_generation(request, platform)
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆç¬”è®°å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆç¬”è®°å¤±è´¥: {str(e)}")


async def handle_collection_generation(
    request: VideoRequest, 
    platform: str
) -> StandardResponse[CollectionResponse]:
    """å¤„ç†åˆé›†ç”Ÿæˆè¯·æ±‚"""
    logger.info(f"ğŸ¬ å¼€å§‹å¤„ç†åˆé›†: {request.video_url}")
    logger.info(f"ğŸ“Š åˆé›†å‚æ•°: platform={platform}, max_videos={request.max_collection_videos}")
    
    try:
        # å¯¹äºå…¶ä»–åˆé›†URLï¼Œå°è¯•å¿«é€Ÿæå–è§†é¢‘åˆ—è¡¨
        logger.info("ğŸ” å¿«é€Ÿæå–åˆé›†è§†é¢‘åˆ—è¡¨...")
        
        try:
            # ä½¿ç”¨å¿«é€Ÿæå–æ–¹æ³•ï¼ˆæœ‰è¶…æ—¶ä¿æŠ¤ï¼‰
            videos = await extract_collection_videos_with_timeout(
                request.video_url, 
                platform, 
                request.max_collection_videos,
                timeout_seconds=8  # 8ç§’è¶…æ—¶
            )
            
            if videos:
                logger.info(f"ğŸ“¹ å¿«é€Ÿæå–æˆåŠŸï¼Œå…± {len(videos)} ä¸ªè§†é¢‘")
                
                # ä¸ºæ¯ä¸ªè§†é¢‘åˆ›å»ºä»»åŠ¡
                task_list = []
                for video_url, title in videos:
                    task_data = {
                        'video_url': video_url,
                        'platform': platform,
                        'quality': request.quality,
                        'model_name': request.model_name,
                        'provider_id': request.provider_id,
                        'screenshot': request.screenshot,
                        'link': request.link,
                        'format': request.format,
                        'style': request.style,
                        'extras': request.extras,
                        'video_understanding': request.video_understanding,
                        'video_interval': request.video_interval,
                        'grid_size': request.grid_size,
                        'title': title
                    }
                    
                    task_id = task_queue.add_task(TaskType.SINGLE_VIDEO, task_data)
                    task_list.append(TaskInfo(
                        task_id=task_id,
                        video_url=video_url,
                        title=title
                    ))
                
                logger.info(f"âœ… å·²ä¸º {len(task_list)} ä¸ªè§†é¢‘åˆ›å»ºä»»åŠ¡")
                
                response_data = CollectionResponse(
                    is_collection=True,
                    total_videos=len(videos),
                    created_tasks=len(task_list),
                    task_list=task_list,
                    message=f"å·²æˆåŠŸä¸ºåˆé›†ä¸­çš„ {len(task_list)} ä¸ªè§†é¢‘åˆ›å»ºç¬”è®°ç”Ÿæˆä»»åŠ¡"
                )
                
                return StandardResponse(
                    success=True,
                    data=response_data,
                    message=f"åˆé›†å¤„ç†å®Œæˆï¼Œå…±åˆ›å»º {len(task_list)} ä¸ªä»»åŠ¡"
                )
                
        except Exception as e:
            logger.warning(f"âš ï¸ å¿«é€Ÿæå–å¤±è´¥: {e}")
        
        # å¦‚æœå¿«é€Ÿæå–å¤±è´¥ï¼Œå›é€€åˆ°å¼‚æ­¥å¤„ç†
        logger.info("ğŸ”„ å›é€€åˆ°å¼‚æ­¥å¤„ç†æ¨¡å¼")
        
        task_data = {
            'video_url': request.video_url,
            'platform': platform,
            'quality': request.quality,
            'model_name': request.model_name,
            'provider_id': request.provider_id,
            'screenshot': request.screenshot,
            'link': request.link,
            'format': request.format,
            'style': request.style,
            'extras': request.extras,
            'video_understanding': request.video_understanding,
            'video_interval': request.video_interval,
            'grid_size': request.grid_size,
            'max_collection_videos': request.max_collection_videos
        }
        
        collection_task_id = task_queue.add_task(TaskType.COLLECTION, task_data)
        logger.info(f"âœ… åˆé›†ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—: {collection_task_id}")
        
        response_data = CollectionResponse(
            is_collection=True,
            total_videos=0,
            created_tasks=0,
            task_list=[],
            message="åˆé›†æ£€æµ‹æˆåŠŸï¼Œæ­£åœ¨åå°è§£æå’Œåˆ›å»ºä»»åŠ¡ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»æŸ¥çœ‹ä»»åŠ¡åˆ—è¡¨"
        )
        
        return StandardResponse(
            success=True,
            data=response_data,
            message="åˆé›†å¤„ç†å·²å¼€å§‹ï¼Œæ­£åœ¨åå°è§£æè§†é¢‘åˆ—è¡¨"
        )
        
    except Exception as e:
        logger.error(f"âŒ å¤„ç†åˆé›†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†åˆé›†å¤±è´¥: {str(e)}")


async def handle_single_video_generation(
    request: VideoRequest, 
    platform: str
) -> StandardResponse[SingleVideoResponse]:
    """å¤„ç†å•è§†é¢‘ç”Ÿæˆè¯·æ±‚"""
    logger.info(f"ğŸ“º å¼€å§‹å¤„ç†å•è§†é¢‘: {request.video_url}")
    logger.info(f"ğŸ“Š å•è§†é¢‘å‚æ•°: platform={platform}")
    
    try:
        # å‡†å¤‡ä»»åŠ¡æ•°æ®
        task_data = {
            'video_url': request.video_url,
            'platform': platform,
            'quality': request.quality,
            'model_name': request.model_name,
            'provider_id': request.provider_id,
            'screenshot': request.screenshot,
            'link': request.link,
            'format': request.format,
            'style': request.style,
            'extras': request.extras,
            'video_understanding': request.video_understanding,
            'video_interval': request.video_interval,
            'grid_size': request.grid_size
        }
        
        # æ·»åŠ å•è§†é¢‘ä»»åŠ¡åˆ°é˜Ÿåˆ—
        task_id = task_queue.add_task(TaskType.SINGLE_VIDEO, task_data)
        logger.info(f"âœ… å•è§†é¢‘ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—: {task_id}")
        
        # è¿”å›å•è§†é¢‘å¤„ç†ç»“æœ
        response_data = SingleVideoResponse(
            is_collection=False,
            task_id=task_id
        )
        
        return StandardResponse(
            success=True,
            data=response_data,
            message="ç¬”è®°ç”Ÿæˆä»»åŠ¡å·²åˆ›å»º"
        )
        
    except Exception as e:
        logger.error(f"âŒ å¤„ç†å•è§†é¢‘å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†å•è§†é¢‘å¤±è´¥: {str(e)}")


@router.get("/task_status/{task_id}")
def get_task_status(task_id: str):
    # é¦–å…ˆæ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—ä¸­çš„çŠ¶æ€
    queue_task = task_queue.get_task_status(task_id)
    if queue_task:
        # åˆ é™¤é¢‘ç¹çš„çŠ¶æ€æŸ¥è¯¢æ—¥å¿—ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
        # logger.info(f"ğŸ” ä»ä»»åŠ¡é˜Ÿåˆ—è·å–çŠ¶æ€: {task_id} -> {queue_task.status.value}")
        
        # æ˜ å°„ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€åˆ°åŸæœ‰çŠ¶æ€
        status_mapping = {
            QueueTaskStatus.PENDING: TaskStatus.PENDING.value,
            QueueTaskStatus.RUNNING: TaskStatus.RUNNING.value,
            QueueTaskStatus.SUCCESS: TaskStatus.SUCCESS.value,
            QueueTaskStatus.FAILED: TaskStatus.FAILED.value
        }
        
        mapped_status = status_mapping.get(queue_task.status, TaskStatus.PENDING.value)
        
        if queue_task.status == QueueTaskStatus.FAILED:
            return R.error(queue_task.error_message or "ä»»åŠ¡å¤±è´¥", code=500)
        elif queue_task.status == QueueTaskStatus.SUCCESS:
            # ä»»åŠ¡æˆåŠŸï¼Œå°è¯•è¯»å–ç»“æœæ–‡ä»¶
            result_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json")
            if os.path.exists(result_path):
                with open(result_path, "r", encoding="utf-8") as f:
                    result_content = json.load(f)
                return R.success({
                    "status": mapped_status,
                    "result": result_content,
                    "message": "ä»»åŠ¡å®Œæˆ",
                    "task_id": task_id
                })
            else:
                return R.success({
                    "status": TaskStatus.PENDING.value,
                    "message": "ä»»åŠ¡å®Œæˆï¼Œä½†ç»“æœæ–‡ä»¶æœªæ‰¾åˆ°",
                    "task_id": task_id
                })
        else:
            # PENDING æˆ– RUNNING çŠ¶æ€
            message = "ä»»åŠ¡æ’é˜Ÿä¸­" if queue_task.status == QueueTaskStatus.PENDING else "ä»»åŠ¡å¤„ç†ä¸­"
            return R.success({
                "status": mapped_status,
                "message": message,
                "task_id": task_id
            })
    
    # ä»»åŠ¡é˜Ÿåˆ—ä¸­æ‰¾ä¸åˆ°ï¼Œæ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿ
    status_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.status.json")
    result_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json")

    # ä¼˜å…ˆè¯»çŠ¶æ€æ–‡ä»¶
    if os.path.exists(status_path):
        with open(status_path, "r", encoding="utf-8") as f:
            status_content = json.load(f)

        status = status_content.get("status")
        message = status_content.get("message", "")

        if status == TaskStatus.SUCCESS.value:
            # æˆåŠŸçŠ¶æ€çš„è¯ï¼Œç»§ç»­è¯»å–æœ€ç»ˆç¬”è®°å†…å®¹
            if os.path.exists(result_path):
                with open(result_path, "r", encoding="utf-8") as rf:
                    result_content = json.load(rf)
                return R.success({
                    "status": status,
                    "result": result_content,
                    "message": message,
                    "task_id": task_id
                })
            else:
                # ç†è®ºä¸Šä¸ä¼šå‡ºç°ï¼Œä¿é™©å¤„ç†
                return R.success({
                    "status": TaskStatus.PENDING.value,
                    "message": "ä»»åŠ¡å®Œæˆï¼Œä½†ç»“æœæ–‡ä»¶æœªæ‰¾åˆ°",
                    "task_id": task_id
                })

        if status == TaskStatus.FAILED.value:
            return R.error(message or "ä»»åŠ¡å¤±è´¥", code=500)

        # å¤„ç†ä¸­çŠ¶æ€
        return R.success({
            "status": status,
            "message": message,
            "task_id": task_id
        })

    # æ²¡æœ‰çŠ¶æ€æ–‡ä»¶ï¼Œä½†æœ‰ç»“æœ
    if os.path.exists(result_path):
        with open(result_path, "r", encoding="utf-8") as f:
            result_content = json.load(f)
        return R.success({
            "status": TaskStatus.SUCCESS.value,
            "result": result_content,
            "task_id": task_id
        })

    # ä»€ä¹ˆéƒ½æ²¡æœ‰ï¼Œé»˜è®¤PENDING
    return R.success({
        "status": TaskStatus.PENDING.value,
        "message": "ä»»åŠ¡æ’é˜Ÿä¸­",
        "task_id": task_id
    })


@router.get("/image_proxy")
async def image_proxy(request: Request, url: str):
    headers = {
        "Referer": "https://www.bilibili.com/",
        "User-Agent": request.headers.get("User-Agent", ""),
    }

    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            resp = await client.get(url, headers=headers)

            if resp.status_code != 200:
                raise HTTPException(status_code=resp.status_code, detail="å›¾ç‰‡è·å–å¤±è´¥")

            content_type = resp.headers.get("Content-Type", "image/jpeg")
            return StreamingResponse(
                resp.aiter_bytes(),
                media_type=content_type,
                headers={
                    "Cache-Control": "public, max-age=86400",  # âœ… ç¼“å­˜ä¸€å¤©
                    "Content-Type": content_type,
                }
            )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ä»»åŠ¡å¤„ç†é€»è¾‘å·²ç§»è‡³ app/core/task_queue.py ä¸­çš„ TaskQueue ç±»

import asyncio
import threading
from typing import List, Tuple

async def extract_collection_videos_with_timeout(
    url: str, 
    platform: str, 
    max_videos: int = 50,
    timeout_seconds: int = 8
) -> List[Tuple[str, str]]:
    """
    å¸¦è¶…æ—¶çš„åˆé›†è§†é¢‘æå–å‡½æ•°
    """
    logger.info(f"ğŸ•’ å¼€å§‹å¿«é€Ÿæå–åˆé›†è§†é¢‘ï¼Œè¶…æ—¶é™åˆ¶: {timeout_seconds}ç§’")
    
    result = {"videos": [], "error": None}
    
    def extract_thread():
        try:
            # è°ƒç”¨åŸæœ‰çš„æå–å‡½æ•°
            videos = extract_collection_videos(url, platform, max_videos)
            result["videos"] = videos
            
        except Exception as e:
            result["error"] = e
    
    # åœ¨çº¿ç¨‹ä¸­æ‰§è¡Œæå–
    thread = threading.Thread(target=extract_thread)
    thread.daemon = True
    thread.start()
    
    # ç­‰å¾…è¶…æ—¶
    thread.join(timeout=timeout_seconds)
    
    if thread.is_alive():
        logger.warning(f"âš ï¸ æå–è¶…æ—¶ ({timeout_seconds}ç§’)ï¼Œæ”¾å¼ƒå¿«é€Ÿæå–")
        return []
    
    if result["error"]:
        logger.warning(f"âš ï¸ æå–å‡ºé”™: {result['error']}")
        return []
    
    logger.info(f"âœ… å¿«é€Ÿæå–æˆåŠŸï¼Œè·å¾— {len(result['videos'])} ä¸ªè§†é¢‘")
    return result["videos"]

@router.get("/queue_status")
def get_queue_status():
    """è·å–ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€"""
    try:
        all_tasks = task_queue.get_all_tasks()
        
        queue_info = {
            "total_tasks": len(all_tasks),
            "pending_tasks": len([t for t in all_tasks.values() if t.status == QueueTaskStatus.PENDING]),
            "running_tasks": len([t for t in all_tasks.values() if t.status == QueueTaskStatus.RUNNING]),
            "completed_tasks": len([t for t in all_tasks.values() if t.status == QueueTaskStatus.SUCCESS]),
            "failed_tasks": len([t for t in all_tasks.values() if t.status == QueueTaskStatus.FAILED]),
            "tasks": []
        }
        
        # è¿”å›ä»»åŠ¡è¯¦æƒ…
        for task in all_tasks.values():
            task_info = {
                "task_id": task.task_id,
                "task_type": task.task_type.value,
                "status": task.status.value,
                "created_at": task.created_at,
                "started_at": task.started_at,
                "completed_at": task.completed_at,
                "video_url": task.data.get('video_url', ''),
                "title": task.data.get('title', 'æœªçŸ¥æ ‡é¢˜'),
                "error_message": task.error_message
            }
            queue_info["tasks"].append(task_info)
        
        return R.success(queue_info)
        
    except Exception as e:
        logger.error(f"âŒ è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {e}")
        return R.error(f"è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {str(e)}")

@router.get("/tasks/recent")
def get_recent_tasks(limit: int = 50):
    """è·å–æœ€è¿‘çš„ä»»åŠ¡åˆ—è¡¨ï¼ˆç”¨äºå‰ç«¯ä»»åŠ¡åˆ—è¡¨æ˜¾ç¤ºï¼‰"""
    try:
        all_tasks = task_queue.get_all_tasks()
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        sorted_tasks = sorted(all_tasks.values(), key=lambda x: x.created_at or 0, reverse=True)
        
        task_list = []
        for task in sorted_tasks[:limit]:
            # æ˜ å°„é˜Ÿåˆ—çŠ¶æ€åˆ°å‰ç«¯çŠ¶æ€
            frontend_status = "PENDING"
            if task.status == QueueTaskStatus.RUNNING:
                frontend_status = "RUNNING"
            elif task.status == QueueTaskStatus.SUCCESS:
                frontend_status = "SUCCESS"
            elif task.status == QueueTaskStatus.FAILED:
                frontend_status = "FAILED"
            
            task_info = {
                "task_id": task.task_id,
                "video_url": task.data.get('video_url', ''),
                "title": task.data.get('title', 'æœªçŸ¥æ ‡é¢˜'),
                "platform": task.data.get('platform', ''),
                "status": frontend_status,
                "created_at": task.created_at,
                "error_message": task.error_message
            }
            task_list.append(task_info)
        
        return R.success({
            "tasks": task_list,
            "total": len(sorted_tasks)
        })
        
    except Exception as e:
        logger.error(f"âŒ è·å–æœ€è¿‘ä»»åŠ¡å¤±è´¥: {e}")
        return R.error(f"è·å–æœ€è¿‘ä»»åŠ¡å¤±è´¥: {str(e)}")

@router.post("/retry_task/{task_id}")
def retry_task(task_id: str):
    """é‡è¯•å¤±è´¥çš„ä»»åŠ¡"""
    try:
        # é¦–å…ˆæ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—ä¸­æ˜¯å¦å­˜åœ¨è¯¥ä»»åŠ¡
        queue_task = task_queue.get_task_status(task_id)
        if queue_task:
            # åœ¨ä»»åŠ¡é˜Ÿåˆ—ä¸­é‡è¯•
            success = task_queue.retry_task(task_id)
            if success:
                logger.info(f"âœ… ä»»åŠ¡é‡è¯•æˆåŠŸ: {task_id}")
                return R.success({
                    "message": "ä»»åŠ¡å·²é‡æ–°æäº¤ï¼Œè¯·ç­‰å¾…å¤„ç†",
                    "task_id": task_id
                })
            else:
                return R.error("ä»»åŠ¡é‡è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»»åŠ¡çŠ¶æ€")
        
        # ä»»åŠ¡é˜Ÿåˆ—ä¸­æ²¡æœ‰ï¼Œæ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿä¸­çš„ä»»åŠ¡
        status_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.status.json")
        if os.path.exists(status_path):
            with open(status_path, "r", encoding="utf-8") as f:
                status_content = json.load(f)
            
            status = status_content.get("status")
            if status == TaskStatus.FAILED.value:
                # ä»æ–‡ä»¶ç³»ç»Ÿä¸­è¯»å–åŸå§‹ä»»åŠ¡æ•°æ®å¹¶é‡æ–°æäº¤
                # è¿™éœ€è¦æœ‰å­˜å‚¨åŸå§‹è¯·æ±‚å‚æ•°çš„æœºåˆ¶
                logger.warning(f"âš ï¸ ä»»åŠ¡ {task_id} åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­ï¼Œä½†æ— æ³•ç›´æ¥é‡è¯•ã€‚å»ºè®®é‡æ–°æäº¤æ–°ä»»åŠ¡ã€‚")
                return R.error("è¯¥ä»»åŠ¡æ— æ³•ç›´æ¥é‡è¯•ï¼Œè¯·é‡æ–°æäº¤æ–°ä»»åŠ¡")
            else:
                return R.error(f"ä»»åŠ¡çŠ¶æ€ä¸æ˜¯å¤±è´¥çŠ¶æ€ï¼Œæ— æ³•é‡è¯• (å½“å‰çŠ¶æ€: {status})")
        
        return R.error("ä»»åŠ¡ä¸å­˜åœ¨")
        
    except Exception as e:
        logger.error(f"âŒ é‡è¯•ä»»åŠ¡å¤±è´¥: {e}")
        return R.error(f"é‡è¯•ä»»åŠ¡å¤±è´¥: {str(e)}")

@router.post("/batch_retry_failed")
def batch_retry_failed_tasks():
    """æ‰¹é‡é‡è¯•æ‰€æœ‰å¤±è´¥çš„ä»»åŠ¡"""
    try:
        result = task_queue.batch_retry_failed_tasks()
        logger.info(f"âœ… æ‰¹é‡é‡è¯•å¤±è´¥ä»»åŠ¡å®Œæˆ: {result}")
        
        if result["retried_count"] > 0:
            return R.success({
                "retried_count": result["retried_count"],
                "total_failed": result["total_failed"],
                "message": result["message"]
            })
        else:
            return R.success({
                "retried_count": 0,
                "total_failed": 0,
                "message": "æ²¡æœ‰éœ€è¦é‡è¯•çš„å¤±è´¥ä»»åŠ¡"
            })
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡é‡è¯•å¤±è´¥ä»»åŠ¡å‡ºé”™: {e}")
        return R.error(f"æ‰¹é‡é‡è¯•å¤±è´¥: {str(e)}")

@router.post("/batch_retry_non_success")
def batch_retry_non_success_tasks():
    """æ‰¹é‡é‡è¯•æ‰€æœ‰éæˆåŠŸçŠ¶æ€çš„ä»»åŠ¡ï¼ˆåŒ…æ‹¬PENDINGã€RUNNINGã€FAILEDï¼‰"""
    try:
        # é¦–å…ˆå°è¯•é‡è¯•é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        queue_result = task_queue.batch_retry_non_success_tasks()
        logger.info(f"âœ… é˜Ÿåˆ—æ‰¹é‡é‡è¯•å®Œæˆ: {queue_result}")
        
        # å¦‚æœé˜Ÿåˆ—ä¸­æ²¡æœ‰éœ€è¦é‡è¯•çš„ä»»åŠ¡ï¼Œå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿé‡å»º
        if queue_result["retried_count"] == 0:
            logger.info("ğŸ” é˜Ÿåˆ—ä¸ºç©ºï¼Œå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿé‡å»ºéœ€è¦é‡è¯•çš„ä»»åŠ¡")
            
            # æ‰«ææ‰€æœ‰çŠ¶æ€æ–‡ä»¶ï¼ŒæŸ¥æ‰¾å¤±è´¥çš„ä»»åŠ¡
            rebuilt_count = 0
            status_files = glob.glob(os.path.join(NOTE_OUTPUT_DIR, "*.status.json"))
            
            for status_file in status_files:
                try:
                    task_id = os.path.basename(status_file).replace(".status.json", "")
                    
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²åœ¨é˜Ÿåˆ—ä¸­
                    if task_queue.get_task_status(task_id):
                        continue
                    
                    with open(status_file, "r", encoding="utf-8") as f:
                        status_content = json.load(f)
                    
                    status = status_content.get("status")
                    if status and status != TaskStatus.SUCCESS.value:
                        # å°è¯•é‡å»ºä»»åŠ¡
                        success = rebuild_task_from_files(task_id)
                        if success:
                            rebuilt_count += 1
                            logger.info(f"âœ… æˆåŠŸé‡å»ºä»»åŠ¡: {task_id}")
                        else:
                            logger.warning(f"âš ï¸ é‡å»ºä»»åŠ¡å¤±è´¥: {task_id}")
                            
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†çŠ¶æ€æ–‡ä»¶å¤±è´¥ {status_file}: {e}")
            
            if rebuilt_count > 0:
                logger.info(f"ğŸ”„ ä»æ–‡ä»¶ç³»ç»Ÿé‡å»ºäº† {rebuilt_count} ä¸ªä»»åŠ¡")
                return R.success({
                    "retried_count": rebuilt_count,
                    "total_non_success": rebuilt_count,
                    "rebuilt_from_files": True,
                    "message": f"ä»æ–‡ä»¶ç³»ç»Ÿé‡å»ºå¹¶é‡è¯•äº† {rebuilt_count} ä¸ªä»»åŠ¡"
                })
        
        # è¿”å›åŸå§‹é˜Ÿåˆ—é‡è¯•ç»“æœ
        if queue_result["retried_count"] > 0:
            return R.success({
                "retried_count": queue_result["retried_count"],
                "total_non_success": queue_result["total_non_success"],
                "pending_count": queue_result["pending_count"],
                "running_count": queue_result["running_count"],
                "failed_count": queue_result["failed_count"],
                "message": queue_result["message"]
            })
        else:
            return R.success({
                "retried_count": 0,
                "total_non_success": 0,
                "message": "æ²¡æœ‰éœ€è¦é‡è¯•çš„éæˆåŠŸä»»åŠ¡"
            })
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡é‡è¯•éæˆåŠŸä»»åŠ¡å‡ºé”™: {e}")
        return R.error(f"æ‰¹é‡é‡è¯•éæˆåŠŸä»»åŠ¡å¤±è´¥: {str(e)}")

def rebuild_task_from_files(task_id: str) -> bool:
    """ä»æ–‡ä»¶ç³»ç»Ÿé‡å»ºä»»åŠ¡"""
    try:
        from app.core.task_queue import TaskType
        from app.enmus.note_enums import DownloadQuality
        
        # æ£€æŸ¥éŸ³é¢‘metadataæ–‡ä»¶ï¼ˆåˆ†ç¦»æ–‡ä»¶æ¨¡å¼ï¼‰
        audio_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}_audio.json")
        result_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json")
        
        # é¦–å…ˆå°è¯•ä»éŸ³é¢‘metadataæ–‡ä»¶è·å–ä¿¡æ¯
        if os.path.exists(audio_path):
            try:
                with open(audio_path, "r", encoding="utf-8") as f:
                    audio_data = json.load(f)
                
                video_url = audio_data.get("file_path", "")
                platform = audio_data.get("platform", "")
                title = audio_data.get("title", "æœªçŸ¥æ ‡é¢˜")
                
                if video_url and platform:
                    try:
                        task_data = {
                            'video_url': video_url,
                            'platform': platform,
                            'quality': DownloadQuality.fast,
                            'model_name': 'gpt-4o-mini',
                            'provider_id': 'openai',
                            'screenshot': False,
                            'link': False,
                            'format': [],
                            'style': 'ç®€æ´',
                            'extras': None,
                            'video_understanding': False,
                            'video_interval': 0,
                            'grid_size': [],
                            'title': title
                        }
                        
                        task_queue.add_task(
                            task_type=TaskType.SINGLE_VIDEO, 
                            data=task_data,
                            task_id=task_id
                        )
                        return True
                    except Exception as task_error:
                        logger.error(f"âŒ ä»éŸ³é¢‘metadataåˆ›å»ºä»»åŠ¡å¤±è´¥: {task_id}, {task_error}")
                        # åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•æ¸…ç©ºé‡ç½®
                        return clear_and_reset_task(task_id)
                    
            except Exception as e:
                logger.error(f"âŒ ä»éŸ³é¢‘metadataé‡å»ºä»»åŠ¡å¤±è´¥: {task_id}, {e}")
                # è¯»å–éŸ³é¢‘metadataæ–‡ä»¶å¤±è´¥ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
                logger.info(f"ğŸ”„ éŸ³é¢‘metadataæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                return clear_and_reset_task(task_id)
        
        # å¦‚æœéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä»ä¸»ç»“æœæ–‡ä»¶è¯»å–
        if os.path.exists(result_path):
            try:
                with open(result_path, "r", encoding="utf-8") as f:
                    result_data = json.load(f)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºé”™è¯¯æ–‡ä»¶
                if "error" in result_data:
                    logger.warning(f"âš ï¸ å‘ç°é”™è¯¯æ–‡ä»¶ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                    return clear_and_reset_task(task_id, result_data)
                
                if "audioMeta" in result_data:
                    audio_meta = result_data.get("audioMeta", {})
                    video_url = audio_meta.get("file_path", "")
                    platform = audio_meta.get("platform", "")
                    title = audio_meta.get("title", "æœªçŸ¥æ ‡é¢˜")
                    
                    if video_url and platform:
                        try:
                            task_data = {
                                'video_url': video_url,
                                'platform': platform,
                                'quality': DownloadQuality.fast,
                                'model_name': 'gpt-4o-mini',
                                'provider_id': 'openai',
                                'screenshot': False,
                                'link': False,
                                'format': [],
                                'style': 'ç®€æ´',
                                'extras': None,
                                'video_understanding': False,
                                'video_interval': 0,
                                'grid_size': [],
                                'title': title
                            }
                            
                            task_queue.add_task(
                                task_type=TaskType.SINGLE_VIDEO, 
                                data=task_data,
                                task_id=task_id
                            )
                            return True
                        except Exception as task_error:
                            logger.error(f"âŒ ä»ç»“æœæ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥: {task_id}, {task_error}")
                            # åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•æ¸…ç©ºé‡ç½®
                            return clear_and_reset_task(task_id, result_data)
                else:
                    # ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
                    logger.warning(f"âš ï¸ ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®: {task_id}")
                    logger.info(f"ğŸ”„ ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                    return clear_and_reset_task(task_id, result_data)
                        
            except Exception as e:
                logger.error(f"âŒ ä»ç»“æœæ–‡ä»¶é‡å»ºä»»åŠ¡å¤±è´¥: {task_id}, {e}")
                # è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
                logger.info(f"ğŸ”„ ç»“æœæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                return clear_and_reset_task(task_id)
        else:
            # æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶: {task_id}")
            logger.info(f"ğŸ”„ æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
            return clear_and_reset_task(task_id)
        
        # å¦‚æœéƒ½æ— æ³•é‡å»ºï¼Œå°è¯•æ¸…ç©ºé‡ç½®
        logger.warning(f"âš ï¸ æ— æ³•é‡å»ºä»»åŠ¡ï¼Œå°è¯•æ¸…ç©ºé‡ç½®: {task_id}")
        return clear_and_reset_task(task_id)
        
    except Exception as e:
        logger.error(f"âŒ é‡å»ºä»»åŠ¡å‡ºé”™: {task_id}, {e}")
        return False

def clear_and_reset_task(task_id: str, error_data: dict = None) -> bool:
    """æ¸…ç©ºä»»åŠ¡ç›¸å…³æ–‡ä»¶å¹¶å°è¯•é‡ç½®ä»»åŠ¡"""
    try:
        from app.core.task_queue import TaskType
        from app.enmus.note_enums import DownloadQuality
        
        logger.info(f"ğŸ§¹ å¼€å§‹æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
        
        # å°è¯•ä»å¤šä¸ªæ¥æºæå–åŸå§‹ä¿¡æ¯
        original_url = None
        original_platform = None
        original_title = "é‡ç½®ä»»åŠ¡"
        
        # 1. ä¼˜å…ˆä»æŒä¹…åŒ–çš„åŸå§‹è¯·æ±‚æ•°æ®ä¸­æå–
        request_file_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.request.json")
        if os.path.exists(request_file_path):
            try:
                with open(request_file_path, "r", encoding="utf-8") as f:
                    request_data = json.load(f)
                
                original_request = request_data.get("original_request", {})
                if original_request:
                    original_url = original_request.get("video_url")
                    original_platform = original_request.get("platform")
                    original_title = original_request.get("title", "é‡ç½®ä»»åŠ¡")
                    
                    if original_url:
                        logger.info(f"âœ… ä»æŒä¹…åŒ–è¯·æ±‚æ•°æ®ä¸­æ‰¾åˆ°åŸå§‹URL: {original_url}")
                        
            except Exception as e:
                logger.warning(f"âš ï¸ è¯»å–æŒä¹…åŒ–è¯·æ±‚æ•°æ®å¤±è´¥: {e}")
        
        # 2. å¦‚æœæŒä¹…åŒ–æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»é”™è¯¯æ•°æ®ä¸­æå–
        if not original_url and error_data and isinstance(error_data, dict):
            # å°è¯•ä»é”™è¯¯ä¿¡æ¯ä¸­æå–åŸå§‹URL
            if "url" in error_data:
                original_url = error_data["url"]
            elif "video_url" in error_data:
                original_url = error_data["video_url"]
            elif "request_data" in error_data:
                request_data = error_data["request_data"]
                if isinstance(request_data, dict):
                    original_url = request_data.get("video_url")
                    original_platform = request_data.get("platform")
                    original_title = request_data.get("title", "é‡ç½®ä»»åŠ¡")
            # å°è¯•ä»audioMetaä¸­æå–
            elif "audioMeta" in error_data:
                audio_meta = error_data["audioMeta"]
                if isinstance(audio_meta, dict):
                    file_path = audio_meta.get("file_path", "")
                    video_id = audio_meta.get("video_id", "")
                    original_platform = audio_meta.get("platform", "")
                    original_title = audio_meta.get("title", "é‡ç½®ä»»åŠ¡")
                    
                    # å¦‚æœæ˜¯BVå·ï¼Œè½¬æ¢ä¸ºBç«™URL
                    if video_id and video_id.startswith("BV"):
                        original_url = f"https://www.bilibili.com/video/{video_id}"
                        original_platform = "bilibili"
                    elif file_path and "http" in file_path:
                        original_url = file_path
        
        # 3. å¦‚æœé”™è¯¯æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»ä»»åŠ¡çŠ¶æ€æ–‡ä»¶ä¸­æå–
        if not original_url:
            status_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.status.json")
            if os.path.exists(status_path):
                try:
                    with open(status_path, "r", encoding="utf-8") as f:
                        status_data = json.load(f)
                    
                    # ä»çŠ¶æ€æ–‡ä»¶ä¸­æå–åŸå§‹ä¿¡æ¯
                    if "original_request" in status_data:
                        orig_req = status_data["original_request"]
                        original_url = orig_req.get("video_url")
                        original_platform = orig_req.get("platform")
                        original_title = orig_req.get("title", "é‡ç½®ä»»åŠ¡")
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
        
        # 4. å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»éŸ³é¢‘metadataæ–‡ä»¶ä¸­æå–
        if not original_url:
            audio_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}_audio.json")
            if os.path.exists(audio_path):
                try:
                    with open(audio_path, "r", encoding="utf-8") as f:
                        audio_data = json.load(f)
                    
                    file_path = audio_data.get("file_path", "")
                    video_id = audio_data.get("video_id", "")
                    original_platform = audio_data.get("platform", "")
                    original_title = audio_data.get("title", "é‡ç½®ä»»åŠ¡")
                    raw_info = audio_data.get("raw_info", {})
                    
                    # ä¼˜å…ˆæ£€æŸ¥ raw_info ä¸­æ˜¯å¦æœ‰åŸå§‹URLä¿¡æ¯
                    if raw_info and isinstance(raw_info, dict):
                        if "webpage_url" in raw_info:
                            original_url = raw_info["webpage_url"]
                            logger.info(f"ğŸ” ä»raw_infoä¸­æ‰¾åˆ°åŸå§‹URL: {original_url}")
                        elif "original_url" in raw_info:
                            original_url = raw_info["original_url"]
                            logger.info(f"ğŸ” ä»raw_infoä¸­æ‰¾åˆ°åŸå§‹URL: {original_url}")
                    
                    # å¦‚æœ raw_info ä¸­æ²¡æœ‰ï¼Œå°è¯•ç”¨ video_id é‡æ„
                    if not original_url and video_id:
                        if video_id.startswith("BV"):
                            # æ£€æŸ¥ video_id ä¸­æ˜¯å¦åŒ…å«åˆ†Pä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼šBV1pwj2zxEL9_p64ï¼‰
                            if "_p" in video_id:
                                base_bv, p_part = video_id.split("_p", 1)
                                try:
                                    p_num = int(p_part)
                                    original_url = f"https://www.bilibili.com/video/{base_bv}?p={p_num}"
                                    logger.info(f"ğŸ”„ é‡æ„åˆ†Pè§†é¢‘URL: {video_id} -> {original_url}")
                                except ValueError:
                                    # åˆ†Pç¼–å·æ— æ•ˆï¼Œä½¿ç”¨åŸºç¡€BVå·
                                    original_url = f"https://www.bilibili.com/video/{base_bv}"
                                    logger.info(f"ğŸ”„ é‡æ„è§†é¢‘URL (å¿½ç•¥æ— æ•ˆåˆ†P): {video_id} -> {original_url}")
                            else:
                                # æ™®é€šBVå·
                                original_url = f"https://www.bilibili.com/video/{video_id}"
                                logger.info(f"ğŸ”„ é‡æ„è§†é¢‘URL: {video_id} -> {original_url}")
                            original_platform = "bilibili"
                        else:
                            logger.warning(f"âš ï¸ æ— æ³•è¯†åˆ«çš„video_idæ ¼å¼: {video_id}")
                    
                    # æœ€åæ£€æŸ¥file_pathæ˜¯å¦åŒ…å«HTTP URLï¼ˆç”¨äºå…¶ä»–å¹³å°ï¼‰
                    if not original_url and file_path and "http" in file_path:
                        original_url = file_path
                        logger.info(f"ğŸ”„ ä½¿ç”¨file_pathä½œä¸ºURL: {file_path}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–éŸ³é¢‘metadataæ–‡ä»¶å¤±è´¥: {e}")
        
        # æ¸…ç©ºç›¸å…³æ–‡ä»¶ï¼ˆä¿ç•™åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶ï¼‰
        files_to_clean = [
            f"{task_id}.json",          # ç»“æœæ–‡ä»¶
            f"{task_id}.status.json",   # çŠ¶æ€æ–‡ä»¶
            # f"{task_id}.request.json",  # ğŸ”’ ä¿ç•™åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶ï¼Œä¸åˆ é™¤
            f"{task_id}_audio.json",    # éŸ³é¢‘metadataæ–‡ä»¶
            f"{task_id}_audio.wav",     # éŸ³é¢‘æ–‡ä»¶
            f"{task_id}_audio.mp3",     # éŸ³é¢‘æ–‡ä»¶
            f"{task_id}.wav",           # éŸ³é¢‘æ–‡ä»¶
            f"{task_id}.mp3",           # éŸ³é¢‘æ–‡ä»¶
        ]
        
        cleaned_files = []
        for filename in files_to_clean:
            file_path = os.path.join(NOTE_OUTPUT_DIR, filename)
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    cleaned_files.append(filename)
                    logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤æ–‡ä»¶: {filename}")
                except Exception as e:
                    logger.warning(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥ {filename}: {e}")
        
        logger.info(f"ğŸ§¹ æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {len(cleaned_files)} ä¸ªæ–‡ä»¶")
        
        # å¦‚æœæ‰¾åˆ°äº†åŸå§‹URLï¼Œé‡æ–°åˆ›å»ºä»»åŠ¡
        if original_url:
            # å°è¯•è¯†åˆ«å¹³å°
            if not original_platform:
                if "bilibili.com" in original_url or "b23.tv" in original_url:
                    original_platform = "bilibili"
                elif "youtube.com" in original_url or "youtu.be" in original_url:
                    original_platform = "youtube"
                else:
                    original_platform = "unknown"
            
            logger.info(f"ğŸ”„ ä½¿ç”¨åŸå§‹URLé‡æ–°åˆ›å»ºä»»åŠ¡: {original_url}")
            
            try:
                task_data = {
                    'video_url': original_url,
                    'platform': original_platform,
                    'quality': DownloadQuality.fast,
                    'model_name': 'gpt-4o-mini',
                    'provider_id': 'openai',
                    'screenshot': False,
                    'link': False,
                    'format': [],
                    'style': 'ç®€æ´',
                    'extras': None,
                    'video_understanding': False,
                    'video_interval': 0,
                    'grid_size': [],
                    'title': original_title
                }
                
                # ä½¿ç”¨åŸtask_idé‡æ–°åˆ›å»ºä»»åŠ¡
                new_task_id = task_queue.add_task(
                    task_type=TaskType.SINGLE_VIDEO, 
                    data=task_data,
                    task_id=task_id
                )
                
                logger.info(f"âœ… ä»»åŠ¡é˜Ÿåˆ—æ·»åŠ æˆåŠŸ: {task_id}")
                
                # æ›´æ–°åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶ï¼ˆä¿å­˜æ–°çš„ä»»åŠ¡æ•°æ®ï¼‰
                try:
                    updated_request_data = {
                        "task_id": task_id,
                        "created_at": time.time(),
                        "created_at_iso": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
                        "reset_count": 1,  # æ ‡è®°è¿™æ˜¯é‡ç½®ä»»åŠ¡
                        "original_request": {
                            "video_url": original_url,
                            "platform": original_platform,
                            "title": original_title,
                            "quality": task_data.get('quality', DownloadQuality.fast),
                            "model_name": task_data.get('model_name', 'gpt-4o-mini'),
                            "provider_id": task_data.get('provider_id', 'openai'),
                            "screenshot": task_data.get('screenshot', False),
                            "link": task_data.get('link', False),
                            "format": task_data.get('format', []),
                            "style": task_data.get('style', 'ç®€æ´'),
                            "extras": task_data.get('extras', None),
                            "video_understanding": task_data.get('video_understanding', False),
                            "video_interval": task_data.get('video_interval', 0),
                            "grid_size": task_data.get('grid_size', [])
                        }
                    }
                    
                    request_file_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.request.json")
                    with open(request_file_path, "w", encoding="utf-8") as f:
                        json.dump(updated_request_data, f, ensure_ascii=False, indent=2)
                    
                    logger.info(f"ğŸ“ å·²æ›´æ–°åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶: {task_id}")
                    
                except Exception as save_error:
                    logger.warning(f"âš ï¸ æ›´æ–°åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶å¤±è´¥: {save_error}")
                
                logger.info(f"âœ… ä»»åŠ¡æ¸…ç©ºé‡ç½®æˆåŠŸ: {task_id} -> æ–°URL: {original_url}")
                return True
                
            except Exception as task_create_error:
                logger.error(f"âŒ åˆ›å»ºä»»åŠ¡ç¥å¥‡çš„å¤±è´¥: {task_id}, {task_create_error}, {traceback.format_exc()}")
                logger.warning(f"âš ï¸ ä»»åŠ¡åˆ›å»ºå¤±è´¥ä½†æ–‡ä»¶å·²æ¸…ç©ºï¼Œç»§ç»­å¤„ç†: {task_id}")
                # ä»»åŠ¡åˆ›å»ºå¤±è´¥ï¼Œä½†æ–‡ä»¶æ¸…ç©ºæˆåŠŸï¼Œä¹Ÿè®¤ä¸ºæ˜¯éƒ¨åˆ†æˆåŠŸ
                return len(cleaned_files) > 0
        else:
            logger.warning(f"âš ï¸ æ— æ³•æ‰¾åˆ°åŸå§‹URLï¼Œåªèƒ½æ¸…ç©ºæ–‡ä»¶: {task_id}ï¼Œ {error_data}")
            # å³ä½¿æ— æ³•é‡æ–°åˆ›å»ºï¼Œæ¸…ç©ºæ–‡ä»¶ä¹Ÿç®—æˆåŠŸ
            return len(cleaned_files) > 0
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç©ºé‡ç½®ä»»åŠ¡å¤±è´¥: {task_id}, {e}")
        return False

class ValidateTasksRequest(BaseModel):
    """éªŒè¯ä»»åŠ¡è¯·æ±‚æ¨¡å‹"""
    task_ids: List[str]

@router.post("/validate_tasks")
def validate_tasks(request: ValidateTasksRequest):
    """éªŒè¯å‰ç«¯ä»»åŠ¡IDåˆ—è¡¨ï¼Œè¿”å›çœŸæ­£éœ€è¦é‡è¯•çš„ä»»åŠ¡çŠ¶æ€"""
    try:
        task_ids = request.task_ids
        validation_results = []
        
        for task_id in task_ids:
            # æ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—ä¸­çš„çŠ¶æ€
            queue_task = task_queue.get_task_status(task_id)
            if queue_task:
                # ä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­ï¼Œè¿”å›é˜Ÿåˆ—çŠ¶æ€
                validation_results.append({
                    "task_id": task_id,
                    "exists_in_queue": True,
                    "status": queue_task.status.value,
                    "needs_retry": queue_task.status != QueueTaskStatus.SUCCESS,
                    "error_message": queue_task.error_message
                })
            else:
                # ä»»åŠ¡ä¸åœ¨é˜Ÿåˆ—ä¸­ï¼Œæ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿ
                status_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.status.json")
                result_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json")
                
                if os.path.exists(status_path):
                    try:
                        with open(status_path, "r", encoding="utf-8") as f:
                            status_content = json.load(f)
                        status = status_content.get("status")
                        validation_results.append({
                            "task_id": task_id,
                            "exists_in_queue": False,
                            "status": status,
                            "needs_retry": status != TaskStatus.SUCCESS.value,
                            "error_message": status_content.get("message")
                        })
                    except Exception as e:
                        validation_results.append({
                            "task_id": task_id,
                            "exists_in_queue": False,
                            "status": "UNKNOWN",
                            "needs_retry": True,
                            "error_message": f"è¯»å–çŠ¶æ€æ–‡ä»¶å¤±è´¥: {str(e)}"
                        })
                elif os.path.exists(result_path):
                    # åªæœ‰ç»“æœæ–‡ä»¶ï¼Œè¯´æ˜ä»»åŠ¡å·²å®Œæˆ
                    validation_results.append({
                        "task_id": task_id,
                        "exists_in_queue": False,
                        "status": TaskStatus.SUCCESS.value,
                        "needs_retry": False,
                        "error_message": None
                    })
                else:
                    # ä»€ä¹ˆéƒ½æ²¡æœ‰ï¼Œä»»åŠ¡ä¸å­˜åœ¨
                    validation_results.append({
                        "task_id": task_id,
                        "exists_in_queue": False,
                        "status": "NOT_FOUND",
                        "needs_retry": False,
                        "error_message": "ä»»åŠ¡ä¸å­˜åœ¨"
                    })
        
        # ç»Ÿè®¡ç»“æœ
        needs_retry_count = len([r for r in validation_results if r["needs_retry"]])
        total_tasks = len(validation_results)
        
        logger.info(f"âœ… ä»»åŠ¡éªŒè¯å®Œæˆ: æ€»æ•°={total_tasks}, éœ€é‡è¯•={needs_retry_count}")
        
        return R.success({
            "validation_results": validation_results,
            "total_tasks": total_tasks,
            "needs_retry_count": needs_retry_count,
            "message": f"éªŒè¯å®Œæˆï¼š{total_tasks}ä¸ªä»»åŠ¡ä¸­æœ‰{needs_retry_count}ä¸ªéœ€è¦é‡è¯•"
        })
        
    except Exception as e:
        logger.error(f"âŒ éªŒè¯ä»»åŠ¡çŠ¶æ€å‡ºé”™: {e}")
        return R.error(f"éªŒè¯ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")

class ForceRetryRequest(BaseModel):
    """å¼ºåˆ¶é‡è¯•è¯·æ±‚æ¨¡å‹"""
    model_name: Optional[str] = None
    provider_id: Optional[str] = None
    style: Optional[str] = None
    format: Optional[list] = None
    video_understanding: Optional[bool] = None
    video_interval: Optional[int] = None

@router.post("/force_retry_all")
def force_retry_all_tasks(request: Optional[ForceRetryRequest] = None):
    """å¼ºåˆ¶é‡è¯•æ‰€æœ‰ä»»åŠ¡ï¼Œä½¿ç”¨æœ€æ–°é…ç½®"""
    try:
        # æ„å»ºæ–°çš„ä»»åŠ¡é…ç½®
        new_task_data = {}
        if request:
            if request.model_name:
                new_task_data['model_name'] = request.model_name
            if request.provider_id:
                new_task_data['provider_id'] = request.provider_id
            if request.style:
                new_task_data['style'] = request.style
            if request.format:
                new_task_data['format'] = request.format
            if request.video_understanding is not None:
                new_task_data['video_understanding'] = request.video_understanding
            if request.video_interval is not None:
                new_task_data['video_interval'] = request.video_interval
        
        result = task_queue.force_retry_all_tasks(new_task_data if new_task_data else None)
        logger.info(f"âœ… å¼ºåˆ¶æ‰¹é‡é‡è¯•æ‰€æœ‰ä»»åŠ¡å®Œæˆ: {result}")
        
        return R.success({
            "retried_count": result["retried_count"],
            "total_tasks": result["total_tasks"],
            "message": result["message"],
            "updated_config": new_task_data
        })
        
    except Exception as e:
        logger.error(f"âŒ å¼ºåˆ¶æ‰¹é‡é‡è¯•æ‰€æœ‰ä»»åŠ¡å‡ºé”™: {e}")
        return R.error(f"å¼ºåˆ¶æ‰¹é‡é‡è¯•å¤±è´¥: {str(e)}")

@router.post("/force_retry_task/{task_id}")
def force_retry_task(task_id: str, request: Optional[ForceRetryRequest] = None):
    """å¼ºåˆ¶é‡è¯•å•ä¸ªä»»åŠ¡ï¼ˆåŒ…æ‹¬æˆåŠŸçŠ¶æ€çš„ä»»åŠ¡ï¼‰"""
    try:
        from app.core.task_queue import TaskStatus as QueueTaskStatus, TaskType
        
        # é¦–å…ˆæ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—ä¸­æ˜¯å¦å­˜åœ¨è¯¥ä»»åŠ¡
        queue_task = task_queue.get_task_status(task_id)
        if queue_task:
            # å¼ºåˆ¶é‡è¯•ï¼Œä¸æ£€æŸ¥çŠ¶æ€
            with task_queue._lock:
                task = task_queue.tasks.get(task_id)
                if task:
                    # å¦‚æœæœ‰æ–°çš„é…ç½®ï¼Œæ›´æ–°ä»»åŠ¡æ•°æ®
                    if request and hasattr(request, 'model_name') and request.model_name:
                        task.data['model_name'] = request.model_name
                    if request and hasattr(request, 'provider_id') and request.provider_id:
                        task.data['provider_id'] = request.provider_id
                    if request and hasattr(request, 'style') and request.style:
                        task.data['style'] = request.style
                    if request and hasattr(request, 'format') and request.format:
                        task.data['format'] = request.format
                    if request and hasattr(request, 'video_understanding') and request.video_understanding is not None:
                        task.data['video_understanding'] = request.video_understanding
                    if request and hasattr(request, 'video_interval') and request.video_interval is not None:
                        task.data['video_interval'] = request.video_interval
                    
                    # é‡ç½®ä»»åŠ¡çŠ¶æ€
                    task.status = QueueTaskStatus.PENDING
                    task.started_at = None
                    task.completed_at = None
                    task.error_message = None
                    task.result = None
                    
                    # é‡æ–°æäº¤åˆ°é˜Ÿåˆ—
                    task_queue.task_queue.put(task)
                    
                    logger.info(f"âœ… å¼ºåˆ¶é‡è¯•ä»»åŠ¡æˆåŠŸ: {task_id}")
                    return R.success({
                        "message": "ä»»åŠ¡å·²å¼ºåˆ¶é‡æ–°æäº¤ï¼Œè¯·ç­‰å¾…å¤„ç†",
                        "task_id": task_id
                    })
                else:
                    return R.error("ä»»åŠ¡ä¸å­˜åœ¨")
        
        # ä»»åŠ¡ä¸åœ¨é˜Ÿåˆ—ä¸­ï¼Œä¼˜å…ˆå°è¯•ä»æŒä¹…åŒ–çš„åŸå§‹è¯·æ±‚æ•°æ®é‡å»º
        logger.info(f"ğŸ” ä»»åŠ¡ä¸åœ¨é˜Ÿåˆ—ä¸­ï¼Œå°è¯•ä»æŒä¹…åŒ–çš„åŸå§‹è¯·æ±‚æ•°æ®é‡å»º: {task_id}")
        
        try:
            # åŠ è½½æŒä¹…åŒ–çš„åŸå§‹è¯·æ±‚æ•°æ®
            original_request_data = load_original_request_data(task_id)
            
            if original_request_data:
                video_url = original_request_data.get('video_url')
                platform = original_request_data.get('platform')
                title = original_request_data.get('title', 'æœªçŸ¥æ ‡é¢˜')
                
                if video_url and platform:
                    try:
                        from app.enmus.note_enums import DownloadQuality
                        
                        # æ„å»ºä»»åŠ¡æ•°æ®ï¼Œä½¿ç”¨æŒä¹…åŒ–æ•°æ®ï¼Œå¯èƒ½ä¼šè¢«è¯·æ±‚ä¸­çš„æ–°é…ç½®è¦†ç›–
                        task_data = {
                            'video_url': video_url,
                            'platform': platform,
                            'quality': original_request_data.get('quality', DownloadQuality.fast),
                            'model_name': request.model_name if request and request.model_name else original_request_data.get('model_name', 'gpt-4o-mini'),
                            'provider_id': request.provider_id if request and request.provider_id else original_request_data.get('provider_id', 'openai'),
                            'screenshot': original_request_data.get('screenshot', False),
                            'link': original_request_data.get('link', False),
                            'format': request.format if request and request.format else original_request_data.get('format', []),
                            'style': request.style if request and request.style else original_request_data.get('style', 'ç®€æ´'),
                            'extras': original_request_data.get('extras', None),
                            'video_understanding': request.video_understanding if request and request.video_understanding is not None else original_request_data.get('video_understanding', False),
                            'video_interval': request.video_interval if request and request.video_interval is not None else original_request_data.get('video_interval', 0),
                            'grid_size': original_request_data.get('grid_size', []),
                            'title': title
                        }
                        
                        # ä½¿ç”¨åŸtask_idé‡æ–°åˆ›å»ºä»»åŠ¡
                        new_task_id = task_queue.add_task(
                            task_type=TaskType.SINGLE_VIDEO, 
                            data=task_data,
                            task_id=task_id  # ä½¿ç”¨åŸæœ‰çš„task_id
                        )
                        
                        logger.info(f"âœ… ä»æŒä¹…åŒ–åŸå§‹è¯·æ±‚æ•°æ®é‡å»ºä»»åŠ¡æˆåŠŸ: {task_id}, æ ‡é¢˜: {title}")
                        return R.success({
                            "message": f"ä»»åŠ¡å·²ä»æŒä¹…åŒ–æ•°æ®é‡å»ºå¹¶é‡æ–°æäº¤ï¼Œæ ‡é¢˜: {title}",
                            "task_id": task_id,
                            "video_url": video_url,
                            "title": title
                        })
                    except Exception as task_error:
                        logger.error(f"âŒ ä»æŒä¹…åŒ–æ•°æ®åˆ›å»ºä»»åŠ¡å¤±è´¥: {task_id}, {task_error}")
                        logger.warning(f"âš ï¸ æŒä¹…åŒ–æ•°æ®åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹æ³•: {task_id}")
                else:
                    logger.warning(f"âš ï¸ æŒä¹…åŒ–æ•°æ®ä¸­ç¼ºå°‘å¿…è¦çš„video_urlæˆ–platform: {task_id}")
            else:
                logger.info(f"ğŸ“‹ æœªæ‰¾åˆ°æŒä¹…åŒ–çš„åŸå§‹è¯·æ±‚æ•°æ®: {task_id}")
                
        except Exception as e:
            logger.error(f"âŒ ä»æŒä¹…åŒ–æ•°æ®é‡å»ºä»»åŠ¡å¤±è´¥: {task_id}, {e}")
        
        # ä»»åŠ¡ä¸åœ¨é˜Ÿåˆ—ä¸­ï¼Œä¸”æ²¡æœ‰æŒä¹…åŒ–æ•°æ®ï¼Œå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿé‡å»ºä»»åŠ¡
        logger.info(f"ğŸ” å°è¯•ä»æ–‡ä»¶ç³»ç»Ÿé‡å»ºä»»åŠ¡: {task_id}")
        
        # æ£€æŸ¥ç»“æœæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆåŒ…å«åŸå§‹ä»»åŠ¡æ•°æ®ï¼‰
        result_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.json")
        audio_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}_audio.json")
        
        # é¦–å…ˆå°è¯•ä»éŸ³é¢‘metadataæ–‡ä»¶è·å–ä¿¡æ¯ï¼ˆåˆ†ç¦»æ–‡ä»¶æ¨¡å¼ï¼‰
        if os.path.exists(audio_path):
            try:
                with open(audio_path, "r", encoding="utf-8") as f:
                    audio_data = json.load(f)
                
                # ä»éŸ³é¢‘æ–‡ä»¶æå–åŸå§‹ä»»åŠ¡æ•°æ®
                video_url = audio_data.get("file_path", "")
                platform = audio_data.get("platform", "")
                title = audio_data.get("title", "æœªçŸ¥æ ‡é¢˜")
                
                if video_url and platform:
                    try:
                        # é‡å»ºä»»åŠ¡æ•°æ®ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
                        from app.enmus.note_enums import DownloadQuality
                        
                        task_data = {
                            'video_url': video_url,
                            'platform': platform,
                            'quality': DownloadQuality.fast,
                            'model_name': request.model_name if request and request.model_name else 'gpt-4o-mini',
                            'provider_id': request.provider_id if request and request.provider_id else 'openai',
                            'screenshot': False,
                            'link': False,
                            'format': request.format if request and request.format else [],
                            'style': request.style if request and request.style else 'ç®€æ´',
                            'extras': None,
                            'video_understanding': request.video_understanding if request and request.video_understanding is not None else False,
                            'video_interval': request.video_interval if request and request.video_interval is not None else 0,
                            'grid_size': [],
                            'title': title
                        }
                        
                        # ä½¿ç”¨åŸtask_idé‡æ–°åˆ›å»ºä»»åŠ¡
                        new_task_id = task_queue.add_task(
                            task_type=TaskType.SINGLE_VIDEO, 
                            data=task_data,
                            task_id=task_id  # ä½¿ç”¨åŸæœ‰çš„task_id
                        )
                        
                        logger.info(f"âœ… ä»éŸ³é¢‘metadataæ–‡ä»¶é‡å»ºä»»åŠ¡æˆåŠŸ: {task_id}")
                        return R.success({
                            "message": f"ä»»åŠ¡å·²ä»éŸ³é¢‘æ–‡ä»¶é‡å»ºå¹¶é‡æ–°æäº¤ï¼Œæ ‡é¢˜: {title}",
                            "task_id": task_id
                        })
                    except Exception as task_error:
                        logger.error(f"âŒ ä»éŸ³é¢‘æ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥: {task_id}, {task_error}")
                        logger.warning(f"âš ï¸ éŸ³é¢‘æ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹æ³•: {task_id}")
                    
            except Exception as e:
                logger.error(f"âŒ è¯»å–éŸ³é¢‘metadataæ–‡ä»¶å¤±è´¥: {task_id}, {e}")
                # ç¬¬ä¸€ç§å¤±è´¥ï¼šè¯»å–éŸ³é¢‘metadataæ–‡ä»¶å¤±è´¥ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
                logger.info(f"ğŸ”„ è¯»å–éŸ³é¢‘metadataæ–‡ä»¶å¤±è´¥ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                success = clear_and_reset_task(task_id)
                if success:
                    return R.success({
                        "message": "éŸ³é¢‘æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œå·²æ¸…ç©ºé‡ç½®å¹¶é‡æ–°æäº¤ä»»åŠ¡",
                        "task_id": task_id
                    })
                else:
                    return R.error("éŸ³é¢‘æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œæ¸…ç©ºé‡ç½®ä»»åŠ¡ä¹Ÿå¤±è´¥")
        
        # å¦‚æœéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨æˆ–å¤±è´¥ï¼Œå°è¯•ä»ä¸»ç»“æœæ–‡ä»¶è¯»å–
        if os.path.exists(result_path):
            try:
                with open(result_path, "r", encoding="utf-8") as f:
                    result_data = json.load(f)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºé”™è¯¯æ–‡ä»¶
                if "error" in result_data:
                    logger.warning(f"âš ï¸ å‘ç°é”™è¯¯æ–‡ä»¶ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                    success = clear_and_reset_task(task_id, result_data)
                    if success:
                        return R.success({
                            "message": "å‘ç°é”™è¯¯æ–‡ä»¶ï¼Œå·²æ¸…ç©ºé‡ç½®å¹¶é‡æ–°æäº¤ä»»åŠ¡",
                            "task_id": task_id
                        })
                    else:
                        return R.error("å‘ç°é”™è¯¯æ–‡ä»¶ï¼Œæ¸…ç©ºé‡ç½®ä»»åŠ¡å¤±è´¥")
                
                # ä»ç»“æœæ–‡ä»¶ä¸­æå–åŸå§‹ä»»åŠ¡æ•°æ®
                if "audioMeta" in result_data and "transcript" in result_data:
                    # è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç»“æœæ–‡ä»¶ï¼ŒåŒ…å«åŸå§‹æ•°æ®
                    audio_meta = result_data.get("audioMeta", {})
                    video_url = audio_meta.get("file_path", "")
                    platform = audio_meta.get("platform", "")
                    title = audio_meta.get("title", "æœªçŸ¥æ ‡é¢˜")
                    
                    if video_url and platform:
                        try:
                            # é‡å»ºä»»åŠ¡æ•°æ®ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
                            from app.enmus.note_enums import DownloadQuality
                            
                            task_data = {
                                'video_url': video_url,
                                'platform': platform,
                                'quality': DownloadQuality.fast,
                                'model_name': request.model_name if request and request.model_name else 'gpt-4o-mini',
                                'provider_id': request.provider_id if request and request.provider_id else 'openai',
                                'screenshot': False,
                                'link': False,
                                'format': request.format if request and request.format else [],
                                'style': request.style if request and request.style else 'ç®€æ´',
                                'extras': None,
                                'video_understanding': request.video_understanding if request and request.video_understanding is not None else False,
                                'video_interval': request.video_interval if request and request.video_interval is not None else 0,
                                'grid_size': [],
                                'title': title
                            }
                            
                            # ä½¿ç”¨åŸtask_idé‡æ–°åˆ›å»ºä»»åŠ¡
                            new_task_id = task_queue.add_task(
                                task_type=TaskType.SINGLE_VIDEO, 
                                data=task_data,
                                task_id=task_id  # ä½¿ç”¨åŸæœ‰çš„task_id
                            )
                            
                            logger.info(f"âœ… ä»ç»“æœæ–‡ä»¶é‡å»ºä»»åŠ¡æˆåŠŸ: {task_id}")
                            return R.success({
                                "message": f"ä»»åŠ¡å·²ä»ç»“æœæ–‡ä»¶é‡å»ºå¹¶é‡æ–°æäº¤ï¼Œæ ‡é¢˜: {title}",
                                "task_id": task_id
                            })
                        except Exception as task_error:
                            logger.error(f"âŒ ä»ç»“æœæ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥: {task_id}, {task_error}")
                            logger.warning(f"âš ï¸ ç»“æœæ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œå°è¯•æ¸…ç©ºé‡ç½®: {task_id}")
                            # åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œå°è¯•æ¸…ç©ºé‡ç½®
                            success = clear_and_reset_task(task_id, result_data)
                            if success:
                                return R.success({
                                    "message": "ç»“æœæ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œå·²æ¸…ç©ºé‡ç½®å¹¶é‡æ–°æäº¤ä»»åŠ¡",
                                    "task_id": task_id
                                })
                            else:
                                return R.error("ç»“æœæ–‡ä»¶åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼Œæ¸…ç©ºé‡ç½®ä»»åŠ¡ä¹Ÿå¤±è´¥")
                    else:
                        logger.warning(f"âš ï¸ ç»“æœæ–‡ä»¶ä¸­ç¼ºå°‘å¿…è¦çš„è§†é¢‘ä¿¡æ¯: {task_id}")
                        # ç»“æœæ–‡ä»¶ä¸­ç¼ºå°‘å¿…è¦ä¿¡æ¯ï¼Œä¹Ÿè°ƒç”¨æ¸…ç©ºé‡ç½®
                        logger.info(f"ğŸ”„ ç»“æœæ–‡ä»¶ç¼ºå°‘è§†é¢‘ä¿¡æ¯ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                        success = clear_and_reset_task(task_id, result_data)
                        if success:
                            return R.success({
                                "message": "ç»“æœæ–‡ä»¶ç¼ºå°‘å¿…è¦ä¿¡æ¯ï¼Œå·²æ¸…ç©ºé‡ç½®å¹¶é‡æ–°æäº¤ä»»åŠ¡",
                                "task_id": task_id
                            })
                        else:
                            return R.error("ç»“æœæ–‡ä»¶ç¼ºå°‘å¿…è¦ä¿¡æ¯ï¼Œæ¸…ç©ºé‡ç½®ä»»åŠ¡å¤±è´¥")
                else:
                    logger.warning(f"âš ï¸ ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®: {task_id}")
                    # ç¬¬äºŒç§å¤±è´¥ï¼šç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
                    logger.info(f"ğŸ”„ ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                    success = clear_and_reset_task(task_id, result_data)
                    if success:
                        return R.success({
                            "message": "ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œå·²æ¸…ç©ºé‡ç½®å¹¶é‡æ–°æäº¤ä»»åŠ¡",
                            "task_id": task_id
                        })
                    else:
                        return R.error("ç»“æœæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œæ¸…ç©ºé‡ç½®ä»»åŠ¡å¤±è´¥")
                    
            except Exception as e:
                logger.error(f"âŒ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {task_id}, {e}")
                # è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥ï¼Œä¹Ÿè°ƒç”¨æ¸…ç©ºé‡ç½®
                logger.info(f"ğŸ”„ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
                success = clear_and_reset_task(task_id)
                if success:
                    return R.success({
                        "message": "ç»“æœæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œå·²æ¸…ç©ºé‡ç½®å¹¶é‡æ–°æäº¤ä»»åŠ¡",
                        "task_id": task_id
                    })
                else:
                    return R.error(f"ç»“æœæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œæ¸…ç©ºé‡ç½®ä»»åŠ¡ä¹Ÿå¤±è´¥: {str(e)}")
        else:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶: {task_id}")
            # ç¬¬ä¸‰ç§å¤±è´¥ï¼šæœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶ï¼Œè°ƒç”¨åˆ é™¤è€è®°å½•é‡æ–°é˜Ÿåˆ—æ‰§è¡Œ
            logger.info(f"ğŸ”„ æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶ï¼Œå°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
            success = clear_and_reset_task(task_id)
            if success:
                return R.success({
                    "message": "æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶ï¼Œå·²å°è¯•æ¸…ç©ºé‡ç½®ä»»åŠ¡",
                    "task_id": task_id
                })
            else:
                return R.error("æœªæ‰¾åˆ°ä»»åŠ¡ç›¸å…³æ–‡ä»¶ï¼Œæ— æ³•é‡å»ºä»»åŠ¡")
        
    except Exception as e:
        logger.error(f"âŒ å¼ºåˆ¶é‡è¯•ä»»åŠ¡å¤±è´¥: {e}")
        return R.error(f"å¼ºåˆ¶é‡è¯•ä»»åŠ¡å¤±è´¥: {str(e)}")

@router.post("/force_restart_task/{task_id}")
def force_restart_task(task_id: str):
    """å¼ºåˆ¶æ¸…ç†å¹¶é‡æ–°å¼€å§‹ä»»åŠ¡ - å®Œå…¨ä»å¤´å¼€å§‹ï¼Œæ¸…ç†æ‰€æœ‰ç›¸å…³æ–‡ä»¶"""
    try:
        from app.core.task_queue import TaskStatus as QueueTaskStatus, TaskType
        import glob
        
        logger.info(f"ğŸ”¥ å¼€å§‹å¼ºåˆ¶é‡æ–°å¼€å§‹ä»»åŠ¡: {task_id}")
        
        # 1. é¦–å…ˆå°è¯•ä»æŒä¹…åŒ–çš„åŸå§‹è¯·æ±‚æ•°æ®è·å–ä»»åŠ¡æ•°æ®
        request_file_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}.request.json")
        task_data = None
        
        if os.path.exists(request_file_path):
            try:
                with open(request_file_path, "r", encoding="utf-8") as f:
                    request_data = json.load(f)
                
                original_request = request_data.get("original_request", {})
                if original_request and original_request.get("video_url"):
                    try:
                        video_url = original_request.get("video_url")
                        platform = original_request.get("platform", "bilibili")
                        title = original_request.get("title", "æœªçŸ¥æ ‡é¢˜")
                        
                        from app.enmus.note_enums import DownloadQuality
                        
                        task_data = {
                            'video_url': video_url,
                            'platform': platform,
                            'quality': original_request.get('quality', DownloadQuality.fast),
                            'model_name': original_request.get('model_name', 'gpt-4o-mini'),
                            'provider_id': original_request.get('provider_id', 'openai'),
                            'screenshot': original_request.get('screenshot', False),
                            'link': original_request.get('link', False),
                            'format': original_request.get('format', []),
                            'style': original_request.get('style', 'ç®€æ´'),
                            'extras': original_request.get('extras', None),
                            'video_understanding': original_request.get('video_understanding', False),
                            'video_interval': original_request.get('video_interval', 0),
                            'grid_size': original_request.get('grid_size', []),
                            'title': title
                        }
                        
                        logger.info(f"âœ… ä»æŒä¹…åŒ–è¯·æ±‚æ•°æ®è·å–ä»»åŠ¡æ•°æ®æˆåŠŸ: {title} ({video_url})")
                    except Exception as data_error:
                        logger.error(f"âŒ ä»æŒä¹…åŒ–æ•°æ®æ„å»ºä»»åŠ¡æ•°æ®å¤±è´¥: {task_id}, {data_error}")
                        # å¦‚æœæ„å»ºä»»åŠ¡æ•°æ®å¤±è´¥ï¼Œtask_dataä¿æŒä¸ºNone
                    
            except Exception as e:
                logger.error(f"âŒ è¯»å–æŒä¹…åŒ–è¯·æ±‚æ•°æ®å¤±è´¥: {task_id}, {e}")
        
        # 2. å¦‚æœæŒä¹…åŒ–æ•°æ®ä¸å­˜åœ¨ï¼Œå°è¯•ä»éŸ³é¢‘æ–‡ä»¶è·å–åŸå§‹ä»»åŠ¡æ•°æ®
        if not task_data:
            audio_path = os.path.join(NOTE_OUTPUT_DIR, f"{task_id}_audio.json")
            
            if os.path.exists(audio_path):
                try:
                    with open(audio_path, "r", encoding="utf-8") as f:
                        audio_data = json.load(f)
                
                    # ä»éŸ³é¢‘æ–‡ä»¶æå–åŸå§‹ä»»åŠ¡æ•°æ®
                    video_url = audio_data.get("file_path", "")
                    # å¦‚æœæ˜¯BVå·ï¼Œè½¬æ¢ä¸ºBç«™URL
                    if "BV" in video_url:
                        video_id = os.path.basename(video_url).replace(".mp3", "")
                        video_url = f"https://www.bilibili.com/video/{video_id}"
                    elif not video_url.startswith("http"):
                        # å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œå°è¯•ä»video_idæ„å»ºURL
                        video_id = audio_data.get("video_id", "")
                        if video_id and video_id.startswith("BV"):
                            video_url = f"https://www.bilibili.com/video/{video_id}"
                        else:
                            video_url = audio_data.get("file_path", "")
                    
                    platform = audio_data.get("platform", "bilibili")
                    title = audio_data.get("title", "æœªçŸ¥æ ‡é¢˜")
                    
                    if video_url and platform:
                        try:
                            # é‡å»ºä»»åŠ¡æ•°æ®ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼Œå¯ä»¥åç»­è°ƒæ•´ï¼‰
                            from app.enmus.note_enums import DownloadQuality
                            
                            task_data = {
                                'video_url': video_url,
                                'platform': platform,
                                'quality': DownloadQuality.fast,
                                'model_name': 'gpt-4o-mini',  # é»˜è®¤æ¨¡å‹
                                'provider_id': 'openai',      # é»˜è®¤æä¾›è€…
                                'screenshot': False,
                                'link': False,
                                'format': [],
                                'style': 'ç®€æ´',
                                'extras': None,
                                'video_understanding': False,
                                'video_interval': 0,
                                'grid_size': [],
                                'title': title
                            }
                            
                            logger.info(f"âœ… ä»éŸ³é¢‘æ–‡ä»¶è·å–ä»»åŠ¡æ•°æ®æˆåŠŸ: {title} ({video_url})")
                        except Exception as data_error:
                            logger.error(f"âŒ æ„å»ºä»»åŠ¡æ•°æ®å¤±è´¥: {task_id}, {data_error}")
                            # å¦‚æœæ„å»ºä»»åŠ¡æ•°æ®å¤±è´¥ï¼Œtask_dataä¿æŒä¸ºNone
                except Exception as e:
                    logger.error(f"âŒ è¯»å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {task_id}, {e}")
        
        # å¦‚æœæ²¡æœ‰è·å–åˆ°ä»»åŠ¡æ•°æ®ï¼Œè¿”å›é”™è¯¯
        if not task_data:
            logger.error(f"âŒ æ— æ³•è·å–ä»»åŠ¡æ•°æ®ï¼Œæ— æ³•é‡æ–°å¼€å§‹: {task_id}")
            return R.error("æ— æ³•è·å–åŸå§‹ä»»åŠ¡æ•°æ®ï¼Œè¯·ç¡®ä¿ä»»åŠ¡æ–‡ä»¶å­˜åœ¨")
        
        # 2. æ¸…ç†æ‰€æœ‰ç›¸å…³æ–‡ä»¶
        logger.info(f"ğŸ§¹ å¼€å§‹æ¸…ç†ä»»åŠ¡ç›¸å…³æ–‡ä»¶: {task_id}")
        
        # æ¸…ç†æ¨¡å¼åˆ—è¡¨
        cleanup_patterns = [
            f"{task_id}.json",
            f"{task_id}.status.json", 
            f"{task_id}.request.json",  # åŸå§‹è¯·æ±‚æ•°æ®æ–‡ä»¶
            f"{task_id}_*.json",
            f"{task_id}_*.md",
            f"{task_id}_*.txt"
        ]
        
        cleaned_files = []
        for pattern in cleanup_patterns:
            file_pattern = os.path.join(NOTE_OUTPUT_DIR, pattern)
            matching_files = glob.glob(file_pattern)
            for file_path in matching_files:
                try:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                        cleaned_files.append(os.path.basename(file_path))
                        logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤æ–‡ä»¶: {os.path.basename(file_path)}")
                except Exception as e:
                    logger.warning(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥: {os.path.basename(file_path)}, {e}")
        
        # 3. ä»ä»»åŠ¡é˜Ÿåˆ—ä¸­ç§»é™¤æ—§ä»»åŠ¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        with task_queue._lock:
            if task_id in task_queue.tasks:
                del task_queue.tasks[task_id]
                logger.info(f"ğŸ—‘ï¸ å·²ä»ä»»åŠ¡é˜Ÿåˆ—ç§»é™¤æ—§ä»»åŠ¡: {task_id}")
        
        # 4. åˆ›å»ºå…¨æ–°çš„ä»»åŠ¡
        try:
            new_task_id = task_queue.add_task(
                task_type=TaskType.SINGLE_VIDEO, 
                data=task_data,
                task_id=task_id  # ä½¿ç”¨åŸæœ‰çš„task_id
            )
            
            logger.info(f"âœ… å¼ºåˆ¶é‡æ–°å¼€å§‹ä»»åŠ¡æˆåŠŸ: {task_id}")
            logger.info(f"ğŸ“‹ ä»»åŠ¡è¯¦æƒ…: {task_data.get('title', 'æœªçŸ¥æ ‡é¢˜')}")
            logger.info(f"ğŸ§¹ æ¸…ç†äº† {len(cleaned_files)} ä¸ªæ–‡ä»¶: {', '.join(cleaned_files)}")
            
            return R.success({
                "message": f"ä»»åŠ¡å·²å¼ºåˆ¶é‡æ–°å¼€å§‹ï¼Œæ ‡é¢˜: {task_data.get('title', 'æœªçŸ¥æ ‡é¢˜')}",
                "task_id": task_id,
                "video_url": task_data.get('video_url', ''),
                "title": task_data.get('title', 'æœªçŸ¥æ ‡é¢˜'),
                "cleaned_files": cleaned_files,
                "restart_time": time.time()
            })
        except Exception as task_error:
            logger.error(f"âŒ å¼ºåˆ¶é‡æ–°å¼€å§‹ä»»åŠ¡æ—¶åˆ›å»ºä»»åŠ¡å¤±è´¥: {task_id}, {task_error}")
            return R.error(f"å¼ºåˆ¶é‡æ–°å¼€å§‹ä»»åŠ¡å¤±è´¥: æ–‡ä»¶å·²æ¸…ç†ä½†ä»»åŠ¡åˆ›å»ºå¤±è´¥ - {str(task_error)}")
        
    except Exception as e:
        logger.error(f"âŒ å¼ºåˆ¶é‡æ–°å¼€å§‹ä»»åŠ¡å¤±è´¥: {task_id}, {e}")
        return R.error(f"å¼ºåˆ¶é‡æ–°å¼€å§‹ä»»åŠ¡å¤±è´¥: {str(e)}")

@router.post("/clear_reset_task/{task_id}")
def clear_reset_task(task_id: str):
    """æ¸…ç©ºå¹¶é‡ç½®å•ä¸ªä»»åŠ¡ï¼ˆåˆ é™¤æ‰€æœ‰ç›¸å…³æ–‡ä»¶å¹¶é‡æ–°åˆ›å»ºï¼‰"""
    try:
        logger.info(f"ğŸ§¹ æ‰‹åŠ¨æ¸…ç©ºé‡ç½®ä»»åŠ¡: {task_id}")
        
        # é¦–å…ˆä»é˜Ÿåˆ—ä¸­ç§»é™¤ä»»åŠ¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        with task_queue._lock:
            if task_id in task_queue.tasks:
                del task_queue.tasks[task_id]
                logger.info(f"ğŸ—‘ï¸ å·²ä»é˜Ÿåˆ—ä¸­ç§»é™¤ä»»åŠ¡: {task_id}")
        
        # æ‰§è¡Œæ¸…ç©ºé‡ç½®
        success = clear_and_reset_task(task_id)
        
        if success:
            logger.info(f"âœ… ä»»åŠ¡æ¸…ç©ºé‡ç½®æˆåŠŸ: {task_id}")
            return R.success({
                "message": "ä»»åŠ¡å·²æ¸…ç©ºé‡ç½®ï¼Œé‡æ–°è¿›å…¥é˜Ÿåˆ—",
                "task_id": task_id
            })
        else:
            logger.warning(f"âš ï¸ ä»»åŠ¡æ¸…ç©ºé‡ç½®éƒ¨åˆ†å¤±è´¥: {task_id}")
            return R.success({
                "message": "ä»»åŠ¡æ–‡ä»¶å·²æ¸…ç©ºï¼Œä½†æ— æ³•é‡æ–°åˆ›å»ºï¼ˆç¼ºå°‘åŸå§‹URLï¼‰",
                "task_id": task_id
            })
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç©ºé‡ç½®ä»»åŠ¡å‡ºé”™: {task_id}, {e}")
        return R.error(f"æ¸…ç©ºé‡ç½®ä»»åŠ¡å¤±è´¥: {str(e)}")

class BatchClearResetRequest(BaseModel):
    """æ‰¹é‡æ¸…ç©ºé‡ç½®è¯·æ±‚æ¨¡å‹"""
    task_ids: List[str]
    force_clear: Optional[bool] = False  # æ˜¯å¦å¼ºåˆ¶æ¸…ç©ºï¼ˆå³ä½¿æ— æ³•é‡æ–°åˆ›å»ºï¼‰

@router.post("/batch_clear_reset_tasks")
def batch_clear_reset_tasks(request: BatchClearResetRequest):
    """æ‰¹é‡æ¸…ç©ºé‡ç½®ä»»åŠ¡"""
    try:
        task_ids = request.task_ids
        force_clear = request.force_clear
        
        logger.info(f"ğŸ§¹ æ‰¹é‡æ¸…ç©ºé‡ç½®ä»»åŠ¡: {len(task_ids)} ä¸ªä»»åŠ¡")
        
        results = []
        success_count = 0
        
        for task_id in task_ids:
            try:
                # ä»é˜Ÿåˆ—ä¸­ç§»é™¤ä»»åŠ¡
                with task_queue._lock:
                    if task_id in task_queue.tasks:
                        del task_queue.tasks[task_id]
                
                # æ‰§è¡Œæ¸…ç©ºé‡ç½®
                success = clear_and_reset_task(task_id)
                
                if success:
                    results.append({
                        "task_id": task_id,
                        "status": "success",
                        "message": "æ¸…ç©ºé‡ç½®æˆåŠŸ"
                    })
                    success_count += 1
                else:
                    if force_clear:
                        # å¼ºåˆ¶æ¸…ç©ºæ¨¡å¼ï¼šå³ä½¿æ— æ³•é‡æ–°åˆ›å»ºä¹Ÿæ¸…ç©ºæ–‡ä»¶
                        results.append({
                            "task_id": task_id,
                            "status": "partial",
                            "message": "æ–‡ä»¶å·²æ¸…ç©ºï¼Œä½†æ— æ³•é‡æ–°åˆ›å»º"
                        })
                        success_count += 1
                    else:
                        results.append({
                            "task_id": task_id,
                            "status": "failed",
                            "message": "æ¸…ç©ºé‡ç½®å¤±è´¥"
                        })
                
            except Exception as e:
                results.append({
                    "task_id": task_id,
                    "status": "error",
                    "message": f"å¤„ç†å‡ºé”™: {str(e)}"
                })
        
        logger.info(f"âœ… æ‰¹é‡æ¸…ç©ºé‡ç½®å®Œæˆ: æˆåŠŸ={success_count}, æ€»æ•°={len(task_ids)}")
        
        return R.success({
            "results": results,
            "success_count": success_count,
            "total_count": len(task_ids),
            "message": f"æ‰¹é‡æ¸…ç©ºé‡ç½®å®Œæˆï¼ŒæˆåŠŸå¤„ç† {success_count}/{len(task_ids)} ä¸ªä»»åŠ¡"
        })
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡æ¸…ç©ºé‡ç½®ä»»åŠ¡å‡ºé”™: {e}")
        return R.error(f"æ‰¹é‡æ¸…ç©ºé‡ç½®ä»»åŠ¡å¤±è´¥: {str(e)}")
